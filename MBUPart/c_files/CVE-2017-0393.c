static void mt_decode_macroblock(VP8D_COMP *pbi, MACROBLOCKD *xd,
 unsigned int mb_idx)
{
    MB_PREDICTION_MODE mode;
 int i;
#if CONFIG_ERROR_CONCEALMENT
 int corruption_detected = 0;
#else
 (void)mb_idx;
#endif

 if (xd->mode_info_context->mbmi.mb_skip_coeff)
 {
        vp8_reset_mb_tokens_context(xd);
 }
 else if (!vp8dx_bool_error(xd->current_bc))
 {
 int eobtotal;
        eobtotal = vp8_decode_mb_tokens(pbi, xd);

 /* Special case:  Force the loopfilter to skip when eobtotal is zero */
        xd->mode_info_context->mbmi.mb_skip_coeff = (eobtotal==0);
 }

    mode = xd->mode_info_context->mbmi.mode;

 if (xd->segmentation_enabled)
        vp8_mb_init_dequantizer(pbi, xd);


#if CONFIG_ERROR_CONCEALMENT

 if(pbi->ec_active)
 {
 int throw_residual;
 /* When we have independent partitions we can apply residual even
         * though other partitions within the frame are corrupt.
         */
        throw_residual = (!pbi->independent_partitions &&
                          pbi->frame_corrupt_residual);
        throw_residual = (throw_residual || vp8dx_bool_error(xd->current_bc));

 if ((mb_idx >= pbi->mvs_corrupt_from_mb || throw_residual))
 {
 /* MB with corrupt residuals or corrupt mode/motion vectors.
             * Better to use the predictor as reconstruction.
             */
            pbi->frame_corrupt_residual = 1;
            memset(xd->qcoeff, 0, sizeof(xd->qcoeff));
            vp8_conceal_corrupt_mb(xd);


            corruption_detected = 1;

 /* force idct to be skipped for B_PRED and use the
             * prediction only for reconstruction
             * */
            memset(xd->eobs, 0, 25);
 }
 }
#endif

 /* do prediction */
 if (xd->mode_info_context->mbmi.ref_frame == INTRA_FRAME)
 {
        vp8_build_intra_predictors_mbuv_s(xd,
                                          xd->recon_above[1],
                                          xd->recon_above[2],
                                          xd->recon_left[1],
                                          xd->recon_left[2],
                                          xd->recon_left_stride[1],
                                          xd->dst.u_buffer, xd->dst.v_buffer,
                                          xd->dst.uv_stride);

 if (mode != B_PRED)
 {
            vp8_build_intra_predictors_mby_s(xd,
                                                 xd->recon_above[0],
                                                 xd->recon_left[0],
                                                 xd->recon_left_stride[0],
                                                 xd->dst.y_buffer,
                                                 xd->dst.y_stride);
 }
 else
 {
 short *DQC = xd->dequant_y1;
 int dst_stride = xd->dst.y_stride;

 /* clear out residual eob info */
 if(xd->mode_info_context->mbmi.mb_skip_coeff)
                memset(xd->eobs, 0, 25);

            intra_prediction_down_copy(xd, xd->recon_above[0] + 16);

 for (i = 0; i < 16; i++)
 {
                BLOCKD *b = &xd->block[i];
 unsigned char *dst = xd->dst.y_buffer + b->offset;
                B_PREDICTION_MODE b_mode =
                    xd->mode_info_context->bmi[i].as_mode;
 unsigned char *Above;
 unsigned char *yleft;
 int left_stride;
 unsigned char top_left;

 /*Caution: For some b_mode, it needs 8 pixels (4 above + 4 above-right).*/
 if (i < 4 && pbi->common.filter_level)
 Above = xd->recon_above[0] + b->offset;
 else
 Above = dst - dst_stride;

 if (i%4==0 && pbi->common.filter_level)
 {
                    yleft = xd->recon_left[0] + i;
                    left_stride = 1;
 }
 else
 {
                    yleft = dst - 1;
                    left_stride = dst_stride;
 }

 if ((i==4 || i==8 || i==12) && pbi->common.filter_level)
                    top_left = *(xd->recon_left[0] + i - 1);
 else
                    top_left = Above[-1];

                vp8_intra4x4_predict(Above, yleft, left_stride,
                                     b_mode, dst, dst_stride, top_left);

 if (xd->eobs[i] )
 {
 if (xd->eobs[i] > 1)
 {
                        vp8_dequant_idct_add(b->qcoeff, DQC, dst, dst_stride);
 }
 else
 {
                        vp8_dc_only_idct_add(b->qcoeff[0] * DQC[0],
                                             dst, dst_stride, dst, dst_stride);
                        memset(b->qcoeff, 0, 2 * sizeof(b->qcoeff[0]));
 }
 }
 }
 }
 }
 else
 {
        vp8_build_inter_predictors_mb(xd);
 }


#if CONFIG_ERROR_CONCEALMENT
 if (corruption_detected)
 {
 return;
 }
#endif

 if(!xd->mode_info_context->mbmi.mb_skip_coeff)
 {
 /* dequantization and idct */
 if (mode != B_PRED)
 {
 short *DQC = xd->dequant_y1;

 if (mode != SPLITMV)
 {
                BLOCKD *b = &xd->block[24];

 /* do 2nd order transform on the dc block */
 if (xd->eobs[24] > 1)
 {
                    vp8_dequantize_b(b, xd->dequant_y2);

                    vp8_short_inv_walsh4x4(&b->dqcoeff[0],
                        xd->qcoeff);
                    memset(b->qcoeff, 0, 16 * sizeof(b->qcoeff[0]));
 }
 else
 {
                    b->dqcoeff[0] = b->qcoeff[0] * xd->dequant_y2[0];
                    vp8_short_inv_walsh4x4_1(&b->dqcoeff[0],
                        xd->qcoeff);
                    memset(b->qcoeff, 0, 2 * sizeof(b->qcoeff[0]));
 }

 /* override the dc dequant constant in order to preserve the
                 * dc components
                 */
                DQC = xd->dequant_y1_dc;
 }

            vp8_dequant_idct_add_y_block
 (xd->qcoeff, DQC,
                             xd->dst.y_buffer,
                             xd->dst.y_stride, xd->eobs);
 }

        vp8_dequant_idct_add_uv_block
 (xd->qcoeff+16*16, xd->dequant_uv,
                         xd->dst.u_buffer, xd->dst.v_buffer,
                         xd->dst.uv_stride, xd->eobs+16);
 }
}

static unsigned int read_partition_size(VP8D_COMP *pbi,
 const unsigned char *cx_size)
{
 unsigned char temp[3];
 if (pbi->decrypt_cb)
 {
        pbi->decrypt_cb(pbi->decrypt_state, cx_size, temp, 3);
        cx_size = temp;
 }
 return cx_size[0] + (cx_size[1] << 8) + (cx_size[2] << 16);
}

vpx_codec_err_t vp8dx_set_reference(VP8D_COMP *pbi, enum vpx_ref_frame_type ref_frame_flag, YV12_BUFFER_CONFIG *sd)
{
    VP8_COMMON *cm = &pbi->common;
 int *ref_fb_ptr = NULL;
 int free_fb;

 if (ref_frame_flag == VP8_LAST_FRAME)
        ref_fb_ptr = &cm->lst_fb_idx;
 else if (ref_frame_flag == VP8_GOLD_FRAME)
        ref_fb_ptr = &cm->gld_fb_idx;
 else if (ref_frame_flag == VP8_ALTR_FRAME)
        ref_fb_ptr = &cm->alt_fb_idx;
 else{
        vpx_internal_error(&pbi->common.error, VPX_CODEC_ERROR,
 "Invalid reference frame");
 return pbi->common.error.error_code;
 }

 if(cm->yv12_fb[*ref_fb_ptr].y_height != sd->y_height ||
        cm->yv12_fb[*ref_fb_ptr].y_width != sd->y_width ||
        cm->yv12_fb[*ref_fb_ptr].uv_height != sd->uv_height ||
        cm->yv12_fb[*ref_fb_ptr].uv_width != sd->uv_width){
        vpx_internal_error(&pbi->common.error, VPX_CODEC_ERROR,
 "Incorrect buffer dimensions");
 }
 else{
 /* Find an empty frame buffer. */
        free_fb = get_free_fb(cm);
 /* Decrease fb_idx_ref_cnt since it will be increased again in
         * ref_cnt_fb() below. */
        cm->fb_idx_ref_cnt[free_fb]--;

 /* Manage the reference counters and copy image. */
        ref_cnt_fb (cm->fb_idx_ref_cnt, ref_fb_ptr, free_fb);
        vp8_yv12_copy_frame(sd, &cm->yv12_fb[*ref_fb_ptr]);
 }

 return pbi->common.error.error_code;
}

static void yv12_extend_frame_top_c(YV12_BUFFER_CONFIG *ybf)
{
 int i;
 unsigned char *src_ptr1;
 unsigned char *dest_ptr1;

 unsigned int Border;
 int plane_stride;

 /***********/
 /* Y Plane */
 /***********/
 Border = ybf->border;
    plane_stride = ybf->y_stride;
    src_ptr1 = ybf->y_buffer - Border;
    dest_ptr1 = src_ptr1 - (Border * plane_stride);

 for (i = 0; i < (int)Border; i++)
 {
        memcpy(dest_ptr1, src_ptr1, plane_stride);
        dest_ptr1 += plane_stride;
 }


 /***********/
 /* U Plane */
 /***********/
    plane_stride = ybf->uv_stride;
 Border /= 2;
    src_ptr1 = ybf->u_buffer - Border;
    dest_ptr1 = src_ptr1 - (Border * plane_stride);

 for (i = 0; i < (int)(Border); i++)
 {
        memcpy(dest_ptr1, src_ptr1, plane_stride);
        dest_ptr1 += plane_stride;
 }

 /***********/
 /* V Plane */
 /***********/

    src_ptr1 = ybf->v_buffer - Border;
    dest_ptr1 = src_ptr1 - (Border * plane_stride);

 for (i = 0; i < (int)(Border); i++)
 {
        memcpy(dest_ptr1, src_ptr1, plane_stride);
        dest_ptr1 += plane_stride;
 }
}

static void yv12_extend_frame_bottom_c(YV12_BUFFER_CONFIG *ybf)
{
 int i;
 unsigned char *src_ptr1, *src_ptr2;
 unsigned char *dest_ptr2;

 unsigned int Border;
 int plane_stride;
 int plane_height;

 /***********/
 /* Y Plane */
 /***********/
 Border = ybf->border;
    plane_stride = ybf->y_stride;
    plane_height = ybf->y_height;

    src_ptr1 = ybf->y_buffer - Border;
    src_ptr2 = src_ptr1 + (plane_height * plane_stride) - plane_stride;
    dest_ptr2 = src_ptr2 + plane_stride;

 for (i = 0; i < (int)Border; i++)
 {
        memcpy(dest_ptr2, src_ptr2, plane_stride);
        dest_ptr2 += plane_stride;
 }


 /***********/
 /* U Plane */
 /***********/
    plane_stride = ybf->uv_stride;
    plane_height = ybf->uv_height;
 Border /= 2;

    src_ptr1 = ybf->u_buffer - Border;
    src_ptr2 = src_ptr1 + (plane_height * plane_stride) - plane_stride;
    dest_ptr2 = src_ptr2 + plane_stride;

 for (i = 0; i < (int)(Border); i++)
 {
        memcpy(dest_ptr2, src_ptr2, plane_stride);
        dest_ptr2 += plane_stride;
 }

 /***********/
 /* V Plane */
 /***********/

    src_ptr1 = ybf->v_buffer - Border;
    src_ptr2 = src_ptr1 + (plane_height * plane_stride) - plane_stride;
    dest_ptr2 = src_ptr2 + plane_stride;

 for (i = 0; i < (int)(Border); i++)
 {
        memcpy(dest_ptr2, src_ptr2, plane_stride);
        dest_ptr2 += plane_stride;
 }
}

void vp8mt_de_alloc_temp_buffers(VP8D_COMP *pbi, int mb_rows)
{
    int i;

    if (pbi->b_multithreaded_rd)
    {
            vpx_free(pbi->mt_current_mb_col);
            pbi->mt_current_mb_col = NULL ;

        /* Free above_row buffers. *
        if (pbi->mt_yabove_row)
        {
            for (i=0; i< mb_rows; i++)
            {
                    vpx_free(pbi->mt_yabove_row[i]);
                    pbi->mt_yabove_row[i] = NULL ;
            }
            vpx_free(pbi->mt_yabove_row);
            pbi->mt_yabove_row = NULL ;
        }
        if (pbi->mt_uabove_row)
        {
            for (i=0; i< mb_rows; i++)
            {
                    vpx_free(pbi->mt_uabove_row[i]);
                    pbi->mt_uabove_row[i] = NULL ;
            }
            vpx_free(pbi->mt_uabove_row);
            pbi->mt_uabove_row = NULL ;
        }
        if (pbi->mt_vabove_row)
        {
            for (i=0; i< mb_rows; i++)
            {
                    vpx_free(pbi->mt_vabove_row[i]);
                    pbi->mt_vabove_row[i] = NULL ;
            }
            vpx_free(pbi->mt_vabove_row);
            pbi->mt_vabove_row = NULL ;
        }
        /* Free left_col buffers. *
        if (pbi->mt_yleft_col)
        {
            for (i=0; i< mb_rows; i++)
            {
                    vpx_free(pbi->mt_yleft_col[i]);
                    pbi->mt_yleft_col[i] = NULL ;
            }
            vpx_free(pbi->mt_yleft_col);
            pbi->mt_yleft_col = NULL ;
        }
        if (pbi->mt_uleft_col)
        {
            for (i=0; i< mb_rows; i++)
            {
                    vpx_free(pbi->mt_uleft_col[i]);
                    pbi->mt_uleft_col[i] = NULL ;
            }
            vpx_free(pbi->mt_uleft_col);
            pbi->mt_uleft_col = NULL ;
        }
        if (pbi->mt_vleft_col)
        {
            for (i=0; i< mb_rows; i++)
            {
                    vpx_free(pbi->mt_vleft_col[i]);
                    pbi->mt_vleft_col[i] = NULL ;
            }
            vpx_free(pbi->mt_vleft_col);
            pbi->mt_vleft_col = NULL ;
        }
}
}

int vp8_create_decoder_instances(struct frame_buffers *fb, VP8D_CONFIG *oxcf)
{
 if(!fb->use_frame_threads)
 {
 /* decoder instance for single thread mode */
        fb->pbi[0] = create_decompressor(oxcf);
 if(!fb->pbi[0])
 return VPX_CODEC_ERROR;

#if CONFIG_MULTITHREAD
 /* enable row-based threading only when use_frame_threads
         * is disabled */
        fb->pbi[0]->max_threads = oxcf->max_threads;
        vp8_decoder_create_threads(fb->pbi[0]);
#endif
 }
 else
 {
 /* TODO : create frame threads and decoder instances for each
         * thread here */
 }

 return VPX_CODEC_OK;
}

static void setup_token_decoder(VP8D_COMP *pbi,
const unsigned char* token_part_sizes)
{
vp8_reader *bool_decoder = &pbi->mbc[0];
unsigned int partition_idx;
unsigned int fragment_idx;
unsigned int num_token_partitions;
const unsigned char *first_fragment_end = pbi->fragments.ptrs[0] +
pbi->fragments.sizes[0];

TOKEN_PARTITION multi_token_partition =
(TOKEN_PARTITION)vp8_read_literal(&pbi->mbc[8], 2);
if (!vp8dx_bool_error(&pbi->mbc[8]))
pbi->common.multi_token_partition = multi_token_partition;
num_token_partitions = 1 << pbi->common.multi_token_partition;

/* Check for partitions within the fragments and unpack the fragments
* so that each fragment pointer points to its corresponding partition. */
for (fragment_idx = 0; fragment_idx < pbi->fragments.count; ++fragment_idx)
{
unsigned int fragment_size = pbi->fragments.sizes[fragment_idx];
const unsigned char *fragment_end = pbi->fragments.ptrs[fragment_idx] +
fragment_size;
/* Special case for handling the first partition since we have already
* read its size. */
if (fragment_idx == 0)
{
/* Size of first partition + token partition sizes element */
ptrdiff_t ext_first_part_size = token_part_sizes -
pbi->fragments.ptrs[0] + 3 * (num_token_partitions - 1);
fragment_size -= (unsigned int)ext_first_part_size;
if (fragment_size > 0)
{
pbi->fragments.sizes[0] = (unsigned int)ext_first_part_size;
/* The fragment contains an additional partition. Move to
* next. */
fragment_idx++;
pbi->fragments.ptrs[fragment_idx] = pbi->fragments.ptrs[0] +
pbi->fragments.sizes[0];
}
}
/* Split the chunk into partitions read from the bitstream */
while (fragment_size > 0)
{
ptrdiff_t partition_size = read_available_partition_size(
pbi,
token_part_sizes,
pbi->fragments.ptrs[fragment_idx],
first_fragment_end,
fragment_end,
fragment_idx - 1,
num_token_partitions);
pbi->fragments.sizes[fragment_idx] = (unsigned int)partition_size;
fragment_size -= (unsigned int)partition_size;
assert(fragment_idx <= num_token_partitions);
if (fragment_size > 0)
{
/* The fragment contains an additional partition.
* Move to next. */
fragment_idx++;
pbi->fragments.ptrs[fragment_idx] =
pbi->fragments.ptrs[fragment_idx - 1] + partition_size;
}
}
}

pbi->fragments.count = num_token_partitions + 1;

for (partition_idx = 1; partition_idx < pbi->fragments.count; ++partition_idx)
{
if (vp8dx_start_decode(bool_decoder,
pbi->fragments.ptrs[partition_idx],
pbi->fragments.sizes[partition_idx],
pbi->decrypt_cb, pbi->decrypt_state))
vpx_internal_error(&pbi->common.error, VPX_CODEC_MEM_ERROR,
"Failed to allocate bool decoder %d",
partition_idx);

bool_decoder++;

}

#if CONFIG_MULTITHREAD
    /* Clamp number of decoder threads *
    if (pbi->decoding_thread_count > num_token_partitions - 1)
        pbi->decoding_thread_count = num_token_partitions - 1;
#endif
}

static void mt_decode_mb_rows(VP8D_COMP *pbi, MACROBLOCKD *xd, int start_mb_row)
{
 volatile const int *last_row_current_mb_col;
 volatile int *current_mb_col;
 int mb_row;
    VP8_COMMON *pc = &pbi->common;
 const int nsync = pbi->sync_range;
 const int first_row_no_sync_above = pc->mb_cols + nsync;
 int num_part = 1 << pbi->common.multi_token_partition;
 int last_mb_row = start_mb_row;

    YV12_BUFFER_CONFIG *yv12_fb_new = pbi->dec_fb_ref[INTRA_FRAME];
    YV12_BUFFER_CONFIG *yv12_fb_lst = pbi->dec_fb_ref[LAST_FRAME];

 int recon_y_stride = yv12_fb_new->y_stride;
 int recon_uv_stride = yv12_fb_new->uv_stride;

 unsigned char *ref_buffer[MAX_REF_FRAMES][3];
 unsigned char *dst_buffer[3];
 int i;
 int ref_fb_corrupted[MAX_REF_FRAMES];

    ref_fb_corrupted[INTRA_FRAME] = 0;

 for(i = 1; i < MAX_REF_FRAMES; i++)
 {
        YV12_BUFFER_CONFIG *this_fb = pbi->dec_fb_ref[i];

        ref_buffer[i][0] = this_fb->y_buffer;
        ref_buffer[i][1] = this_fb->u_buffer;
        ref_buffer[i][2] = this_fb->v_buffer;

        ref_fb_corrupted[i] = this_fb->corrupted;
 }

    dst_buffer[0] = yv12_fb_new->y_buffer;
    dst_buffer[1] = yv12_fb_new->u_buffer;
    dst_buffer[2] = yv12_fb_new->v_buffer;

    xd->up_available = (start_mb_row != 0);

 for (mb_row = start_mb_row; mb_row < pc->mb_rows; mb_row += (pbi->decoding_thread_count + 1))
 {
 int recon_yoffset, recon_uvoffset;
 int mb_col;
 int filter_level;
       loop_filter_info_n *lfi_n = &pc->lf_info;

 /* save last row processed by this thread */
       last_mb_row = mb_row;
 /* select bool coder for current partition */
       xd->current_bc = &pbi->mbc[mb_row%num_part];

 if (mb_row > 0)
           last_row_current_mb_col = &pbi->mt_current_mb_col[mb_row -1];
 else
           last_row_current_mb_col = &first_row_no_sync_above;

       current_mb_col = &pbi->mt_current_mb_col[mb_row];

       recon_yoffset = mb_row * recon_y_stride * 16;
       recon_uvoffset = mb_row * recon_uv_stride * 8;

 /* reset contexts */
       xd->above_context = pc->above_context;
       memset(xd->left_context, 0, sizeof(ENTROPY_CONTEXT_PLANES));

       xd->left_available = 0;

       xd->mb_to_top_edge = -((mb_row * 16)) << 3;
       xd->mb_to_bottom_edge = ((pc->mb_rows - 1 - mb_row) * 16) << 3;

 if (pbi->common.filter_level)
 {
          xd->recon_above[0] = pbi->mt_yabove_row[mb_row] + 0*16 +32;
          xd->recon_above[1] = pbi->mt_uabove_row[mb_row] + 0*8 +16;
          xd->recon_above[2] = pbi->mt_vabove_row[mb_row] + 0*8 +16;

          xd->recon_left[0] = pbi->mt_yleft_col[mb_row];
          xd->recon_left[1] = pbi->mt_uleft_col[mb_row];
          xd->recon_left[2] = pbi->mt_vleft_col[mb_row];

 /* TODO: move to outside row loop */
          xd->recon_left_stride[0] = 1;
          xd->recon_left_stride[1] = 1;
 }
 else
 {
          xd->recon_above[0] = dst_buffer[0] + recon_yoffset;
          xd->recon_above[1] = dst_buffer[1] + recon_uvoffset;
          xd->recon_above[2] = dst_buffer[2] + recon_uvoffset;

          xd->recon_left[0] = xd->recon_above[0] - 1;
          xd->recon_left[1] = xd->recon_above[1] - 1;
          xd->recon_left[2] = xd->recon_above[2] - 1;

          xd->recon_above[0] -= xd->dst.y_stride;
          xd->recon_above[1] -= xd->dst.uv_stride;
          xd->recon_above[2] -= xd->dst.uv_stride;

 /* TODO: move to outside row loop */
          xd->recon_left_stride[0] = xd->dst.y_stride;
          xd->recon_left_stride[1] = xd->dst.uv_stride;

          setup_intra_recon_left(xd->recon_left[0], xd->recon_left[1],
                                 xd->recon_left[2], xd->dst.y_stride,
                                 xd->dst.uv_stride);
 }

 for (mb_col = 0; mb_col < pc->mb_cols; mb_col++)
 {
 *current_mb_col = mb_col - 1;

 if ((mb_col & (nsync - 1)) == 0)
 {
 while (mb_col > (*last_row_current_mb_col - nsync))
 {
                   x86_pause_hint();
                   thread_sleep(0);
 }
 }

 /* Distance of MB to the various image edges.
            * These are specified to 8th pel as they are always
            * compared to values that are in 1/8th pel units.
            */
           xd->mb_to_left_edge = -((mb_col * 16) << 3);
           xd->mb_to_right_edge = ((pc->mb_cols - 1 - mb_col) * 16) << 3;

 #if CONFIG_ERROR_CONCEALMENT
 {
 int corrupt_residual =
 (!pbi->independent_partitions &&
                           pbi->frame_corrupt_residual) ||
                           vp8dx_bool_error(xd->current_bc);
 if (pbi->ec_active &&
 (xd->mode_info_context->mbmi.ref_frame ==
                                                    INTRA_FRAME) &&
                   corrupt_residual)
 {
 /* We have an intra block with corrupt
                    * coefficients, better to conceal with an inter
                    * block.
                    * Interpolate MVs from neighboring MBs
                    *
                    * Note that for the first mb with corrupt
                    * residual in a frame, we might not discover
                    * that before decoding the residual. That
                    * happens after this check, and therefore no
                    * inter concealment will be done.
                    */
                   vp8_interpolate_motion(xd,
                                          mb_row, mb_col,
                                          pc->mb_rows, pc->mb_cols,
                                          pc->mode_info_stride);
 }
 }
 #endif


           xd->dst.y_buffer = dst_buffer[0] + recon_yoffset;
           xd->dst.u_buffer = dst_buffer[1] + recon_uvoffset;
           xd->dst.v_buffer = dst_buffer[2] + recon_uvoffset;

           xd->pre.y_buffer = ref_buffer[xd->mode_info_context->mbmi.ref_frame][0] + recon_yoffset;
           xd->pre.u_buffer = ref_buffer[xd->mode_info_context->mbmi.ref_frame][1] + recon_uvoffset;
           xd->pre.v_buffer = ref_buffer[xd->mode_info_context->mbmi.ref_frame][2] + recon_uvoffset;

 /* propagate errors from reference frames */
           xd->corrupted |= ref_fb_corrupted[xd->mode_info_context->mbmi.ref_frame];

           mt_decode_macroblock(pbi, xd, 0);

           xd->left_available = 1;

 /* check if the boolean decoder has suffered an error */
           xd->corrupted |= vp8dx_bool_error(xd->current_bc);

           xd->recon_above[0] += 16;
           xd->recon_above[1] += 8;
           xd->recon_above[2] += 8;

 if (!pbi->common.filter_level)
 {
              xd->recon_left[0] += 16;
              xd->recon_left[1] += 8;
              xd->recon_left[2] += 8;
 }

 if (pbi->common.filter_level)
 {
 int skip_lf = (xd->mode_info_context->mbmi.mode != B_PRED &&
                               xd->mode_info_context->mbmi.mode != SPLITMV &&
                               xd->mode_info_context->mbmi.mb_skip_coeff);

 const int mode_index = lfi_n->mode_lf_lut[xd->mode_info_context->mbmi.mode];
 const int seg = xd->mode_info_context->mbmi.segment_id;
 const int ref_frame = xd->mode_info_context->mbmi.ref_frame;

               filter_level = lfi_n->lvl[seg][ref_frame][mode_index];

 if( mb_row != pc->mb_rows-1 )
 {
 /* Save decoded MB last row data for next-row decoding */
                   memcpy((pbi->mt_yabove_row[mb_row + 1] + 32 + mb_col*16), (xd->dst.y_buffer + 15 * recon_y_stride), 16);
                   memcpy((pbi->mt_uabove_row[mb_row + 1] + 16 + mb_col*8), (xd->dst.u_buffer + 7 * recon_uv_stride), 8);
                   memcpy((pbi->mt_vabove_row[mb_row + 1] + 16 + mb_col*8), (xd->dst.v_buffer + 7 * recon_uv_stride), 8);
 }

 /* save left_col for next MB decoding */
 if(mb_col != pc->mb_cols-1)
 {
                   MODE_INFO *next = xd->mode_info_context +1;

 if (next->mbmi.ref_frame == INTRA_FRAME)
 {
 for (i = 0; i < 16; i++)
                           pbi->mt_yleft_col[mb_row][i] = xd->dst.y_buffer [i* recon_y_stride + 15];
 for (i = 0; i < 8; i++)
 {
                           pbi->mt_uleft_col[mb_row][i] = xd->dst.u_buffer [i* recon_uv_stride + 7];
                           pbi->mt_vleft_col[mb_row][i] = xd->dst.v_buffer [i* recon_uv_stride + 7];
 }
 }
 }

 /* loopfilter on this macroblock. */
 if (filter_level)
 {
 if(pc->filter_type == NORMAL_LOOPFILTER)
 {
                       loop_filter_info lfi;
                       FRAME_TYPE frame_type = pc->frame_type;
 const int hev_index = lfi_n->hev_thr_lut[frame_type][filter_level];
                       lfi.mblim = lfi_n->mblim[filter_level];
                       lfi.blim = lfi_n->blim[filter_level];
                       lfi.lim = lfi_n->lim[filter_level];
                       lfi.hev_thr = lfi_n->hev_thr[hev_index];

 if (mb_col > 0)
                           vp8_loop_filter_mbv
 (xd->dst.y_buffer, xd->dst.u_buffer, xd->dst.v_buffer, recon_y_stride, recon_uv_stride, &lfi);

 if (!skip_lf)
                           vp8_loop_filter_bv
 (xd->dst.y_buffer, xd->dst.u_buffer, xd->dst.v_buffer, recon_y_stride, recon_uv_stride, &lfi);

 /* don't apply across umv border */
 if (mb_row > 0)
                           vp8_loop_filter_mbh
 (xd->dst.y_buffer, xd->dst.u_buffer, xd->dst.v_buffer, recon_y_stride, recon_uv_stride, &lfi);

 if (!skip_lf)
                           vp8_loop_filter_bh
 (xd->dst.y_buffer, xd->dst.u_buffer, xd->dst.v_buffer,  recon_y_stride, recon_uv_stride, &lfi);
 }
 else
 {
 if (mb_col > 0)
                           vp8_loop_filter_simple_mbv
 (xd->dst.y_buffer, recon_y_stride, lfi_n->mblim[filter_level]);

 if (!skip_lf)
                           vp8_loop_filter_simple_bv
 (xd->dst.y_buffer, recon_y_stride, lfi_n->blim[filter_level]);

 /* don't apply across umv border */
 if (mb_row > 0)
                           vp8_loop_filter_simple_mbh
 (xd->dst.y_buffer, recon_y_stride, lfi_n->mblim[filter_level]);

 if (!skip_lf)
                           vp8_loop_filter_simple_bh
 (xd->dst.y_buffer, recon_y_stride, lfi_n->blim[filter_level]);
 }
 }

 }

           recon_yoffset += 16;
           recon_uvoffset += 8;

 ++xd->mode_info_context; /* next mb */

           xd->above_context++;
 }

 /* adjust to the next row of mbs */
 if (pbi->common.filter_level)
 {
 if(mb_row != pc->mb_rows-1)
 {
 int lasty = yv12_fb_lst->y_width + VP8BORDERINPIXELS;
 int lastuv = (yv12_fb_lst->y_width>>1) + (VP8BORDERINPIXELS>>1);

 for (i = 0; i < 4; i++)
 {
                   pbi->mt_yabove_row[mb_row +1][lasty + i] = pbi->mt_yabove_row[mb_row +1][lasty -1];
                   pbi->mt_uabove_row[mb_row +1][lastuv + i] = pbi->mt_uabove_row[mb_row +1][lastuv -1];
                   pbi->mt_vabove_row[mb_row +1][lastuv + i] = pbi->mt_vabove_row[mb_row +1][lastuv -1];
 }
 }
 }
 else
           vp8_extend_mb_row(yv12_fb_new, xd->dst.y_buffer + 16,
                             xd->dst.u_buffer + 8, xd->dst.v_buffer + 8);

 /* last MB of row is ready just after extension is done */
 *current_mb_col = mb_col + nsync;

 ++xd->mode_info_context; /* skip prediction column */
       xd->up_available = 1;

 /* since we have multithread */
       xd->mode_info_context += xd->mode_info_stride * pbi->decoding_thread_count;
 }

 /* signal end of frame decoding if this thread processed the last mb_row */
 if (last_mb_row == (pc->mb_rows - 1))
        sem_post(&pbi->h_event_end_decoding);

}

void vp8_mb_init_dequantizer(VP8D_COMP *pbi, MACROBLOCKD *xd)
{
 int i;
 int QIndex;
    MB_MODE_INFO *mbmi = &xd->mode_info_context->mbmi;
    VP8_COMMON *const pc = & pbi->common;

 /* Decide whether to use the default or alternate baseline Q value. */
 if (xd->segmentation_enabled)
 {
 /* Abs Value */
 if (xd->mb_segement_abs_delta == SEGMENT_ABSDATA)
 QIndex = xd->segment_feature_data[MB_LVL_ALT_Q][mbmi->segment_id];

 /* Delta Value */
 else
 QIndex = pc->base_qindex + xd->segment_feature_data[MB_LVL_ALT_Q][mbmi->segment_id];

 QIndex = (QIndex >= 0) ? ((QIndex <= MAXQ) ? QIndex : MAXQ) : 0; /* Clamp to valid range */
 }
 else
 QIndex = pc->base_qindex;

 /* Set up the macroblock dequant constants */
    xd->dequant_y1_dc[0] = 1;
    xd->dequant_y1[0] = pc->Y1dequant[QIndex][0];
    xd->dequant_y2[0] = pc->Y2dequant[QIndex][0];
    xd->dequant_uv[0] = pc->UVdequant[QIndex][0];

 for (i = 1; i < 16; i++)
 {
        xd->dequant_y1_dc[i] =
        xd->dequant_y1[i] = pc->Y1dequant[QIndex][1];
        xd->dequant_y2[i] = pc->Y2dequant[QIndex][1];
        xd->dequant_uv[i] = pc->UVdequant[QIndex][1];
 }
}

void vp8_decoder_remove_threads(VP8D_COMP *pbi)
{
    /* shutdown MB Decoding thread; *
    if (pbi->b_multithreaded_rd)
    {
        int i;

        pbi->b_multithreaded_rd = 0;
        /* allow all threads to exit *
        for (i = 0; i < pbi->allocated_decoding_thread_count; i++)
        {
            sem_post(&pbi->h_event_start_decoding[i]);
            pthread_join(pbi->h_decoding_thread[i], NULL);
        }
        for (i = 0; i < pbi->allocated_decoding_thread_count; i++)
        {
            sem_destroy(&pbi->h_event_start_decoding[i]);
        }
        sem_destroy(&pbi->h_event_end_decoding);
            vpx_free(pbi->h_decoding_thread);
            pbi->h_decoding_thread = NULL;
            vpx_free(pbi->h_event_start_decoding);
            pbi->h_event_start_decoding = NULL;
            vpx_free(pbi->mb_row_di);
            pbi->mb_row_di = NULL ;
            vpx_free(pbi->de_thread_data);
            pbi->de_thread_data = NULL;
}
}

static int get_free_fb (VP8_COMMON *cm)
{
 int i;
 for (i = 0; i < NUM_YV12_BUFFERS; i++)
 if (cm->fb_idx_ref_cnt[i] == 0)
 break;

    assert(i < NUM_YV12_BUFFERS);
    cm->fb_idx_ref_cnt[i] = 1;
 return i;
}

static int get_delta_q(vp8_reader *bc, int prev, int *q_update)
{
 int ret_val = 0;

 if (vp8_read_bit(bc))
 {
        ret_val = vp8_read_literal(bc, 4);

 if (vp8_read_bit(bc))
            ret_val = -ret_val;
 }

 /* Trigger a quantizer update if the delta-q value has changed */
 if (ret_val != prev)
 *q_update = 1;

 return ret_val;
}

static void decode_macroblock(VP8D_COMP *pbi, MACROBLOCKD *xd,
 unsigned int mb_idx)
{
    MB_PREDICTION_MODE mode;
 int i;
#if CONFIG_ERROR_CONCEALMENT
 int corruption_detected = 0;
#else
 (void)mb_idx;
#endif

 if (xd->mode_info_context->mbmi.mb_skip_coeff)
 {
        vp8_reset_mb_tokens_context(xd);
 }
 else if (!vp8dx_bool_error(xd->current_bc))
 {
 int eobtotal;
        eobtotal = vp8_decode_mb_tokens(pbi, xd);

 /* Special case:  Force the loopfilter to skip when eobtotal is zero */
        xd->mode_info_context->mbmi.mb_skip_coeff = (eobtotal==0);
 }

    mode = xd->mode_info_context->mbmi.mode;

 if (xd->segmentation_enabled)
        vp8_mb_init_dequantizer(pbi, xd);


#if CONFIG_ERROR_CONCEALMENT

 if(pbi->ec_active)
 {
 int throw_residual;
 /* When we have independent partitions we can apply residual even
         * though other partitions within the frame are corrupt.
         */
        throw_residual = (!pbi->independent_partitions &&
                          pbi->frame_corrupt_residual);
        throw_residual = (throw_residual || vp8dx_bool_error(xd->current_bc));

 if ((mb_idx >= pbi->mvs_corrupt_from_mb || throw_residual))
 {
 /* MB with corrupt residuals or corrupt mode/motion vectors.
             * Better to use the predictor as reconstruction.
             */
            pbi->frame_corrupt_residual = 1;
            memset(xd->qcoeff, 0, sizeof(xd->qcoeff));
            vp8_conceal_corrupt_mb(xd);


            corruption_detected = 1;

 /* force idct to be skipped for B_PRED and use the
             * prediction only for reconstruction
             * */
            memset(xd->eobs, 0, 25);
 }
 }
#endif

 /* do prediction */
 if (xd->mode_info_context->mbmi.ref_frame == INTRA_FRAME)
 {
        vp8_build_intra_predictors_mbuv_s(xd,
                                          xd->recon_above[1],
                                          xd->recon_above[2],
                                          xd->recon_left[1],
                                          xd->recon_left[2],
                                          xd->recon_left_stride[1],
                                          xd->dst.u_buffer, xd->dst.v_buffer,
                                          xd->dst.uv_stride);

 if (mode != B_PRED)
 {
            vp8_build_intra_predictors_mby_s(xd,
                                                 xd->recon_above[0],
                                                 xd->recon_left[0],
                                                 xd->recon_left_stride[0],
                                                 xd->dst.y_buffer,
                                                 xd->dst.y_stride);
 }
 else
 {
 short *DQC = xd->dequant_y1;
 int dst_stride = xd->dst.y_stride;

 /* clear out residual eob info */
 if(xd->mode_info_context->mbmi.mb_skip_coeff)
                memset(xd->eobs, 0, 25);

            intra_prediction_down_copy(xd, xd->recon_above[0] + 16);

 for (i = 0; i < 16; i++)
 {
                BLOCKD *b = &xd->block[i];
 unsigned char *dst = xd->dst.y_buffer + b->offset;
                B_PREDICTION_MODE b_mode =
                    xd->mode_info_context->bmi[i].as_mode;
 unsigned char *Above = dst - dst_stride;
 unsigned char *yleft = dst - 1;
 int left_stride = dst_stride;
 unsigned char top_left = Above[-1];

                vp8_intra4x4_predict(Above, yleft, left_stride, b_mode,
                                     dst, dst_stride, top_left);

 if (xd->eobs[i])
 {
 if (xd->eobs[i] > 1)
 {
                    vp8_dequant_idct_add(b->qcoeff, DQC, dst, dst_stride);
 }
 else
 {
                        vp8_dc_only_idct_add
 (b->qcoeff[0] * DQC[0],
                                dst, dst_stride,
                                dst, dst_stride);
                        memset(b->qcoeff, 0, 2 * sizeof(b->qcoeff[0]));
 }
 }
 }
 }
 }
 else
 {
        vp8_build_inter_predictors_mb(xd);
 }


#if CONFIG_ERROR_CONCEALMENT
 if (corruption_detected)
 {
 return;
 }
#endif

 if(!xd->mode_info_context->mbmi.mb_skip_coeff)
 {
 /* dequantization and idct */
 if (mode != B_PRED)
 {
 short *DQC = xd->dequant_y1;

 if (mode != SPLITMV)
 {
                BLOCKD *b = &xd->block[24];

 /* do 2nd order transform on the dc block */
 if (xd->eobs[24] > 1)
 {
                    vp8_dequantize_b(b, xd->dequant_y2);

                    vp8_short_inv_walsh4x4(&b->dqcoeff[0],
                        xd->qcoeff);
                    memset(b->qcoeff, 0, 16 * sizeof(b->qcoeff[0]));
 }
 else
 {
                    b->dqcoeff[0] = b->qcoeff[0] * xd->dequant_y2[0];
                    vp8_short_inv_walsh4x4_1(&b->dqcoeff[0],
                        xd->qcoeff);
                    memset(b->qcoeff, 0, 2 * sizeof(b->qcoeff[0]));
 }

 /* override the dc dequant constant in order to preserve the
                 * dc components
                 */
                DQC = xd->dequant_y1_dc;
 }

            vp8_dequant_idct_add_y_block
 (xd->qcoeff, DQC,
                             xd->dst.y_buffer,
                             xd->dst.y_stride, xd->eobs);
 }

        vp8_dequant_idct_add_uv_block
 (xd->qcoeff+16*16, xd->dequant_uv,
                         xd->dst.u_buffer, xd->dst.v_buffer,
                         xd->dst.uv_stride, xd->eobs+16);
 }
}

static void decode_mb_rows(VP8D_COMP *pbi)
{
    VP8_COMMON *const pc = & pbi->common;
    MACROBLOCKD *const xd  = & pbi->mb;

    MODE_INFO *lf_mic = xd->mode_info_context;

 int ibc = 0;
 int num_part = 1 << pc->multi_token_partition;

 int recon_yoffset, recon_uvoffset;
 int mb_row, mb_col;
 int mb_idx = 0;

    YV12_BUFFER_CONFIG *yv12_fb_new = pbi->dec_fb_ref[INTRA_FRAME];

 int recon_y_stride = yv12_fb_new->y_stride;
 int recon_uv_stride = yv12_fb_new->uv_stride;

 unsigned char *ref_buffer[MAX_REF_FRAMES][3];
 unsigned char *dst_buffer[3];
 unsigned char *lf_dst[3];
 unsigned char *eb_dst[3];
 int i;
 int ref_fb_corrupted[MAX_REF_FRAMES];

    ref_fb_corrupted[INTRA_FRAME] = 0;

 for(i = 1; i < MAX_REF_FRAMES; i++)
 {
        YV12_BUFFER_CONFIG *this_fb = pbi->dec_fb_ref[i];

        ref_buffer[i][0] = this_fb->y_buffer;
        ref_buffer[i][1] = this_fb->u_buffer;
        ref_buffer[i][2] = this_fb->v_buffer;

        ref_fb_corrupted[i] = this_fb->corrupted;
 }

 /* Set up the buffer pointers */
    eb_dst[0] = lf_dst[0] = dst_buffer[0] = yv12_fb_new->y_buffer;
    eb_dst[1] = lf_dst[1] = dst_buffer[1] = yv12_fb_new->u_buffer;
    eb_dst[2] = lf_dst[2] = dst_buffer[2] = yv12_fb_new->v_buffer;

    xd->up_available = 0;

 /* Initialize the loop filter for this frame. */
 if(pc->filter_level)
        vp8_loop_filter_frame_init(pc, xd, pc->filter_level);

    vp8_setup_intra_recon_top_line(yv12_fb_new);

 /* Decode the individual macro block */
 for (mb_row = 0; mb_row < pc->mb_rows; mb_row++)
 {
 if (num_part > 1)
 {
            xd->current_bc = & pbi->mbc[ibc];
            ibc++;

 if (ibc == num_part)
                ibc = 0;
 }

        recon_yoffset = mb_row * recon_y_stride * 16;
        recon_uvoffset = mb_row * recon_uv_stride * 8;

 /* reset contexts */
        xd->above_context = pc->above_context;
        memset(xd->left_context, 0, sizeof(ENTROPY_CONTEXT_PLANES));

        xd->left_available = 0;

        xd->mb_to_top_edge = -((mb_row * 16) << 3);
        xd->mb_to_bottom_edge = ((pc->mb_rows - 1 - mb_row) * 16) << 3;

        xd->recon_above[0] = dst_buffer[0] + recon_yoffset;
        xd->recon_above[1] = dst_buffer[1] + recon_uvoffset;
        xd->recon_above[2] = dst_buffer[2] + recon_uvoffset;

        xd->recon_left[0] = xd->recon_above[0] - 1;
        xd->recon_left[1] = xd->recon_above[1] - 1;
        xd->recon_left[2] = xd->recon_above[2] - 1;

        xd->recon_above[0] -= xd->dst.y_stride;
        xd->recon_above[1] -= xd->dst.uv_stride;
        xd->recon_above[2] -= xd->dst.uv_stride;

 /* TODO: move to outside row loop */
        xd->recon_left_stride[0] = xd->dst.y_stride;
        xd->recon_left_stride[1] = xd->dst.uv_stride;

        setup_intra_recon_left(xd->recon_left[0], xd->recon_left[1],
                               xd->recon_left[2], xd->dst.y_stride,
                               xd->dst.uv_stride);

 for (mb_col = 0; mb_col < pc->mb_cols; mb_col++)
 {
 /* Distance of Mb to the various image edges.
             * These are specified to 8th pel as they are always compared to values
             * that are in 1/8th pel units
             */
            xd->mb_to_left_edge = -((mb_col * 16) << 3);
            xd->mb_to_right_edge = ((pc->mb_cols - 1 - mb_col) * 16) << 3;

#if CONFIG_ERROR_CONCEALMENT
 {
 int corrupt_residual = (!pbi->independent_partitions &&
                                       pbi->frame_corrupt_residual) ||
                                       vp8dx_bool_error(xd->current_bc);
 if (pbi->ec_active &&
                    xd->mode_info_context->mbmi.ref_frame == INTRA_FRAME &&
                    corrupt_residual)
 {
 /* We have an intra block with corrupt coefficients, better to
                     * conceal with an inter block. Interpolate MVs from neighboring
                     * MBs.
                     *
                     * Note that for the first mb with corrupt residual in a frame,
                     * we might not discover that before decoding the residual. That
                     * happens after this check, and therefore no inter concealment
                     * will be done.
                     */
                    vp8_interpolate_motion(xd,
                                           mb_row, mb_col,
                                           pc->mb_rows, pc->mb_cols,
                                           pc->mode_info_stride);
 }
 }
#endif

            xd->dst.y_buffer = dst_buffer[0] + recon_yoffset;
            xd->dst.u_buffer = dst_buffer[1] + recon_uvoffset;
            xd->dst.v_buffer = dst_buffer[2] + recon_uvoffset;

 if (xd->mode_info_context->mbmi.ref_frame >= LAST_FRAME) {
 const MV_REFERENCE_FRAME ref = xd->mode_info_context->mbmi.ref_frame;
              xd->pre.y_buffer = ref_buffer[ref][0] + recon_yoffset;
              xd->pre.u_buffer = ref_buffer[ref][1] + recon_uvoffset;
              xd->pre.v_buffer = ref_buffer[ref][2] + recon_uvoffset;
 } else {
              xd->pre.y_buffer = 0;
              xd->pre.u_buffer = 0;
              xd->pre.v_buffer = 0;
 }

 /* propagate errors from reference frames */
            xd->corrupted |= ref_fb_corrupted[xd->mode_info_context->mbmi.ref_frame];

            decode_macroblock(pbi, xd, mb_idx);

            mb_idx++;
            xd->left_available = 1;

 /* check if the boolean decoder has suffered an error */
            xd->corrupted |= vp8dx_bool_error(xd->current_bc);

            xd->recon_above[0] += 16;
            xd->recon_above[1] += 8;
            xd->recon_above[2] += 8;
            xd->recon_left[0] += 16;
            xd->recon_left[1] += 8;
            xd->recon_left[2] += 8;

            recon_yoffset += 16;
            recon_uvoffset += 8;

 ++xd->mode_info_context; /* next mb */

            xd->above_context++;
 }

 /* adjust to the next row of mbs */
        vp8_extend_mb_row(yv12_fb_new, xd->dst.y_buffer + 16,
                          xd->dst.u_buffer + 8, xd->dst.v_buffer + 8);

 ++xd->mode_info_context; /* skip prediction column */
        xd->up_available = 1;

 if(pc->filter_level)
 {
 if(mb_row > 0)
 {
 if (pc->filter_type == NORMAL_LOOPFILTER)
                    vp8_loop_filter_row_normal(pc, lf_mic, mb_row-1,
                                               recon_y_stride, recon_uv_stride,
                                               lf_dst[0], lf_dst[1], lf_dst[2]);
 else
                    vp8_loop_filter_row_simple(pc, lf_mic, mb_row-1,
                                               recon_y_stride, recon_uv_stride,
                                               lf_dst[0], lf_dst[1], lf_dst[2]);
 if(mb_row > 1)
 {
                    yv12_extend_frame_left_right_c(yv12_fb_new,
                                                   eb_dst[0],
                                                   eb_dst[1],
                                                   eb_dst[2]);

                    eb_dst[0] += recon_y_stride  * 16;
                    eb_dst[1] += recon_uv_stride * 8;
                    eb_dst[2] += recon_uv_stride * 8;
 }

                lf_dst[0] += recon_y_stride  * 16;
                lf_dst[1] += recon_uv_stride * 8;
                lf_dst[2] += recon_uv_stride * 8;
                lf_mic += pc->mb_cols;
                lf_mic++; /* Skip border mb */
 }
 }
 else
 {
 if(mb_row > 0)
 {
 /**/
                yv12_extend_frame_left_right_c(yv12_fb_new,
                                               eb_dst[0],
                                               eb_dst[1],
                                               eb_dst[2]);
                eb_dst[0] += recon_y_stride  * 16;
                eb_dst[1] += recon_uv_stride * 8;
                eb_dst[2] += recon_uv_stride * 8;
 }
 }
 }

 if(pc->filter_level)
 {
 if (pc->filter_type == NORMAL_LOOPFILTER)
            vp8_loop_filter_row_normal(pc, lf_mic, mb_row-1, recon_y_stride,
                                       recon_uv_stride, lf_dst[0], lf_dst[1],
                                       lf_dst[2]);
 else
            vp8_loop_filter_row_simple(pc, lf_mic, mb_row-1, recon_y_stride,
                                       recon_uv_stride, lf_dst[0], lf_dst[1],
                                       lf_dst[2]);

        yv12_extend_frame_left_right_c(yv12_fb_new,
                                       eb_dst[0],
                                       eb_dst[1],
                                       eb_dst[2]);
        eb_dst[0] += recon_y_stride  * 16;
        eb_dst[1] += recon_uv_stride * 8;
        eb_dst[2] += recon_uv_stride * 8;
 }
    yv12_extend_frame_left_right_c(yv12_fb_new,
                                   eb_dst[0],
                                   eb_dst[1],
                                   eb_dst[2]);
    yv12_extend_frame_top_c(yv12_fb_new);
    yv12_extend_frame_bottom_c(yv12_fb_new);

}

static void setup_decoding_thread_data(VP8D_COMP *pbi, MACROBLOCKD *xd, MB_ROW_DEC *mbrd, int count)
{
    VP8_COMMON *const pc = & pbi->common;
 int i;

 for (i = 0; i < count; i++)
 {
        MACROBLOCKD *mbd = &mbrd[i].mbd;
        mbd->subpixel_predict        = xd->subpixel_predict;
        mbd->subpixel_predict8x4     = xd->subpixel_predict8x4;
        mbd->subpixel_predict8x8     = xd->subpixel_predict8x8;
        mbd->subpixel_predict16x16   = xd->subpixel_predict16x16;

        mbd->mode_info_context = pc->mi   + pc->mode_info_stride * (i + 1);
        mbd->mode_info_stride  = pc->mode_info_stride;

        mbd->frame_type = pc->frame_type;
        mbd->pre = xd->pre;
        mbd->dst = xd->dst;

        mbd->segmentation_enabled    = xd->segmentation_enabled;
        mbd->mb_segement_abs_delta     = xd->mb_segement_abs_delta;
        memcpy(mbd->segment_feature_data, xd->segment_feature_data, sizeof(xd->segment_feature_data));

 /*signed char ref_lf_deltas[MAX_REF_LF_DELTAS];*/
        memcpy(mbd->ref_lf_deltas, xd->ref_lf_deltas, sizeof(xd->ref_lf_deltas));
 /*signed char mode_lf_deltas[MAX_MODE_LF_DELTAS];*/
        memcpy(mbd->mode_lf_deltas, xd->mode_lf_deltas, sizeof(xd->mode_lf_deltas));
 /*unsigned char mode_ref_lf_delta_enabled;
        unsigned char mode_ref_lf_delta_update;*/
        mbd->mode_ref_lf_delta_enabled    = xd->mode_ref_lf_delta_enabled;
        mbd->mode_ref_lf_delta_update    = xd->mode_ref_lf_delta_update;

        mbd->current_bc = &pbi->mbc[0];

        memcpy(mbd->dequant_y1_dc, xd->dequant_y1_dc, sizeof(xd->dequant_y1_dc));
        memcpy(mbd->dequant_y1, xd->dequant_y1, sizeof(xd->dequant_y1));
        memcpy(mbd->dequant_y2, xd->dequant_y2, sizeof(xd->dequant_y2));
        memcpy(mbd->dequant_uv, xd->dequant_uv, sizeof(xd->dequant_uv));

        mbd->fullpixel_mask = 0xffffffff;

 if (pc->full_pixel)
            mbd->fullpixel_mask = 0xfffffff8;

 }

 for (i = 0; i < pc->mb_rows; i++)
        pbi->mt_current_mb_col[i] = -1;
}

 void vp8mt_decode_mb_rows( VP8D_COMP *pbi, MACROBLOCKD *xd)
{
    VP8_COMMON *pc = &pbi->common;
 unsigned int i;
 int j;

 int filter_level = pc->filter_level;
    YV12_BUFFER_CONFIG *yv12_fb_new = pbi->dec_fb_ref[INTRA_FRAME];

 if (filter_level)
 {
 /* Set above_row buffer to 127 for decoding first MB row */
        memset(pbi->mt_yabove_row[0] + VP8BORDERINPIXELS-1, 127, yv12_fb_new->y_width + 5);
        memset(pbi->mt_uabove_row[0] + (VP8BORDERINPIXELS>>1)-1, 127, (yv12_fb_new->y_width>>1) +5);
        memset(pbi->mt_vabove_row[0] + (VP8BORDERINPIXELS>>1)-1, 127, (yv12_fb_new->y_width>>1) +5);

 for (j=1; j<pc->mb_rows; j++)
 {
            memset(pbi->mt_yabove_row[j] + VP8BORDERINPIXELS-1, (unsigned char)129, 1);
            memset(pbi->mt_uabove_row[j] + (VP8BORDERINPIXELS>>1)-1, (unsigned char)129, 1);
            memset(pbi->mt_vabove_row[j] + (VP8BORDERINPIXELS>>1)-1, (unsigned char)129, 1);
 }

 /* Set left_col to 129 initially */
 for (j=0; j<pc->mb_rows; j++)
 {
            memset(pbi->mt_yleft_col[j], (unsigned char)129, 16);
            memset(pbi->mt_uleft_col[j], (unsigned char)129, 8);
            memset(pbi->mt_vleft_col[j], (unsigned char)129, 8);
 }

 /* Initialize the loop filter for this frame. */
        vp8_loop_filter_frame_init(pc, &pbi->mb, filter_level);
 }
 else
        vp8_setup_intra_recon_top_line(yv12_fb_new);

    setup_decoding_thread_data(pbi, xd, pbi->mb_row_di, pbi->decoding_thread_count);

 for (i = 0; i < pbi->decoding_thread_count; i++)
        sem_post(&pbi->h_event_start_decoding[i]);

    mt_decode_mb_rows(pbi, xd, 0);

    sem_wait(&pbi->h_event_end_decoding); /* add back for each frame */
}

int vp8dx_get_raw_frame(VP8D_COMP *pbi, YV12_BUFFER_CONFIG *sd, int64_t *time_stamp, int64_t *time_end_stamp, vp8_ppflags_t *flags)
{
 int ret = -1;

 if (pbi->ready_for_new_data == 1)
 return ret;

 /* ie no raw frame to show!!! */
 if (pbi->common.show_frame == 0)
 return ret;

    pbi->ready_for_new_data = 1;
 *time_stamp = pbi->last_time_stamp;
 *time_end_stamp = 0;

#if CONFIG_POSTPROC
    ret = vp8_post_proc_frame(&pbi->common, sd, flags);
#else
 (void)flags;

 if (pbi->common.frame_to_show)
 {
 *sd = *pbi->common.frame_to_show;
        sd->y_width = pbi->common.Width;
        sd->y_height = pbi->common.Height;
        sd->uv_height = pbi->common.Height / 2;
        ret = 0;
 }
 else
 {
        ret = -1;
 }

#endif /*!CONFIG_POSTPROC*/
    vp8_clear_system_state();
 return ret;
}

static void init_frame(VP8D_COMP *pbi)
{
    VP8_COMMON *const pc = & pbi->common;
    MACROBLOCKD *const xd  = & pbi->mb;

 if (pc->frame_type == KEY_FRAME)
 {
 /* Various keyframe initializations */
        memcpy(pc->fc.mvc, vp8_default_mv_context, sizeof(vp8_default_mv_context));

        vp8_init_mbmode_probs(pc);

        vp8_default_coef_probs(pc);

 /* reset the segment feature data to 0 with delta coding (Default state). */
        memset(xd->segment_feature_data, 0, sizeof(xd->segment_feature_data));
        xd->mb_segement_abs_delta = SEGMENT_DELTADATA;

 /* reset the mode ref deltasa for loop filter */
        memset(xd->ref_lf_deltas, 0, sizeof(xd->ref_lf_deltas));
        memset(xd->mode_lf_deltas, 0, sizeof(xd->mode_lf_deltas));

 /* All buffers are implicitly updated on key frames. */
        pc->refresh_golden_frame = 1;
        pc->refresh_alt_ref_frame = 1;
        pc->copy_buffer_to_gf = 0;
        pc->copy_buffer_to_arf = 0;

 /* Note that Golden and Altref modes cannot be used on a key frame so
         * ref_frame_sign_bias[] is undefined and meaningless
         */
        pc->ref_frame_sign_bias[GOLDEN_FRAME] = 0;
        pc->ref_frame_sign_bias[ALTREF_FRAME] = 0;
 }
 else
 {
 /* To enable choice of different interploation filters */
 if (!pc->use_bilinear_mc_filter)
 {
            xd->subpixel_predict        = vp8_sixtap_predict4x4;
            xd->subpixel_predict8x4     = vp8_sixtap_predict8x4;
            xd->subpixel_predict8x8     = vp8_sixtap_predict8x8;
            xd->subpixel_predict16x16   = vp8_sixtap_predict16x16;
 }
 else
 {
            xd->subpixel_predict        = vp8_bilinear_predict4x4;
            xd->subpixel_predict8x4     = vp8_bilinear_predict8x4;
            xd->subpixel_predict8x8     = vp8_bilinear_predict8x8;
            xd->subpixel_predict16x16   = vp8_bilinear_predict16x16;
 }

 if (pbi->decoded_key_frame && pbi->ec_enabled && !pbi->ec_active)
            pbi->ec_active = 1;
 }

    xd->left_context = &pc->left_context;
    xd->mode_info_context = pc->mi;
    xd->frame_type = pc->frame_type;
    xd->mode_info_context->mbmi.mode = DC_PRED;
    xd->mode_info_stride = pc->mode_info_stride;
    xd->corrupted = 0; /* init without corruption */

    xd->fullpixel_mask = 0xffffffff;
 if(pc->full_pixel)
        xd->fullpixel_mask = 0xfffffff8;

}

static void remove_decompressor(VP8D_COMP *pbi)
{
#if CONFIG_ERROR_CONCEALMENT
    vp8_de_alloc_overlap_lists(pbi);
#endif
    vp8_remove_common(&pbi->common);
    vpx_free(pbi);
}

int vp8dx_receive_compressed_data(VP8D_COMP *pbi, size_t size,
 const uint8_t *source,
 int64_t time_stamp)
{
    VP8_COMMON *cm = &pbi->common;
 int retcode = -1;
 (void)size;
 (void)source;

    pbi->common.error.error_code = VPX_CODEC_OK;

    retcode = check_fragments_for_errors(pbi);
 if(retcode <= 0)
 return retcode;

    cm->new_fb_idx = get_free_fb (cm);

 /* setup reference frames for vp8_decode_frame */
    pbi->dec_fb_ref[INTRA_FRAME] = &cm->yv12_fb[cm->new_fb_idx];
    pbi->dec_fb_ref[LAST_FRAME] = &cm->yv12_fb[cm->lst_fb_idx];
    pbi->dec_fb_ref[GOLDEN_FRAME] = &cm->yv12_fb[cm->gld_fb_idx];
    pbi->dec_fb_ref[ALTREF_FRAME] = &cm->yv12_fb[cm->alt_fb_idx];

 if (setjmp(pbi->common.error.jmp))
 {
 /* We do not know if the missing frame(s) was supposed to update
        * any of the reference buffers, but we act conservative and
        * mark only the last buffer as corrupted.
        */
        cm->yv12_fb[cm->lst_fb_idx].corrupted = 1;

 
         if (cm->fb_idx_ref_cnt[cm->new_fb_idx] > 0)
           cm->fb_idx_ref_cnt[cm->new_fb_idx]--;
         goto decode_exit;
     }
 
    pbi->common.error.setjmp = 1;

    retcode = vp8_decode_frame(pbi);

 if (retcode < 0)
 {
 if (cm->fb_idx_ref_cnt[cm->new_fb_idx] > 0)
          cm->fb_idx_ref_cnt[cm->new_fb_idx]--;

        pbi->common.error.error_code = VPX_CODEC_ERROR;
 goto decode_exit;
 }

 if (swap_frame_buffers (cm))
 {
        pbi->common.error.error_code = VPX_CODEC_ERROR;
 goto decode_exit;
 }

    vp8_clear_system_state();

 if (cm->show_frame)
 {
        cm->current_video_frame++;
        cm->show_frame_mi = cm->mi;
 }

 #if CONFIG_ERROR_CONCEALMENT
 /* swap the mode infos to storage for future error concealment */
 if (pbi->ec_enabled && pbi->common.prev_mi)
 {
        MODE_INFO* tmp = pbi->common.prev_mi;
 int row, col;
        pbi->common.prev_mi = pbi->common.mi;
        pbi->common.mi = tmp;

 /* Propagate the segment_ids to the next frame */
 for (row = 0; row < pbi->common.mb_rows; ++row)
 {
 for (col = 0; col < pbi->common.mb_cols; ++col)
 {
 const int i = row*pbi->common.mode_info_stride + col;
                pbi->common.mi[i].mbmi.segment_id =
                        pbi->common.prev_mi[i].mbmi.segment_id;
 }
 }
 }
#endif

    pbi->ready_for_new_data = 0;
    pbi->last_time_stamp = time_stamp;

decode_exit:
    pbi->common.error.setjmp = 0;
    vp8_clear_system_state();
 return retcode;
}

void vp8cx_init_de_quantizer(VP8D_COMP *pbi)
{
 int Q;
    VP8_COMMON *const pc = & pbi->common;

 for (Q = 0; Q < QINDEX_RANGE; Q++)
 {
        pc->Y1dequant[Q][0] = (short)vp8_dc_quant(Q, pc->y1dc_delta_q);
        pc->Y2dequant[Q][0] = (short)vp8_dc2quant(Q, pc->y2dc_delta_q);
        pc->UVdequant[Q][0] = (short)vp8_dc_uv_quant(Q, pc->uvdc_delta_q);

        pc->Y1dequant[Q][1] = (short)vp8_ac_yquant(Q);
        pc->Y2dequant[Q][1] = (short)vp8_ac2quant(Q, pc->y2ac_delta_q);
        pc->UVdequant[Q][1] = (short)vp8_ac_uv_quant(Q, pc->uvac_delta_q);
 }
}
