val_get_mic_args(
    OM_uint32 *minor_status,
    gss_ctx_id_t context_handle,
    gss_qop_t qop_req,
    gss_buffer_t message_buffer,
    gss_buffer_t msg_token)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    if (msg_token != GSS_C_NO_BUFFER) {
	msg_token->value = NULL;
	msg_token->length = 0;
    }

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (message_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_READ);

    if (msg_token == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    return (GSS_S_COMPLETE);
}

gss_complete_auth_token (OM_uint32 *minor_status,
	                 const gss_ctx_id_t context_handle,
	                 gss_buffer_t input_message_buffer)
{
    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    if (context_handle == GSS_C_NO_CONTEXT)
	return GSS_S_NO_CONTEXT;

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech != NULL) {
	if (mech->gss_complete_auth_token != NULL) {
	    status = mech->gss_complete_auth_token(minor_status,
						   ctx->internal_ctx_id,
						   input_message_buffer);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else
	    status = GSS_S_COMPLETE;
    } else
	status = GSS_S_BAD_MECH;

    return status;
}

gssint_unwrap_aead (gss_mechanism mech,
		    OM_uint32 *minor_status,
		    gss_union_ctx_id_t ctx,
		    gss_buffer_t input_message_buffer,
		    gss_buffer_t input_assoc_buffer,
		    gss_buffer_t output_payload_buffer,
		    int *conf_state,
		    gss_qop_t *qop_state)
{
    OM_uint32		    status;

    assert(mech != NULL);
    assert(ctx != NULL);

 /* EXPORT DELETE START */

    if (mech->gss_unwrap_aead) {
	status = mech->gss_unwrap_aead(minor_status,
				       ctx->internal_ctx_id,
				       input_message_buffer,
				       input_assoc_buffer,
				       output_payload_buffer,
				       conf_state,
				       qop_state);
	if (status != GSS_S_COMPLETE)
	    map_error(minor_status, mech);
    } else if (mech->gss_unwrap_iov) {
	status = gssint_unwrap_aead_iov_shim(mech,
					     minor_status,
					     ctx->internal_ctx_id,
					     input_message_buffer,
					     input_assoc_buffer,
					     output_payload_buffer,
					     conf_state,
					     qop_state);
    } else
	status = GSS_S_UNAVAILABLE;
 /* EXPORT DELETE END */

    return (status);
}

gss_wrap_iov_length (minor_status,
                     context_handle,
                     conf_req_flag,
                     qop_req,
                     conf_state,
                     iov,
                     iov_count)
OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
int			conf_req_flag;
gss_qop_t		qop_req;
int *			conf_state;
gss_iov_buffer_desc  *	iov;
int			iov_count;
{
 /* EXPORT DELETE START */

    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    status = val_wrap_iov_args(minor_status, context_handle,
			       conf_req_flag, qop_req,
			       conf_state, iov, iov_count);
    if (status != GSS_S_COMPLETE)
	return (status);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {
	if (mech->gss_wrap_iov_length) {
	    status = mech->gss_wrap_iov_length(
					      minor_status,
					      ctx->internal_ctx_id,
					      conf_req_flag,
					      qop_req,
					      conf_state,
					      iov,
					      iov_count);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else
	    status = GSS_S_UNAVAILABLE;

	return(status);
    }
 /* EXPORT DELETE END */

    return (GSS_S_BAD_MECH);
}

gss_unwrap (minor_status,
            context_handle,
            input_message_buffer,
            output_message_buffer,
            conf_state,
            qop_state)

OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
gss_buffer_t		input_message_buffer;
gss_buffer_t		output_message_buffer;
int *			conf_state;
gss_qop_t *		qop_state;

{
/* EXPORT DELETE START */
    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    if (minor_status != NULL)
	*minor_status = 0;

    if (output_message_buffer != GSS_C_NO_BUFFER) {
	output_message_buffer->length = 0;
	output_message_buffer->value = NULL;
    }

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (input_message_buffer == GSS_C_NO_BUFFER ||
	GSS_EMPTY_BUFFER(input_message_buffer))

	return (GSS_S_CALL_INACCESSIBLE_READ);

    if (output_message_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    /*
     * select the approprate underlying mechanism routine and
      * call it.
      */
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {
	if (mech->gss_unwrap) {
	    status = mech->gss_unwrap(minor_status,
				      ctx->internal_ctx_id,
				      input_message_buffer,
				      output_message_buffer,
				      conf_state,
				      qop_state);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else if (mech->gss_unwrap_aead || mech->gss_unwrap_iov) {
	    status = gssint_unwrap_aead(mech,
					minor_status,
					ctx,
					input_message_buffer,
					GSS_C_NO_BUFFER,
					output_message_buffer,
					conf_state,
					(gss_qop_t *)qop_state);
	} else
	    status = GSS_S_UNAVAILABLE;

	return(status);
    }

/* EXPORT DELETE END */

    return (GSS_S_BAD_MECH);
}

gss_unseal (minor_status,
            context_handle,
            input_message_buffer,
            output_message_buffer,
            conf_state,
            qop_state)

OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
gss_buffer_t		input_message_buffer;
gss_buffer_t		output_message_buffer;
int *			conf_state;
int *			qop_state;

{
    return (gss_unwrap(minor_status, context_handle,
		       input_message_buffer,
		       output_message_buffer, conf_state, (gss_qop_t *) qop_state));
}

val_unwrap_aead_args(
    OM_uint32 *minor_status,
    gss_ctx_id_t context_handle,
    gss_buffer_t input_message_buffer,
    gss_buffer_t input_assoc_buffer,
    gss_buffer_t output_payload_buffer,
    int *conf_state,
    gss_qop_t *qop_state)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (input_message_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_READ);

    if (output_payload_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    return (GSS_S_COMPLETE);
}

val_init_sec_ctx_args(
    OM_uint32 *minor_status,
    gss_cred_id_t claimant_cred_handle,
    gss_ctx_id_t *context_handle,
    gss_name_t target_name,
    gss_OID req_mech_type,
    OM_uint32 req_flags,
    OM_uint32 time_req,
    gss_channel_bindings_t input_chan_bindings,
    gss_buffer_t input_token,
    gss_OID *actual_mech_type,
    gss_buffer_t output_token,
    OM_uint32 *ret_flags,
    OM_uint32 *time_rec)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    if (actual_mech_type != NULL)
	*actual_mech_type = GSS_C_NO_OID;

    if (output_token != GSS_C_NO_BUFFER) {
	output_token->length = 0;
	output_token->value = NULL;
    }

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE | GSS_S_NO_CONTEXT);

    if (target_name == NULL)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_BAD_NAME);

    if (output_token == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    return (GSS_S_COMPLETE);
}

gss_verify (minor_status,
            context_handle,
            message_buffer,
            token_buffer,
            qop_state)

OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
gss_buffer_t		message_buffer;
gss_buffer_t		token_buffer;
int *			qop_state;

{
	return (gss_verify_mic(minor_status, context_handle,
			       message_buffer, token_buffer,
			       (gss_qop_t *) qop_state));
}

val_unwrap_iov_args(
    OM_uint32 *minor_status,
    gss_ctx_id_t context_handle,
    int *conf_state,
    gss_qop_t *qop_state,
    gss_iov_buffer_desc *iov,
    int iov_count)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (iov == GSS_C_NO_IOV_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_READ);

    return (GSS_S_COMPLETE);
}

gss_unwrap_aead (minor_status,
                 context_handle,
		 input_message_buffer,
		 input_assoc_buffer,
		 output_payload_buffer,
                 conf_state,
                 qop_state)
OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
gss_buffer_t		input_message_buffer;
gss_buffer_t		input_assoc_buffer;
gss_buffer_t		output_payload_buffer;
int 			*conf_state;
gss_qop_t		*qop_state;
{

    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    status = val_unwrap_aead_args(minor_status, context_handle,
				  input_message_buffer, input_assoc_buffer,
				  output_payload_buffer,
				  conf_state, qop_state);
    if (status != GSS_S_COMPLETE)
	return (status);

    /*
     * select the approprate underlying mechanism routine and
      * call it.
      */
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (!mech)
	return (GSS_S_BAD_MECH);

    return gssint_unwrap_aead(mech, minor_status, ctx,
			      input_message_buffer, input_assoc_buffer,
			      output_payload_buffer, conf_state, qop_state);
}

val_del_sec_ctx_args(
    OM_uint32 *minor_status,
    gss_ctx_id_t *context_handle,
    gss_buffer_t output_token)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    if (output_token != GSS_C_NO_BUFFER) {
	output_token->length = 0;
	output_token->value = NULL;
    }

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == NULL || *context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_WRITE | GSS_S_NO_CONTEXT);

    return (GSS_S_COMPLETE);
}

val_wrap_aead_args(
    OM_uint32 *minor_status,
    gss_ctx_id_t context_handle,
    int conf_req_flag,
    gss_qop_t qop_req,
    gss_buffer_t input_assoc_buffer,
    gss_buffer_t input_payload_buffer,
    int *conf_state,
    gss_buffer_t output_message_buffer)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (input_payload_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_READ);

    if (output_message_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    return (GSS_S_COMPLETE);
}

val_inq_ctx_args(
    OM_uint32 *minor_status,
    gss_ctx_id_t context_handle,
    gss_name_t *src_name,
    gss_name_t *targ_name,
    OM_uint32 *lifetime_rec,
    gss_OID *mech_type,
    OM_uint32 *ctx_flags,
    int *locally_initiated,
    int *opened)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    if (src_name != NULL)
	*src_name = GSS_C_NO_NAME;

    if (targ_name != NULL)
	*targ_name = GSS_C_NO_NAME;

    if (mech_type != NULL)
	*mech_type = GSS_C_NO_OID;

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    return (GSS_S_COMPLETE);
}

gss_accept_sec_context (minor_status,
context_handle,
verifier_cred_handle,
input_token_buffer,
input_chan_bindings,
src_name,
mech_type,
output_token,
ret_flags,
time_rec,
d_cred)

OM_uint32 *		minor_status;
gss_ctx_id_t *		context_handle;
gss_cred_id_t		verifier_cred_handle;
gss_buffer_t		input_token_buffer;
gss_channel_bindings_t	input_chan_bindings;
gss_name_t *		src_name;
gss_OID *		mech_type;
gss_buffer_t		output_token;
OM_uint32 *		ret_flags;
OM_uint32 *		time_rec;
gss_cred_id_t *		d_cred;

{
OM_uint32		status, temp_status, temp_minor_status;
OM_uint32		temp_ret_flags = 0;
gss_union_ctx_id_t	union_ctx_id = NULL;
gss_cred_id_t	input_cred_handle = GSS_C_NO_CREDENTIAL;
gss_cred_id_t	tmp_d_cred = GSS_C_NO_CREDENTIAL;
gss_name_t		internal_name = GSS_C_NO_NAME;
gss_name_t		tmp_src_name = GSS_C_NO_NAME;
gss_OID_desc	token_mech_type_desc;
gss_OID		token_mech_type = &token_mech_type_desc;
gss_OID		actual_mech = GSS_C_NO_OID;
gss_OID		selected_mech = GSS_C_NO_OID;
gss_OID		public_mech;
gss_mechanism	mech = NULL;
gss_union_cred_t	uc;
int			i;

status = val_acc_sec_ctx_args(minor_status,
context_handle,
verifier_cred_handle,
input_token_buffer,
input_chan_bindings,
src_name,
mech_type,
output_token,
ret_flags,
time_rec,
d_cred);
if (status != GSS_S_COMPLETE)
return (status);

/*
* if context_handle is GSS_C_NO_CONTEXT, allocate a union context
* descriptor to hold the mech type information as well as the
* underlying mechanism context handle. Otherwise, cast the
* value of *context_handle to the union context variable.
*/

if(*context_handle == GSS_C_NO_CONTEXT) {

if (input_token_buffer == GSS_C_NO_BUFFER)
return (GSS_S_CALL_INACCESSIBLE_READ);

/* Get the token mech type */
status = gssint_get_mech_type(token_mech_type, input_token_buffer);
if (status)
return status;

/*
* An interposer calling back into the mechglue can't pass in a special
* mech, so we have to recognize it using verifier_cred_handle.  Use
* the mechanism for which we have matching creds, if available.
*/
if (verifier_cred_handle != GSS_C_NO_CREDENTIAL) {
uc = (gss_union_cred_t)verifier_cred_handle;
for (i = 0; i < uc->count; i++) {
public_mech = gssint_get_public_oid(&uc->mechs_array[i]);
if (public_mech && g_OID_equal(token_mech_type, public_mech)) {
selected_mech = &uc->mechs_array[i];
break;
}
}
}

if (selected_mech == GSS_C_NO_OID) {
status = gssint_select_mech_type(minor_status, token_mech_type,
&selected_mech);
if (status)
return status;
}

} else {
union_ctx_id = (gss_union_ctx_id_t)*context_handle;
selected_mech = union_ctx_id->mech_type;
}

/* Now create a new context if we didn't get one. */
if (*context_handle == GSS_C_NO_CONTEXT) {
status = GSS_S_FAILURE;
union_ctx_id = (gss_union_ctx_id_t)
malloc(sizeof(gss_union_ctx_id_desc));
if (!union_ctx_id)
return (GSS_S_FAILURE);

union_ctx_id->loopback = union_ctx_id;
union_ctx_id->internal_ctx_id = GSS_C_NO_CONTEXT;
status = generic_gss_copy_oid(&temp_minor_status, selected_mech,
&union_ctx_id->mech_type);
if (status != GSS_S_COMPLETE) {
free(union_ctx_id);
return (status);
}
	/* set the new context handle to caller's data *
	*context_handle = (gss_ctx_id_t)union_ctx_id;
}

/*
* get the appropriate cred handle from the union cred struct.
*/
if (verifier_cred_handle != GSS_C_NO_CREDENTIAL) {
input_cred_handle =
gssint_get_mechanism_cred((gss_union_cred_t)verifier_cred_handle,
selected_mech);
if (input_cred_handle == GSS_C_NO_CREDENTIAL) {
/* verifier credential specified but no acceptor credential found */
status = GSS_S_NO_CRED;
goto error_out;
}
} else if (!allow_mech_by_default(selected_mech)) {
status = GSS_S_NO_CRED;
goto error_out;
}

/*
* now select the approprate underlying mechanism routine and
* call it.
*/

mech = gssint_get_mechanism(selected_mech);
if (mech && mech->gss_accept_sec_context) {

status = mech->gss_accept_sec_context(minor_status,
&union_ctx_id->internal_ctx_id,
input_cred_handle,
input_token_buffer,
input_chan_bindings,
src_name ? &internal_name : NULL,
&actual_mech,
output_token,
&temp_ret_flags,
time_rec,
d_cred ? &tmp_d_cred : NULL);

/* If there's more work to do, keep going... */
	    if (status == GSS_S_CONTINUE_NEEDED)
return GSS_S_CONTINUE_NEEDED;

/* if the call failed, return with failure */
if (status != GSS_S_COMPLETE) {
map_error(minor_status, mech);
goto error_out;
}

/*
* if src_name is non-NULL,
* convert internal_name into a union name equivalent
* First call the mechanism specific display_name()
* then call gss_import_name() to create
* the union name struct cast to src_name
*/
if (src_name != NULL) {
if (internal_name != GSS_C_NO_NAME) {
/* consumes internal_name regardless of success */
temp_status = gssint_convert_name_to_union_name(
&temp_minor_status, mech,
internal_name, &tmp_src_name);
if (temp_status != GSS_S_COMPLETE) {
status = temp_status;
*minor_status = temp_minor_status;
map_error(minor_status, mech);
if (output_token->length)
(void) gss_release_buffer(&temp_minor_status,
output_token);
goto error_out;
}
*src_name = tmp_src_name;
} else
*src_name = GSS_C_NO_NAME;
}

#define g_OID_prefix_equal(o1, o2) \
(((o1)->length >= (o2)->length) && \
(memcmp((o1)->elements, (o2)->elements, (o2)->length) == 0))

/* Ensure we're returning correct creds format */
if ((temp_ret_flags & GSS_C_DELEG_FLAG) &&
tmp_d_cred != GSS_C_NO_CREDENTIAL) {
public_mech = gssint_get_public_oid(selected_mech);
if (actual_mech != GSS_C_NO_OID &&
public_mech != GSS_C_NO_OID &&
!g_OID_prefix_equal(actual_mech, public_mech)) {
*d_cred = tmp_d_cred; /* unwrapped pseudo-mech */
} else {
gss_union_cred_t d_u_cred = NULL;

d_u_cred = malloc(sizeof (gss_union_cred_desc));
if (d_u_cred == NULL) {
status = GSS_S_FAILURE;
goto error_out;
}
(void) memset(d_u_cred, 0, sizeof (gss_union_cred_desc));

d_u_cred->count = 1;

status = generic_gss_copy_oid(&temp_minor_status,
selected_mech,
&d_u_cred->mechs_array);

if (status != GSS_S_COMPLETE) {
free(d_u_cred);
goto error_out;
}

d_u_cred->cred_array = malloc(sizeof(gss_cred_id_t));
if (d_u_cred->cred_array != NULL) {
d_u_cred->cred_array[0] = tmp_d_cred;
} else {
free(d_u_cred);
status = GSS_S_FAILURE;
goto error_out;
}

d_u_cred->loopback = d_u_cred;
*d_cred = (gss_cred_id_t)d_u_cred;
}
}

if (mech_type != NULL)
*mech_type = gssint_get_public_oid(actual_mech);
if (ret_flags != NULL)
*ret_flags = temp_ret_flags;
	    return	(status);
} else {

status = GSS_S_BAD_MECH;
}

error_out:
    if (union_ctx_id) {
if (union_ctx_id->mech_type) {
if (union_ctx_id->mech_type->elements)
free(union_ctx_id->mech_type->elements);
free(union_ctx_id->mech_type);
}
if (union_ctx_id->internal_ctx_id && mech &&
mech->gss_delete_sec_context) {
mech->gss_delete_sec_context(&temp_minor_status,
&union_ctx_id->internal_ctx_id,
GSS_C_NO_BUFFER);
}
free(union_ctx_id);
	*context_handle = GSS_C_NO_CONTEXT;
}

if (src_name)
*src_name = GSS_C_NO_NAME;

if (tmp_src_name != GSS_C_NO_NAME)
(void) gss_release_buffer(&temp_minor_status,
(gss_buffer_t)tmp_src_name);

return (status);
}

gss_verify_mic (minor_status,
		context_handle,
		message_buffer,
		token_buffer,
		qop_state)

OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
gss_buffer_t		message_buffer;
gss_buffer_t		token_buffer;
gss_qop_t *		qop_state;

{
    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;


    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);
    *minor_status = 0;

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if ((message_buffer == GSS_C_NO_BUFFER) ||
	GSS_EMPTY_BUFFER(token_buffer))

	return (GSS_S_CALL_INACCESSIBLE_READ);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {
	if (mech->gss_verify_mic) {
	    status = mech->gss_verify_mic(
					  minor_status,
					  ctx->internal_ctx_id,
					  message_buffer,
					  token_buffer,
					  qop_state);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else
	    status = GSS_S_UNAVAILABLE;

	return(status);
    }

    return (GSS_S_BAD_MECH);
}

gss_wrap_size_limit(OM_uint32  *minor_status,
                    gss_ctx_id_t context_handle,
                    int conf_req_flag,
                    gss_qop_t qop_req, OM_uint32 req_output_size, OM_uint32 *max_input_size)
{
    gss_union_ctx_id_t  ctx;
    gss_mechanism       mech;
    OM_uint32           major_status;

    if (minor_status == NULL)
        return (GSS_S_CALL_INACCESSIBLE_WRITE);
    *minor_status = 0;

    if (context_handle == GSS_C_NO_CONTEXT)
        return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (max_input_size == NULL)
        return (GSS_S_CALL_INACCESSIBLE_WRITE);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (!mech)
        return (GSS_S_BAD_MECH);

    if (mech->gss_wrap_size_limit)
        major_status = mech->gss_wrap_size_limit(minor_status,
                                                 ctx->internal_ctx_id,
                                                 conf_req_flag, qop_req,
                                                 req_output_size, max_input_size);
    else if (mech->gss_wrap_iov_length)
        major_status = gssint_wrap_size_limit_iov_shim(mech, minor_status,
                                                       ctx->internal_ctx_id,
                                                       conf_req_flag, qop_req,
                                                       req_output_size, max_input_size);
    else
        major_status = GSS_S_UNAVAILABLE;
    if (major_status != GSS_S_COMPLETE)
        map_error(minor_status, mech);
    return major_status;
}

gss_wrap_aead (minor_status,
               context_handle,
               conf_req_flag,
               qop_req,
	       input_assoc_buffer,
	       input_payload_buffer,
               conf_state,
               output_message_buffer)
OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
int			conf_req_flag;
gss_qop_t		qop_req;
gss_buffer_t		input_assoc_buffer;
gss_buffer_t		input_payload_buffer;
int *			conf_state;
gss_buffer_t		output_message_buffer;
{
    OM_uint32		status;
    gss_mechanism	mech;
    gss_union_ctx_id_t	ctx;

    status = val_wrap_aead_args(minor_status, context_handle,
				conf_req_flag, qop_req,
				input_assoc_buffer, input_payload_buffer,
				conf_state, output_message_buffer);
    if (status != GSS_S_COMPLETE)
	return (status);

    /*
     * select the approprate underlying mechanism routine and
      * call it.
      */
     ctx = (gss_union_ctx_id_t)context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
     if (!mech)
 	return (GSS_S_BAD_MECH);

    return gssint_wrap_aead(mech, minor_status, ctx,
			    conf_req_flag, qop_req,
			    input_assoc_buffer, input_payload_buffer,
			    conf_state, output_message_buffer);
}

gss_process_context_token (minor_status,
                           context_handle,
                           token_buffer)

OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
gss_buffer_t		token_buffer;

{
    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);
    *minor_status = 0;

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (token_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_READ);

    if (GSS_EMPTY_BUFFER(token_buffer))
	return (GSS_S_CALL_INACCESSIBLE_READ);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {

	if (mech->gss_process_context_token) {
	    status = mech->gss_process_context_token(
						    minor_status,
						    ctx->internal_ctx_id,
						    token_buffer);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else
	    status = GSS_S_UNAVAILABLE;

	return(status);
    }

    return (GSS_S_BAD_MECH);
}

val_acc_sec_ctx_args(
    OM_uint32 *minor_status,
    gss_ctx_id_t *context_handle,
    gss_cred_id_t verifier_cred_handle,
    gss_buffer_t input_token_buffer,
    gss_channel_bindings_t input_chan_bindings,
    gss_name_t *src_name,
    gss_OID *mech_type,
    gss_buffer_t output_token,
    OM_uint32 *ret_flags,
    OM_uint32 *time_rec,
    gss_cred_id_t *d_cred)
{

    /* Initialize outputs. */

    if (minor_status != NULL)
	*minor_status = 0;

    if (src_name != NULL)
	*src_name = GSS_C_NO_NAME;

    if (mech_type != NULL)
	*mech_type = GSS_C_NO_OID;

    if (output_token != GSS_C_NO_BUFFER) {
	output_token->length = 0;
	output_token->value = NULL;
    }

    if (d_cred != NULL)
	*d_cred = GSS_C_NO_CREDENTIAL;

    /* Validate arguments. */

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (input_token_buffer == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_READ);

    if (output_token == GSS_C_NO_BUFFER)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    return (GSS_S_COMPLETE);
}

gss_release_iov_buffer (minor_status,
			iov,
			iov_count)
OM_uint32 *		minor_status;
gss_iov_buffer_desc *	iov;
int			iov_count;
{
    OM_uint32		status = GSS_S_COMPLETE;
    int			i;

    if (minor_status)
	*minor_status = 0;

    if (iov == GSS_C_NO_IOV_BUFFER)
	return GSS_S_COMPLETE;

    for (i = 0; i < iov_count; i++) {
	if (iov[i].type & GSS_IOV_BUFFER_FLAG_ALLOCATED) {
	    status = gss_release_buffer(minor_status, &iov[i].buffer);
	    if (status != GSS_S_COMPLETE)
		break;

	    iov[i].type &= ~(GSS_IOV_BUFFER_FLAG_ALLOCATED);
	}
    }

    return status;
}

gss_get_mic (minor_status,
	     context_handle,
	     qop_req,
	     message_buffer,
	     msg_token)

OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
gss_qop_t		qop_req;
gss_buffer_t		message_buffer;
gss_buffer_t		msg_token;

{
    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    status = val_get_mic_args(minor_status, context_handle,
			      qop_req, message_buffer, msg_token);
    if (status != GSS_S_COMPLETE)
	return (status);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {
	if (mech->gss_get_mic) {
	    status = mech->gss_get_mic(
				    minor_status,
				    ctx->internal_ctx_id,
				    qop_req,
				    message_buffer,
				    msg_token);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else
	    status = GSS_S_UNAVAILABLE;

	return(status);
    }

    return (GSS_S_BAD_MECH);
}

gss_wrap_iov (minor_status,
              context_handle,
              conf_req_flag,
              qop_req,
              conf_state,
              iov,
              iov_count)
OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
int			conf_req_flag;
gss_qop_t		qop_req;
int *			conf_state;
gss_iov_buffer_desc  *	iov;
int			iov_count;
{
 /* EXPORT DELETE START */

    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    status = val_wrap_iov_args(minor_status, context_handle,
			       conf_req_flag, qop_req,
			       conf_state, iov, iov_count);
    if (status != GSS_S_COMPLETE)
	return (status);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {
	if (mech->gss_wrap_iov) {
	    status = mech->gss_wrap_iov(
					minor_status,
					ctx->internal_ctx_id,
					conf_req_flag,
					qop_req,
					conf_state,
					iov,
					iov_count);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else
	    status = GSS_S_UNAVAILABLE;

	return(status);
    }
 /* EXPORT DELETE END */

    return (GSS_S_BAD_MECH);
}

gssint_wrap_aead_iov_shim(gss_mechanism mech,
			  OM_uint32 *minor_status,
			  gss_ctx_id_t context_handle,
			  int conf_req_flag,
			  gss_qop_t qop_req,
			  gss_buffer_t input_assoc_buffer,
			  gss_buffer_t input_payload_buffer,
			  int *conf_state,
			  gss_buffer_t output_message_buffer)
{
    gss_iov_buffer_desc	iov[5];
    OM_uint32		status;
    size_t		offset;
    int			i = 0, iov_count;

    /* HEADER | SIGN_ONLY_DATA | DATA | PADDING | TRAILER */

    iov[i].type = GSS_IOV_BUFFER_TYPE_HEADER;
    iov[i].buffer.value = NULL;
    iov[i].buffer.length = 0;
    i++;

    if (input_assoc_buffer != GSS_C_NO_BUFFER) {
	iov[i].type = GSS_IOV_BUFFER_TYPE_SIGN_ONLY;
	iov[i].buffer = *input_assoc_buffer;
	i++;
    }

    iov[i].type = GSS_IOV_BUFFER_TYPE_DATA;
    iov[i].buffer = *input_payload_buffer;
    i++;

    iov[i].type = GSS_IOV_BUFFER_TYPE_PADDING;
    iov[i].buffer.value = NULL;
    iov[i].buffer.length = 0;
    i++;

    iov[i].type = GSS_IOV_BUFFER_TYPE_TRAILER;
    iov[i].buffer.value = NULL;
    iov[i].buffer.length = 0;
    i++;

    iov_count = i;

    assert(mech->gss_wrap_iov_length);

    status = mech->gss_wrap_iov_length(minor_status, context_handle,
				       conf_req_flag, qop_req,
				       NULL, iov, iov_count);
    if (status != GSS_S_COMPLETE) {
	map_error(minor_status, mech);
	return status;
    }

    /* Format output token (does not include associated data) */
    for (i = 0, output_message_buffer->length = 0; i < iov_count; i++) {
	if (GSS_IOV_BUFFER_TYPE(iov[i].type) == GSS_IOV_BUFFER_TYPE_SIGN_ONLY)
	    continue;

	output_message_buffer->length += iov[i].buffer.length;
    }

    output_message_buffer->value = gssalloc_malloc(output_message_buffer->length);
    if (output_message_buffer->value == NULL) {
	*minor_status = ENOMEM;
	return GSS_S_FAILURE;
    }

    i = 0, offset = 0;

    /* HEADER */
    iov[i].buffer.value = (unsigned char *)output_message_buffer->value + offset;
    offset += iov[i].buffer.length;
    i++;

    /* SIGN_ONLY_DATA */
    if (input_assoc_buffer != GSS_C_NO_BUFFER)
	i++;

    /* DATA */
    iov[i].buffer.value = (unsigned char *)output_message_buffer->value + offset;
    offset += iov[i].buffer.length;

    memcpy(iov[i].buffer.value, input_payload_buffer->value, iov[i].buffer.length);
    i++;

    /* PADDING */
    iov[i].buffer.value = (unsigned char *)output_message_buffer->value + offset;
    offset += iov[i].buffer.length;
    i++;

    /* TRAILER */
    iov[i].buffer.value = (unsigned char *)output_message_buffer->value + offset;
    offset += iov[i].buffer.length;
    i++;

    assert(offset == output_message_buffer->length);

    assert(mech->gss_wrap_iov);

    status = mech->gss_wrap_iov(minor_status, context_handle,
				conf_req_flag, qop_req,
				conf_state, iov, iov_count);
    if (status != GSS_S_COMPLETE) {
	OM_uint32 minor;

	map_error(minor_status, mech);
	gss_release_buffer(&minor, output_message_buffer);
    }

    return status;
}

val_wrap_args(OM_uint32 *minor_status,
              gss_ctx_id_t context_handle,
              int conf_req_flag,
              gss_qop_t qop_req,
              gss_buffer_t input_message_buffer,
              int *conf_state,
              gss_buffer_t output_message_buffer)
{
    /* Initialize outputs. */

    if (minor_status != NULL)
        *minor_status = 0;

    if (output_message_buffer != GSS_C_NO_BUFFER) {
        output_message_buffer->length = 0;
        output_message_buffer->value = NULL;
    }

    /* Validate arguments. */

    if (minor_status == NULL)
        return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
        return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    if (input_message_buffer == GSS_C_NO_BUFFER)
        return (GSS_S_CALL_INACCESSIBLE_READ);

    if (output_message_buffer == GSS_C_NO_BUFFER)
        return (GSS_S_CALL_INACCESSIBLE_WRITE);

    return (GSS_S_COMPLETE);
}

gssint_wrap_aead (gss_mechanism mech,
		  OM_uint32 *minor_status,
		  gss_union_ctx_id_t ctx,
		  int conf_req_flag,
		  gss_qop_t qop_req,
		  gss_buffer_t input_assoc_buffer,
		  gss_buffer_t input_payload_buffer,
		  int *conf_state,
		  gss_buffer_t output_message_buffer)
{
 /* EXPORT DELETE START */
    OM_uint32		status;

    assert(ctx != NULL);
    assert(mech != NULL);

    if (mech->gss_wrap_aead) {
	status = mech->gss_wrap_aead(minor_status,
				     ctx->internal_ctx_id,
				     conf_req_flag,
				     qop_req,
				     input_assoc_buffer,
				     input_payload_buffer,
				     conf_state,
				     output_message_buffer);
	if (status != GSS_S_COMPLETE)
	    map_error(minor_status, mech);
    } else if (mech->gss_wrap_iov && mech->gss_wrap_iov_length) {
	status = gssint_wrap_aead_iov_shim(mech,
					   minor_status,
					   ctx->internal_ctx_id,
					   conf_req_flag,
					   qop_req,
					   input_assoc_buffer,
					   input_payload_buffer,
					   conf_state,
					   output_message_buffer);
    } else
	status = GSS_S_UNAVAILABLE;

 /* EXPORT DELETE END */

    return status;
}

gssint_wrap_size_limit_iov_shim(gss_mechanism mech,
                                OM_uint32 *minor_status,
                                gss_ctx_id_t context_handle,
                                int conf_req_flag,
                                gss_qop_t qop_req,
                                OM_uint32 req_output_size,
                                OM_uint32 *max_input_size)
{
    gss_iov_buffer_desc iov[4];
    OM_uint32           status;
    OM_uint32           ohlen;

    iov[0].type = GSS_IOV_BUFFER_TYPE_HEADER;
    iov[0].buffer.value = NULL;
    iov[0].buffer.length = 0;

    iov[1].type = GSS_IOV_BUFFER_TYPE_DATA;
    iov[1].buffer.length = req_output_size;
    iov[1].buffer.value = NULL;

    iov[2].type = GSS_IOV_BUFFER_TYPE_PADDING;
    iov[2].buffer.value = NULL;
    iov[2].buffer.length = 0;

    iov[3].type = GSS_IOV_BUFFER_TYPE_TRAILER;
    iov[3].buffer.value = NULL;
    iov[3].buffer.length = 0;

    assert(mech->gss_wrap_iov_length);

    status = mech->gss_wrap_iov_length(minor_status, context_handle,
                                       conf_req_flag, qop_req,
                                       NULL, iov,
                                       sizeof(iov)/sizeof(iov[0]));
    if (status != GSS_S_COMPLETE) {
        map_error(minor_status, mech);
        return status;
    }

    ohlen = iov[0].buffer.length + iov[3].buffer.length;

    if (iov[2].buffer.length == 0 && ohlen < req_output_size)
        *max_input_size = req_output_size - ohlen;
    else
        *max_input_size = 0;

    return GSS_S_COMPLETE;
}

gss_get_mic_iov_length(OM_uint32 *minor_status, gss_ctx_id_t context_handle,
		       gss_qop_t qop_req, gss_iov_buffer_desc *iov,
		       int iov_count)
{
    OM_uint32 status;
    gss_union_ctx_id_t ctx;
    gss_mechanism mech;

    status = val_wrap_iov_args(minor_status, context_handle, 0, qop_req, NULL,
			       iov, iov_count);
    if (status != GSS_S_COMPLETE)
	return status;
 
     /* Select the approprate underlying mechanism routine and call it. */
     ctx = (gss_union_ctx_id_t)context_handle;
     mech = gssint_get_mechanism(ctx->mech_type);
     if (mech == NULL)
 	return GSS_S_BAD_MECH;
    if (mech->gss_get_mic_iov_length == NULL)
	return GSS_S_UNAVAILABLE;
    status = mech->gss_get_mic_iov_length(minor_status, ctx->internal_ctx_id,
					  qop_req, iov, iov_count);
    if (status != GSS_S_COMPLETE)
	map_error(minor_status, mech);
    return status;
}

gss_get_mic_iov(OM_uint32 *minor_status, gss_ctx_id_t context_handle,
		gss_qop_t qop_req, gss_iov_buffer_desc *iov, int iov_count)
{
    OM_uint32 status;
    gss_union_ctx_id_t ctx;
    gss_mechanism mech;

    status = val_wrap_iov_args(minor_status, context_handle, 0, qop_req, NULL,
			       iov, iov_count);
    if (status != GSS_S_COMPLETE)
	return status;
 
     /* Select the approprate underlying mechanism routine and call it. */
     ctx = (gss_union_ctx_id_t)context_handle;
     mech = gssint_get_mechanism(ctx->mech_type);
     if (mech == NULL)
 	return GSS_S_BAD_MECH;
    if (mech->gss_get_mic_iov == NULL)
	return GSS_S_UNAVAILABLE;
    status = mech->gss_get_mic_iov(minor_status, ctx->internal_ctx_id, qop_req,
				   iov, iov_count);
    if (status != GSS_S_COMPLETE)
	map_error(minor_status, mech);
    return status;
}

gss_context_time (minor_status,
                  context_handle,
                  time_rec)

OM_uint32 *		minor_status;
gss_ctx_id_t		context_handle;
OM_uint32 *		time_rec;

{
    OM_uint32		status;
    gss_union_ctx_id_t	ctx;
    gss_mechanism	mech;

    if (minor_status == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);
    *minor_status = 0;

    if (time_rec == NULL)
	return (GSS_S_CALL_INACCESSIBLE_WRITE);

    if (context_handle == GSS_C_NO_CONTEXT)
	return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {

	if (mech->gss_context_time) {
	    status = mech->gss_context_time(
					    minor_status,
					    ctx->internal_ctx_id,
					    time_rec);
	    if (status != GSS_S_COMPLETE)
		map_error(minor_status, mech);
	} else
	    status = GSS_S_UNAVAILABLE;

	return(status);
    }

    return (GSS_S_BAD_MECH);
}

gss_wrap( OM_uint32 *minor_status,
          gss_ctx_id_t context_handle,
          int conf_req_flag,
          gss_qop_t qop_req,
          gss_buffer_t input_message_buffer,
          int *conf_state,
          gss_buffer_t output_message_buffer)
{

    /* EXPORT DELETE START */

    OM_uint32           status;
    gss_union_ctx_id_t  ctx;
    gss_mechanism       mech;

    status = val_wrap_args(minor_status, context_handle,
                           conf_req_flag, qop_req,
                           input_message_buffer, conf_state,
                           output_message_buffer);
    if (status != GSS_S_COMPLETE)
        return (status);

    /*
     * select the approprate underlying mechanism routine and
     * call it.
      */
 
     ctx = (gss_union_ctx_id_t) context_handle;
     mech = gssint_get_mechanism (ctx->mech_type);
 
     if (mech) {
        if (mech->gss_wrap) {
            status = mech->gss_wrap(minor_status,
                                    ctx->internal_ctx_id,
                                    conf_req_flag,
                                    qop_req,
                                    input_message_buffer,
                                    conf_state,
                                    output_message_buffer);
            if (status != GSS_S_COMPLETE)
                map_error(minor_status, mech);
        } else if (mech->gss_wrap_aead ||
                   (mech->gss_wrap_iov && mech->gss_wrap_iov_length)) {
            status = gssint_wrap_aead(mech,
                                      minor_status,
                                      ctx,
                                      conf_req_flag,
                                      (gss_qop_t)qop_req,
                                      GSS_C_NO_BUFFER,
                                      input_message_buffer,
                                      conf_state,
                                      output_message_buffer);
        } else
            status = GSS_S_UNAVAILABLE;

        return(status);
    }
    /* EXPORT DELETE END */

    return (GSS_S_BAD_MECH);
}

gss_init_sec_context (minor_status,
claimant_cred_handle,
context_handle,
target_name,
req_mech_type,
req_flags,
time_req,
input_chan_bindings,
input_token,
actual_mech_type,
output_token,
ret_flags,
time_rec)

OM_uint32 *		minor_status;
gss_cred_id_t		claimant_cred_handle;
gss_ctx_id_t *		context_handle;
gss_name_t		target_name;
gss_OID			req_mech_type;
OM_uint32		req_flags;
OM_uint32		time_req;
gss_channel_bindings_t	input_chan_bindings;
gss_buffer_t		input_token;
gss_OID *		actual_mech_type;
gss_buffer_t		output_token;
OM_uint32 *		ret_flags;
OM_uint32 *		time_rec;

{
OM_uint32		status, temp_minor_status;
gss_union_name_t	union_name;
gss_union_cred_t	union_cred;
gss_name_t		internal_name;
gss_union_ctx_id_t	union_ctx_id;
gss_OID		selected_mech;
gss_mechanism	mech;
gss_cred_id_t	input_cred_handle;

status = val_init_sec_ctx_args(minor_status,
claimant_cred_handle,
context_handle,
target_name,
req_mech_type,
req_flags,
time_req,
input_chan_bindings,
input_token,
actual_mech_type,
output_token,
ret_flags,
time_rec);
if (status != GSS_S_COMPLETE)
return (status);

status = gssint_select_mech_type(minor_status, req_mech_type,
&selected_mech);
if (status != GSS_S_COMPLETE)
return (status);

union_name = (gss_union_name_t)target_name;

/*
* obtain the gss mechanism information for the requested
* mechanism.  If mech_type is NULL, set it to the resultant
* mechanism
*/
mech = gssint_get_mechanism(selected_mech);
if (mech == NULL)
return (GSS_S_BAD_MECH);

if (mech->gss_init_sec_context == NULL)
return (GSS_S_UNAVAILABLE);

/*
* If target_name is mechanism_specific, then it must match the
* mech_type that we're about to use.  Otherwise, do an import on
* the external_name form of the target name.
*/
if (union_name->mech_type &&
g_OID_equal(union_name->mech_type, selected_mech)) {
internal_name = union_name->mech_name;
} else {
if ((status = gssint_import_internal_name(minor_status, selected_mech,
union_name,
&internal_name)) != GSS_S_COMPLETE)
return (status);
}

/*
* if context_handle is GSS_C_NO_CONTEXT, allocate a union context
* descriptor to hold the mech type information as well as the
* underlying mechanism context handle. Otherwise, cast the
* value of *context_handle to the union context variable.
*/

if(*context_handle == GSS_C_NO_CONTEXT) {
status = GSS_S_FAILURE;
union_ctx_id = (gss_union_ctx_id_t)
malloc(sizeof(gss_union_ctx_id_desc));
if (union_ctx_id == NULL)
goto end;

if (generic_gss_copy_oid(&temp_minor_status, selected_mech,
&union_ctx_id->mech_type) != GSS_S_COMPLETE) {
free(union_ctx_id);
goto end;
}

/* copy the supplied context handle */
union_ctx_id->internal_ctx_id = GSS_C_NO_CONTEXT;
    } else
union_ctx_id = (gss_union_ctx_id_t)*context_handle;

/*
* get the appropriate cred handle from the union cred struct.
* defaults to GSS_C_NO_CREDENTIAL if there is no cred, which will
* use the default credential.
*/
union_cred = (gss_union_cred_t) claimant_cred_handle;
input_cred_handle = gssint_get_mechanism_cred(union_cred, selected_mech);

/*
* now call the approprate underlying mechanism routine
*/

status = mech->gss_init_sec_context(
minor_status,
input_cred_handle,
&union_ctx_id->internal_ctx_id,
internal_name,
gssint_get_public_oid(selected_mech),
req_flags,
time_req,
input_chan_bindings,
input_token,
actual_mech_type,
output_token,
ret_flags,
time_rec);

if (status != GSS_S_COMPLETE && status != GSS_S_CONTINUE_NEEDED) {
/*
	 * The spec says the preferred method is to delete all context info on
	 * the first call to init, and on all subsequent calls make the caller
	 * responsible for calling gss_delete_sec_context.  However, if the
	 * mechanism decided to delete the internal context, we should also
	 * delete the union context.
*/
map_error(minor_status, mech);
	if (union_ctx_id->internal_ctx_id == GSS_C_NO_CONTEXT)
	    *context_handle = GSS_C_NO_CONTEXT;
if (*context_handle == GSS_C_NO_CONTEXT) {
free(union_ctx_id->mech_type->elements);
free(union_ctx_id->mech_type);
free(union_ctx_id);
}
} else if (*context_handle == GSS_C_NO_CONTEXT) {
union_ctx_id->loopback = union_ctx_id;
*context_handle = (gss_ctx_id_t)union_ctx_id;
}

end:
if (union_name->mech_name == NULL ||
union_name->mech_name != internal_name) {
(void) gssint_release_internal_name(&temp_minor_status,
selected_mech, &internal_name);
}

return(status);
}

gss_delete_sec_context (minor_status,
context_handle,
output_token)

OM_uint32 *		minor_status;
gss_ctx_id_t *		context_handle;
gss_buffer_t		output_token;

{
OM_uint32		status;
gss_union_ctx_id_t	ctx;

status = val_del_sec_ctx_args(minor_status, context_handle, output_token);
if (status != GSS_S_COMPLETE)
return (status);

/*
* select the approprate underlying mechanism routine and
* call it.
*/

ctx = (gss_union_ctx_id_t) *context_handle;
if (GSSINT_CHK_LOOP(ctx))
return (GSS_S_CALL_INACCESSIBLE_READ | GSS_S_NO_CONTEXT);

    status = gssint_delete_internal_sec_context(minor_status,
						ctx->mech_type,
						&ctx->internal_ctx_id,
						output_token);
    if (status)
	return status;

/* now free up the space for the union context structure */
free(ctx->mech_type->elements);
free(ctx->mech_type);
free(*context_handle);
*context_handle = GSS_C_NO_CONTEXT;

return (GSS_S_COMPLETE);
}
