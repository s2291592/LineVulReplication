void BaseAudioContext::Uninitialize() {
  DCHECK(IsMainThread());

  if (!IsDestinationInitialized())
    return;

  if (destination_node_)
    destination_node_->Handler().Uninitialize();

  GetDeferredTaskHandler().FinishTailProcessing();

  ReleaseActiveSourceNodes();

  RejectPendingResolvers();
  DidClose();

  DCHECK(listener_);
  listener_->WaitForHRTFDatabaseLoaderThreadCompletion();

  RecordAutoplayStatus();

  Clear();
}

void BaseAudioContext::Initialize() {
  if (IsDestinationInitialized())
    return;

  FFTFrame::Initialize();

  audio_worklet_ = AudioWorklet::Create(this);

  if (destination_node_) {
    destination_node_->Handler().Initialize();
    listener_ = AudioListener::Create(*this);
  }
}

bool MediaElementAudioSourceHandler::PassesCORSAccessCheck() {
  DCHECK(MediaElement());
  return (MediaElement()->GetWebMediaPlayer() &&
          MediaElement()->GetWebMediaPlayer()->DidPassCORSAccessCheck()) ||
         passes_current_src_cors_access_check_;
}

AutoplayPolicy::Type BaseAudioContext::GetAutoplayPolicy() const {
  if (RuntimeEnabledFeatures::AutoplayIgnoresWebAudioEnabled()) {
#if defined(OS_ANDROID)
    return AutoplayPolicy::Type::kUserGestureRequired;
#else
    return AutoplayPolicy::Type::kNoUserGestureRequired;
#endif
  }

  Document* document = GetDocument();
  DCHECK(document);
  return AutoplayPolicy::GetAutoplayPolicyForDocument(*document);
}

BaseAudioContext::~BaseAudioContext() {
  GetDeferredTaskHandler().ContextWillBeDestroyed();
  DCHECK(!active_source_nodes_.size());
  DCHECK(!is_resolving_resume_promises_);
  DCHECK(!resume_resolvers_.size());
  DCHECK(!autoplay_status_.has_value());
}

void BaseAudioContext::RecordAutoplayStatus() {
  if (!autoplay_status_.has_value())
    return;

  DEFINE_STATIC_LOCAL(
      EnumerationHistogram, autoplay_histogram,
      ("WebAudio.Autoplay", AutoplayStatus::kAutoplayStatusCount));
  DEFINE_STATIC_LOCAL(
      EnumerationHistogram, cross_origin_autoplay_histogram,
      ("WebAudio.Autoplay.CrossOrigin", AutoplayStatus::kAutoplayStatusCount));

  autoplay_histogram.Count(autoplay_status_.value());

  if (GetDocument()->GetFrame() &&
      GetDocument()->GetFrame()->IsCrossOriginSubframe()) {
    cross_origin_autoplay_histogram.Count(autoplay_status_.value());
  }

  autoplay_status_.reset();
}

bool MediaElementAudioSourceHandler::PassesCurrentSrcCORSAccessCheck(
    const KURL& current_src) {
  DCHECK(IsMainThread());
  return Context()->GetSecurityOrigin() &&
         Context()->GetSecurityOrigin()->CanRequest(current_src);
}

ScriptPromise BaseAudioContext::decodeAudioData(
    ScriptState* script_state,
    DOMArrayBuffer* audio_data,
    V8DecodeSuccessCallback* success_callback,
    V8DecodeErrorCallback* error_callback,
    ExceptionState& exception_state) {
  DCHECK(IsMainThread());
  DCHECK(audio_data);

  ScriptPromiseResolver* resolver = ScriptPromiseResolver::Create(script_state);
  ScriptPromise promise = resolver->Promise();

  float rate = IsContextClosed() ? ClosedContextSampleRate() : sampleRate();

  DCHECK_GT(rate, 0);

  v8::Isolate* isolate = script_state->GetIsolate();
  WTF::ArrayBufferContents buffer_contents;
  if (audio_data->IsNeuterable(isolate) &&
      audio_data->Transfer(isolate, buffer_contents)) {
    DOMArrayBuffer* audio = DOMArrayBuffer::Create(buffer_contents);

    decode_audio_resolvers_.insert(resolver);

    audio_decoder_.DecodeAsync(
        audio, rate, ToV8PersistentCallbackFunction(success_callback),
        ToV8PersistentCallbackFunction(error_callback), resolver, this);
  } else {
    DOMException* error = DOMException::Create(
        kDataCloneError, "Cannot decode detached ArrayBuffer");
    resolver->Reject(error);
    if (error_callback) {
      error_callback->InvokeAndReportException(this, error);
    }
  }

  return promise;
}

Document* BaseAudioContext::GetDocument() const {
  return ToDocument(GetExecutionContext());
}

void MediaElementAudioSourceNode::OnCurrentSrcChanged(const KURL& current_src) {
  GetMediaElementAudioSourceHandler().OnCurrentSrcChanged(current_src);
}

void MediaElementAudioSourceHandler::OnCurrentSrcChanged(
    const KURL& current_src) {
  DCHECK(IsMainThread());
  // Synchronize with process().
  Locker<MediaElementAudioSourceHandler> locker(*this);

  passes_current_src_cors_access_check_ =
      PassesCurrentSrcCORSAccessCheck(current_src);

  // Make a note if we need to print a console message and save the |curentSrc|
  // for use in the message.  Need to wait until later to print the message in
  // case HTMLMediaElement allows access.
  maybe_print_cors_message_ = !passes_current_src_cors_access_check_;
  current_src_string_ = current_src.GetString();
}

MediaElementAudioSourceNode::MediaElementAudioSourceNode(
    BaseAudioContext& context,
    HTMLMediaElement& media_element)
    : AudioNode(context) {
  SetHandler(MediaElementAudioSourceHandler::Create(*this, media_element));
}

void BaseAudioContext::RejectPendingResolvers() {
  DCHECK(IsMainThread());


  for (auto& resolver : resume_resolvers_) {
    resolver->Reject(DOMException::Create(kInvalidStateError,
                                          "Audio context is going away"));
  }
  resume_resolvers_.clear();
  is_resolving_resume_promises_ = false;

  RejectPendingDecodeAudioDataResolvers();
}

 void MediaElementAudioSourceNode::lock() {
   GetMediaElementAudioSourceHandler().lock();
 }

MediaStreamAudioDestinationNode* BaseAudioContext::createMediaStreamDestination(
    ExceptionState& exception_state) {
  DCHECK(IsMainThread());

  return MediaStreamAudioDestinationNode::Create(*this, 2, exception_state);
}

void BaseAudioContext::HandlePostRenderTasks() {
  DCHECK(IsAudioThread());

  if (TryLock()) {
    GetDeferredTaskHandler().BreakConnections();

    GetDeferredTaskHandler().HandleDeferredTasks();
    GetDeferredTaskHandler().RequestToDeleteHandlersOnMainThread();

    unlock();
  }
}

 void MediaElementAudioSourceHandler::SetFormat(size_t number_of_channels,
                                                float source_sample_rate) {
   if (number_of_channels != source_number_of_channels_ ||
       source_sample_rate != source_sample_rate_) {
     if (!number_of_channels ||
        number_of_channels > BaseAudioContext::MaxNumberOfChannels() ||
        !AudioUtilities::IsValidAudioBufferSampleRate(source_sample_rate)) {
      DLOG(ERROR) << "setFormat(" << number_of_channels << ", "
                  << source_sample_rate << ") - unhandled format change";
       Locker<MediaElementAudioSourceHandler> locker(*this);
       source_number_of_channels_ = 0;
       source_sample_rate_ = 0;
       return;
     }
 
     Locker<MediaElementAudioSourceHandler> locker(*this);
 
     source_number_of_channels_ = number_of_channels;
     source_sample_rate_ = source_sample_rate;
 
    if (source_sample_rate != Context()->sampleRate()) {
      double scale_factor = source_sample_rate / Context()->sampleRate();
      multi_channel_resampler_ = std::make_unique<MultiChannelResampler>(
          scale_factor, number_of_channels);
    } else {
      multi_channel_resampler_.reset();
    }

    {
      BaseAudioContext::GraphAutoLocker context_locker(Context());

      Output(0).SetNumberOfChannels(number_of_channels);
    }
   }
 }

void BaseAudioContext::StartRendering() {
  DCHECK(IsMainThread());
  DCHECK(destination_node_);
  DCHECK(IsAllowedToStart());

  if (context_state_ == kSuspended) {
    destination()->GetAudioDestinationHandler().StartRendering();
  }
}

MediaElementAudioSourceNode* MediaElementAudioSourceNode::Create(
    BaseAudioContext& context,
    HTMLMediaElement& media_element,
    ExceptionState& exception_state) {
  DCHECK(IsMainThread());

  if (context.IsContextClosed()) {
    context.ThrowExceptionForClosedState(exception_state);
    return nullptr;
  }

  if (media_element.AudioSourceNode()) {
    exception_state.ThrowDOMException(kInvalidStateError,
                                      "HTMLMediaElement already connected "
                                      "previously to a different "
                                      "MediaElementSourceNode.");
    return nullptr;
  }

  MediaElementAudioSourceNode* node =
      new MediaElementAudioSourceNode(context, media_element);

  if (node) {
    media_element.SetAudioSourceNode(node);
    context.NotifySourceNodeStartedProcessing(node);
  }

  return node;
}

void MediaElementAudioSourceNode::SetFormat(size_t number_of_channels,
                                            float sample_rate) {
  GetMediaElementAudioSourceHandler().SetFormat(number_of_channels,
                                                 sample_rate);
 }

void BaseAudioContext::NotifyStateChange() {
  DispatchEvent(Event::Create(EventTypeNames::statechange));
}

void BaseAudioContext::ThrowExceptionForClosedState(
    ExceptionState& exception_state) {
  exception_state.ThrowDOMException(kInvalidStateError,
                                    "AudioContext has been closed.");
}

void BaseAudioContext::MaybeUnlockUserGesture() {
  if (!user_gesture_required_ || !AreAutoplayRequirementsFulfilled())
    return;

  DCHECK(!autoplay_status_.has_value() ||
         autoplay_status_ != AutoplayStatus::kAutoplayStatusSucceeded);

  user_gesture_required_ = false;
  autoplay_status_ = AutoplayStatus::kAutoplayStatusSucceeded;
}

void BaseAudioContext::HandleDecodeAudioData(
    AudioBuffer* audio_buffer,
    ScriptPromiseResolver* resolver,
    V8PersistentCallbackFunction<V8DecodeSuccessCallback>* success_callback,
    V8PersistentCallbackFunction<V8DecodeErrorCallback>* error_callback) {
  DCHECK(IsMainThread());

  if (audio_buffer) {
    resolver->Resolve(audio_buffer);
    if (success_callback)
      success_callback->InvokeAndReportException(this, audio_buffer);
  } else {
    DOMException* error =
        DOMException::Create(kEncodingError, "Unable to decode audio data");
    resolver->Reject(error);
    if (error_callback)
      error_callback->InvokeAndReportException(this, error);
  }

  DCHECK(decode_audio_resolvers_.Contains(resolver));
  decode_audio_resolvers_.erase(resolver);
}

void BaseAudioContext::ScheduleMainThreadCleanup() {
  if (has_posted_cleanup_task_)
    return;
  PostCrossThreadTask(
      *Platform::Current()->MainThread()->GetTaskRunner(), FROM_HERE,
      CrossThreadBind(&BaseAudioContext::PerformCleanupOnMainThread,
                      WrapCrossThreadPersistent(this)));
  has_posted_cleanup_task_ = true;
}

MediaElementAudioSourceHandler::MediaElementAudioSourceHandler(
AudioNode& node,
HTMLMediaElement& media_element)
: AudioHandler(kNodeTypeMediaElementAudioSource,
node,
node.context()->sampleRate()),
media_element_(media_element),
source_number_of_channels_(0),
source_sample_rate_(0),
      passes_current_src_cors_access_check_(
          PassesCurrentSrcCORSAccessCheck(media_element.currentSrc())),
      maybe_print_cors_message_(!passes_current_src_cors_access_check_),
      current_src_string_(media_element.currentSrc().GetString()) {
DCHECK(IsMainThread());
// Default to stereo. This could change depending on what the media element
// .src is set to.
AddOutput(2);

if (Context()->GetExecutionContext()) {
task_runner_ = Context()->GetExecutionContext()->GetTaskRunner(
TaskType::kMediaElementEvent);
}

Initialize();
}

void BaseAudioContext::MaybeRecordStartAttempt() {
  if (!user_gesture_required_ || !AreAutoplayRequirementsFulfilled())
    return;

  DCHECK(!autoplay_status_.has_value() ||
         autoplay_status_ != AutoplayStatus::kAutoplayStatusSucceeded);
  autoplay_status_ = AutoplayStatus::kAutoplayStatusFailedWithStart;
}

MediaElementAudioSourceNode* BaseAudioContext::createMediaElementSource(
    HTMLMediaElement* media_element,
    ExceptionState& exception_state) {
  DCHECK(IsMainThread());

  return MediaElementAudioSourceNode::Create(*this, *media_element,
                                             exception_state);
}

MediaStreamAudioSourceNode* BaseAudioContext::createMediaStreamSource(
    MediaStream* media_stream,
    ExceptionState& exception_state) {
  DCHECK(IsMainThread());

  return MediaStreamAudioSourceNode::Create(*this, *media_stream,
                                            exception_state);
}

void BaseAudioContext::RejectPendingDecodeAudioDataResolvers() {
  for (auto& resolver : decode_audio_resolvers_)
    resolver->Reject(DOMException::Create(kInvalidStateError,
                                          "Audio context is going away"));
  decode_audio_resolvers_.clear();
}
