status_t SoftOpus::initDecoder() {
 return OK;
}

SoftAVC::SoftAVC(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SoftVideoDecoderOMXComponent(
            name, componentName, codingType,
            kProfileLevels, ARRAY_SIZE(kProfileLevels),
 320 /* width */, 240 /* height */, callbacks,
            appData, component),
      mCodecCtx(NULL),
      mFlushOutBuffer(NULL),
      mOmxColorFormat(OMX_COLOR_FormatYUV420Planar),
      mIvColorFormat(IV_YUV_420P),
      mChangingResolution(false),
      mSignalledError(false),
      mStride(mWidth){
    initPorts(
            kNumBuffers, INPUT_BUF_SIZE, kNumBuffers, CODEC_MIME_TYPE);

    GETTIME(&mTimeStart, NULL);

    GENERATE_FILE_NAMES();
    CREATE_DUMP_FILE(mInFile);
}

void SoftVorbis::onQueueFilled(OMX_U32 portIndex) {
List<BufferInfo *> &inQueue = getPortQueue(0);
List<BufferInfo *> &outQueue = getPortQueue(1);

if (mOutputPortSettingsChange != NONE) {
return;
}

if (portIndex == 0 && mInputBufferCount < 2) {
BufferInfo *info = *inQueue.begin();
OMX_BUFFERHEADERTYPE *header = info->mHeader;


const uint8_t *data = header->pBuffer + header->nOffset;
size_t size = header->nFilledLen;

ogg_buffer buf;
ogg_reference ref;
oggpack_buffer bits;

makeBitReader(
(const uint8_t *)data + 7, size - 7,
&buf, &ref, &bits);

if (mInputBufferCount == 0) {
CHECK(mVi == NULL);
mVi = new vorbis_info;
vorbis_info_init(mVi);

CHECK_EQ(0, _vorbis_unpack_info(mVi, &bits));
} else {
CHECK_EQ(0, _vorbis_unpack_books(mVi, &bits));

CHECK(mState == NULL);
mState = new vorbis_dsp_state;
CHECK_EQ(0, vorbis_dsp_init(mState, mVi));

notify(OMX_EventPortSettingsChanged, 1, 0, NULL);
mOutputPortSettingsChange = AWAITING_DISABLED;
}

inQueue.erase(inQueue.begin());
info->mOwnedByUs = false;
notifyEmptyBufferDone(header);

++mInputBufferCount;

return;
}

while ((!inQueue.empty() || (mSawInputEos && !mSignalledOutputEos)) && !outQueue.empty()) {
BufferInfo *inInfo = NULL;
OMX_BUFFERHEADERTYPE *inHeader = NULL;
if (!inQueue.empty()) {
inInfo = *inQueue.begin();
inHeader = inInfo->mHeader;
}

BufferInfo *outInfo = *outQueue.begin();
OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

int32_t numPageSamples = 0;

if (inHeader) {
if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
mSawInputEos = true;
}

if (inHeader->nFilledLen || !mSawInputEos) {
CHECK_GE(inHeader->nFilledLen, sizeof(numPageSamples));
memcpy(&numPageSamples,
inHeader->pBuffer
+ inHeader->nOffset + inHeader->nFilledLen - 4,
sizeof(numPageSamples));

if (inHeader->nOffset == 0) {
mAnchorTimeUs = inHeader->nTimeStamp;
mNumFramesOutput = 0;
}

inHeader->nFilledLen -= sizeof(numPageSamples);;
}
}

if (numPageSamples >= 0) {
mNumFramesLeftOnPage = numPageSamples;
}

ogg_buffer buf;
buf.data = inHeader ? inHeader->pBuffer + inHeader->nOffset : NULL;
buf.size = inHeader ? inHeader->nFilledLen : 0;
buf.refcount = 1;
buf.ptr.owner = NULL;

ogg_reference ref;
ref.buffer = &buf;
ref.begin = 0;
ref.length = buf.size;
ref.next = NULL;

ogg_packet pack;
pack.packet = &ref;
pack.bytes = ref.length;
pack.b_o_s = 0;
pack.e_o_s = 0;
pack.granulepos = 0;
pack.packetno = 0;

int numFrames = 0;

outHeader->nFlags = 0;
int err = vorbis_dsp_synthesis(mState, &pack, 1);
if (err != 0) {
// FIXME temporary workaround for log spam
#if !defined(__arm__) && !defined(__aarch64__)
ALOGV("vorbis_dsp_synthesis returned %d", err);
#else

ALOGW("vorbis_dsp_synthesis returned %d", err);
#endif
} else {
numFrames = vorbis_dsp_pcmout(
mState, (int16_t *)outHeader->pBuffer,
                    (kMaxNumSamplesPerBuffer / mVi->channels));

if (numFrames < 0) {
ALOGE("vorbis_dsp_pcmout returned %d", numFrames);
numFrames = 0;
}
}

if (mNumFramesLeftOnPage >= 0) {
if (numFrames > mNumFramesLeftOnPage) {
ALOGV("discarding %d frames at end of page",
numFrames - mNumFramesLeftOnPage);
numFrames = mNumFramesLeftOnPage;
if (mSawInputEos) {
outHeader->nFlags = OMX_BUFFERFLAG_EOS;
mSignalledOutputEos = true;
}
}
mNumFramesLeftOnPage -= numFrames;
}

outHeader->nFilledLen = numFrames * sizeof(int16_t) * mVi->channels;
outHeader->nOffset = 0;

outHeader->nTimeStamp =
mAnchorTimeUs
+ (mNumFramesOutput * 1000000ll) / mVi->rate;

mNumFramesOutput += numFrames;

if (inHeader) {
inInfo->mOwnedByUs = false;
inQueue.erase(inQueue.begin());
inInfo = NULL;
notifyEmptyBufferDone(inHeader);
inHeader = NULL;
}

outInfo->mOwnedByUs = false;
outQueue.erase(outQueue.begin());
outInfo = NULL;
notifyFillBufferDone(outHeader);
outHeader = NULL;

++mInputBufferCount;
}
}

status_t SoftMPEG2::resetDecoder() {
 ivd_ctl_reset_ip_t s_ctl_ip;
 ivd_ctl_reset_op_t s_ctl_op;
    IV_API_CALL_STATUS_T status;

    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_RESET;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_reset_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_reset_op_t);

    status = ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip, (void *)&s_ctl_op);
 if (IV_SUCCESS != status) {
        ALOGE("Error in reset: 0x%x", s_ctl_op.u4_error_code);
 return UNKNOWN_ERROR;
 }

 /* Set the run-time (dynamic) parameters */
    setParams(outputBufferWidth());

 /* Set number of cores/threads to be used by the codec */
    setNumCores();

 return OK;
}

status_t SoftMPEG2::setParams(size_t stride) {
 ivd_ctl_set_config_ip_t s_ctl_ip;
 ivd_ctl_set_config_op_t s_ctl_op;
    IV_API_CALL_STATUS_T status;
    s_ctl_ip.u4_disp_wd = (UWORD32)stride;
    s_ctl_ip.e_frm_skip_mode = IVD_SKIP_NONE;

    s_ctl_ip.e_frm_out_mode = IVD_DISPLAY_FRAME_OUT;
    s_ctl_ip.e_vid_dec_mode = IVD_DECODE_FRAME;
    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_SETPARAMS;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_set_config_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_set_config_op_t);

    ALOGV("Set the run-time (dynamic) parameters stride = %zu", stride);
    status = ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip, (void *)&s_ctl_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in setting the run-time parameters: 0x%x",
                s_ctl_op.u4_error_code);

 return UNKNOWN_ERROR;
 }
 return OK;
}

SoftOpus::~SoftOpus() {
 if (mDecoder != NULL) {
        opus_multistream_decoder_destroy(mDecoder);
        mDecoder = NULL;
 }
 if (mHeader != NULL) {
 delete mHeader;
        mHeader = NULL;
 }
}

static uint16_t ReadLE16(const uint8_t *data, size_t data_size,
 uint32_t read_offset) {
 if (read_offset + 1 > data_size)
 return 0;
 uint16_t val;
    val = data[read_offset];
    val |= data[read_offset + 1] << 8;
 return val;
}

void SoftVorbis::onReset() {
    mInputBufferCount = 0;
    mNumFramesOutput = 0;
 if (mState != NULL) {
        vorbis_dsp_clear(mState);
 delete mState;
        mState = NULL;
 }

 if (mVi != NULL) {
        vorbis_info_clear(mVi);
 delete mVi;
        mVi = NULL;
 }

    mSawInputEos = false;
    mSignalledOutputEos = false;
    mOutputPortSettingsChange = NONE;
}

android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks, OMX_PTR appData,
        OMX_COMPONENTTYPE **component) {
 return new android::SoftAVC(name, callbacks, appData, component);
}

SoftMPEG2::~SoftMPEG2() {
    CHECK_EQ(deInitDecoder(), (status_t)OK);
}

OMX_ERRORTYPE SoftVorbis::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioVorbis:
 {
            OMX_AUDIO_PARAM_VORBISTYPE *vorbisParams =
 (OMX_AUDIO_PARAM_VORBISTYPE *)params;

 if (!isValidOMXParam(vorbisParams)) {
 return OMX_ErrorBadParameter;
 }

 if (vorbisParams->nPortIndex != 0) {
 return OMX_ErrorUndefined;
 }

            vorbisParams->nBitRate = 0;
            vorbisParams->nMinBitRate = 0;
            vorbisParams->nMaxBitRate = 0;
            vorbisParams->nAudioBandWidth = 0;
            vorbisParams->nQuality = 3;
            vorbisParams->bManaged = OMX_FALSE;
            vorbisParams->bDownmix = OMX_FALSE;

 if (!isConfigured()) {
                vorbisParams->nChannels = 1;
                vorbisParams->nSampleRate = 44100;
 } else {
                vorbisParams->nChannels = mVi->channels;
                vorbisParams->nSampleRate = mVi->rate;
                vorbisParams->nBitRate = mVi->bitrate_nominal;
                vorbisParams->nMinBitRate = mVi->bitrate_lower;
                vorbisParams->nMaxBitRate = mVi->bitrate_upper;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {
            OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;

 if (!isValidOMXParam(pcmParams)) {
 return OMX_ErrorBadParameter;
 }

 if (pcmParams->nPortIndex != 1) {
 return OMX_ErrorUndefined;
 }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

 if (!isConfigured()) {
                pcmParams->nChannels = 1;
                pcmParams->nSamplingRate = 44100;
 } else {
                pcmParams->nChannels = mVi->channels;
                pcmParams->nSamplingRate = mVi->rate;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

void SoftAVC::drainOneOutputBuffer(int32_t picId, uint8_t* data) {
List<BufferInfo *> &outQueue = getPortQueue(kOutputPortIndex);
BufferInfo *outInfo = *outQueue.begin();
    outQueue.erase(outQueue.begin());
OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;
OMX_BUFFERHEADERTYPE *header = mPicToHeaderMap.valueFor(picId);
outHeader->nTimeStamp = header->nTimeStamp;
outHeader->nFlags = header->nFlags;
    outHeader->nFilledLen = mWidth * mHeight * 3 / 2;

uint8_t *dst = outHeader->pBuffer + outHeader->nOffset;
const uint8_t *srcY = data;
const uint8_t *srcU = srcY + mWidth * mHeight;
const uint8_t *srcV = srcU + mWidth * mHeight / 4;
size_t srcYStride = mWidth;
size_t srcUStride = mWidth / 2;
size_t srcVStride = srcUStride;
copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);

mPicToHeaderMap.removeItem(picId);

delete header;
outInfo->mOwnedByUs = false;
notifyFillBufferDone(outHeader);
}

void SoftAVC::saveFirstOutputBuffer(int32_t picId, uint8_t *data) {
    CHECK(mFirstPicture == NULL);
    mFirstPictureId = picId;

 uint32_t pictureSize = mWidth * mHeight * 3 / 2;
    mFirstPicture = new uint8_t[pictureSize];

     memcpy(mFirstPicture, data, pictureSize);
 }

void SoftVorbis::onPortEnableCompleted(OMX_U32 portIndex, bool enabled) {
 if (portIndex != 1) {
 return;
 }

 switch (mOutputPortSettingsChange) {
 case NONE:
 break;

 case AWAITING_DISABLED:
 {
            CHECK(!enabled);
            mOutputPortSettingsChange = AWAITING_ENABLED;
 break;
 }

 default:
 {
            CHECK_EQ((int)mOutputPortSettingsChange, (int)AWAITING_ENABLED);
            CHECK(enabled);
            mOutputPortSettingsChange = NONE;
 break;
 }
 }
}

void SoftAVC::logVersion() {
 ivd_ctl_getversioninfo_ip_t s_ctl_ip;
 ivd_ctl_getversioninfo_op_t s_ctl_op;
    UWORD8 au1_buf[512];
    IV_API_CALL_STATUS_T status;

    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_GETVERSION;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_getversioninfo_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_getversioninfo_op_t);
    s_ctl_ip.pv_version_buffer = au1_buf;
    s_ctl_ip.u4_version_buffer_size = sizeof(au1_buf);

    status =
        ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip, (void *)&s_ctl_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in getting version number: 0x%x",
                s_ctl_op.u4_error_code);
 } else {
        ALOGV("Ittiam decoder version number: %s",
 (char *)s_ctl_ip.pv_version_buffer);
 }
 return;
}

status_t SoftMPEG2::reInitDecoder() {
 status_t ret;

    deInitDecoder();

    ret = initDecoder();
 if (OK != ret) {
        ALOGE("Create failure");
        deInitDecoder();
 return NO_MEMORY;
 }
 return OK;
}

void SoftAVC::onReset() {
 SoftVideoDecoderOMXComponent::onReset();
    mSignalledError = false;
}

SoftAVC::SoftAVC(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SoftVideoDecoderOMXComponent(
            name, "video_decoder.avc", OMX_VIDEO_CodingAVC,
            kProfileLevels, ARRAY_SIZE(kProfileLevels),
 320 /* width */, 240 /* height */, callbacks, appData, component),
      mHandle(NULL),
      mInputBufferCount(0),
      mFirstPicture(NULL),
      mFirstPictureId(-1),
      mPicId(0),
      mHeadersDecoded(false),
      mEOSStatus(INPUT_DATA_AVAILABLE),
      mSignalledError(false) {
 const size_t kMinCompressionRatio = 2;
 const size_t kMaxOutputBufferSize = 2048 * 2048 * 3 / 2;
    initPorts(
            kNumInputBuffers, kMaxOutputBufferSize / kMinCompressionRatio /* minInputBufferSize */,
            kNumOutputBuffers, MEDIA_MIMETYPE_VIDEO_AVC, kMinCompressionRatio);

    CHECK_EQ(initDecoder(), (status_t)OK);
}

 void SoftMPEG2::onPortFlushCompleted(OMX_U32 portIndex) {
     /* Once the output buffers are flushed, ignore any buffers that are held in decoder */
 if (kOutputPortIndex == portIndex) {
        setFlushMode();

 while (true) {
 ivd_video_decode_ip_t s_dec_ip;
 ivd_video_decode_op_t s_dec_op;
            IV_API_CALL_STATUS_T status;
 size_t sizeY, sizeUV;

            setDecodeArgs(&s_dec_ip, &s_dec_op, NULL, NULL, 0);

            status = ivdec_api_function(mCodecCtx, (void *)&s_dec_ip, (void *)&s_dec_op);
 if (0 == s_dec_op.u4_output_present) {
                resetPlugin();
 break;
 }
 }
 }
}

void SoftVorbis::initPorts() {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);

    def.nPortIndex = 0;
    def.eDir = OMX_DirInput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 8192;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 1;

    def.format.audio.cMIMEType =
 const_cast<char *>(MEDIA_MIMETYPE_AUDIO_VORBIS);

    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingVORBIS;

    addPort(def);

    def.nPortIndex = 1;
    def.eDir = OMX_DirOutput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = kMaxNumSamplesPerBuffer * sizeof(int16_t);
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 2;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);
}

status_t SoftMPEG2::deInitDecoder() {
 size_t i;

 if (mMemRecords) {
 iv_mem_rec_t *ps_mem_rec;

        ps_mem_rec = mMemRecords;
 for (i = 0; i < mNumMemRecords; i++) {
 if (ps_mem_rec->pv_base) {
                ivd_aligned_free(ps_mem_rec->pv_base);
 }
            ps_mem_rec++;
 }
        ivd_aligned_free(mMemRecords);
        mMemRecords = NULL;
 }

 if (mFlushOutBuffer) {
        ivd_aligned_free(mFlushOutBuffer);
        mFlushOutBuffer = NULL;
 }

    mInitNeeded = true;
    mChangingResolution = false;

 return OK;
}

status_t SoftAVC::setParams(size_t stride) {
 ivd_ctl_set_config_ip_t s_ctl_ip;
 ivd_ctl_set_config_op_t s_ctl_op;
    IV_API_CALL_STATUS_T status;
    s_ctl_ip.u4_disp_wd = (UWORD32)stride;
    s_ctl_ip.e_frm_skip_mode = IVD_SKIP_NONE;

    s_ctl_ip.e_frm_out_mode = IVD_DISPLAY_FRAME_OUT;
    s_ctl_ip.e_vid_dec_mode = IVD_DECODE_FRAME;
    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_SETPARAMS;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_set_config_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_set_config_op_t);

    ALOGV("Set the run-time (dynamic) parameters stride = %zu", stride);
    status = ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip, (void *)&s_ctl_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in setting the run-time parameters: 0x%x",
                s_ctl_op.u4_error_code);

 return UNKNOWN_ERROR;
 }
 return OK;
}

void SoftMPEG2::onQueueFilled(OMX_U32 portIndex) {
UNUSED(portIndex);

if (mOutputPortSettingsChange != NONE) {
return;
}

List<BufferInfo *> &inQueue = getPortQueue(kInputPortIndex);
List<BufferInfo *> &outQueue = getPortQueue(kOutputPortIndex);

/* If input EOS is seen and decoder is not in flush mode,
* set the decoder in flush mode.
* There can be a case where EOS is sent along with last picture data
* In that case, only after decoding that input data, decoder has to be
* put in flush. This case is handled here  */

if (mReceivedEOS && !mIsInFlush) {
setFlushMode();
}

while (!outQueue.empty()) {
BufferInfo *inInfo;
OMX_BUFFERHEADERTYPE *inHeader;

BufferInfo *outInfo;
OMX_BUFFERHEADERTYPE *outHeader;
size_t timeStampIx;

inInfo = NULL;
inHeader = NULL;

if (!mIsInFlush) {
if (!inQueue.empty()) {
inInfo = *inQueue.begin();
inHeader = inInfo->mHeader;
} else {
break;
}
}

outInfo = *outQueue.begin();
outHeader = outInfo->mHeader;
outHeader->nFlags = 0;
outHeader->nTimeStamp = 0;
outHeader->nOffset = 0;

if (inHeader != NULL && (inHeader->nFlags & OMX_BUFFERFLAG_EOS)) {
mReceivedEOS = true;
if (inHeader->nFilledLen == 0) {
inQueue.erase(inQueue.begin());
inInfo->mOwnedByUs = false;
notifyEmptyBufferDone(inHeader);
inHeader = NULL;
setFlushMode();
}
}

// When there is an init required and the decoder is not in flush mode,
// update output port's definition and reinitialize decoder.
if (mInitNeeded && !mIsInFlush) {
bool portWillReset = false;
handlePortSettingsChange(&portWillReset, mNewWidth, mNewHeight);

CHECK_EQ(reInitDecoder(), (status_t)OK);
return;
}

/* Get a free slot in timestamp array to hold input timestamp */
{
size_t i;
timeStampIx = 0;
for (i = 0; i < MAX_TIME_STAMPS; i++) {
if (!mTimeStampsValid[i]) {
timeStampIx = i;
break;
}
}
if (inHeader != NULL) {
mTimeStampsValid[timeStampIx] = true;
mTimeStamps[timeStampIx] = inHeader->nTimeStamp;
}
}

{
ivd_video_decode_ip_t s_dec_ip;
ivd_video_decode_op_t s_dec_op;

WORD32 timeDelay, timeTaken;
size_t sizeY, sizeUV;

            setDecodeArgs(&s_dec_ip, &s_dec_op, inHeader, outHeader, timeStampIx);
// If input dump is enabled, then write to file
DUMP_TO_FILE(mInFile, s_dec_ip.pv_stream_buffer, s_dec_ip.u4_num_Bytes);

if (s_dec_ip.u4_num_Bytes > 0) {
char *ptr = (char *)s_dec_ip.pv_stream_buffer;
}

GETTIME(&mTimeStart, NULL);
/* Compute time elapsed between end of previous decode()
* to start of current decode() */
TIME_DIFF(mTimeEnd, mTimeStart, timeDelay);

IV_API_CALL_STATUS_T status;
status = ivdec_api_function(mCodecCtx, (void *)&s_dec_ip, (void *)&s_dec_op);

bool unsupportedDimensions = (IMPEG2D_UNSUPPORTED_DIMENSIONS == s_dec_op.u4_error_code);
bool resChanged = (IVD_RES_CHANGED == (s_dec_op.u4_error_code & 0xFF));

GETTIME(&mTimeEnd, NULL);
/* Compute time taken for decode() */
TIME_DIFF(mTimeStart, mTimeEnd, timeTaken);

ALOGV("timeTaken=%6d delay=%6d numBytes=%6d", timeTaken, timeDelay,
s_dec_op.u4_num_bytes_consumed);
if (s_dec_op.u4_frame_decoded_flag && !mFlushNeeded) {
mFlushNeeded = true;
}

if ((inHeader != NULL) && (1 != s_dec_op.u4_frame_decoded_flag)) {
/* If the input did not contain picture data, then ignore
* the associated timestamp */
mTimeStampsValid[timeStampIx] = false;
}

// This is needed to handle CTS DecoderTest testCodecResetsMPEG2WithoutSurface,
// which is not sending SPS/PPS after port reconfiguration and flush to the codec.
if (unsupportedDimensions && !mFlushNeeded) {
bool portWillReset = false;
handlePortSettingsChange(&portWillReset, s_dec_op.u4_pic_wd, s_dec_op.u4_pic_ht);


CHECK_EQ(reInitDecoder(), (status_t)OK);

                setDecodeArgs(&s_dec_ip, &s_dec_op, inHeader, outHeader, timeStampIx);
                ivdec_api_function(mCodecCtx, (void *)&s_dec_ip, (void *)&s_dec_op);
return;
}

// If the decoder is in the changing resolution mode and there is no output present,
// that means the switching is done and it's ready to reset the decoder and the plugin.
if (mChangingResolution && !s_dec_op.u4_output_present) {
mChangingResolution = false;
resetDecoder();
resetPlugin();
continue;
}

if (unsupportedDimensions || resChanged) {
mChangingResolution = true;
if (mFlushNeeded) {
setFlushMode();
}

if (unsupportedDimensions) {
mNewWidth = s_dec_op.u4_pic_wd;
mNewHeight = s_dec_op.u4_pic_ht;
mInitNeeded = true;
}
continue;
}

if ((0 < s_dec_op.u4_pic_wd) && (0 < s_dec_op.u4_pic_ht)) {
uint32_t width = s_dec_op.u4_pic_wd;
uint32_t height = s_dec_op.u4_pic_ht;
bool portWillReset = false;
handlePortSettingsChange(&portWillReset, width, height);

if (portWillReset) {
resetDecoder();
return;
}
}

if (s_dec_op.u4_output_present) {
size_t timeStampIdx;
outHeader->nFilledLen = (mWidth * mHeight * 3) / 2;

timeStampIdx = getMinTimestampIdx(mTimeStamps, mTimeStampsValid);
outHeader->nTimeStamp = mTimeStamps[timeStampIdx];
mTimeStampsValid[timeStampIdx] = false;

/* mWaitForI waits for the first I picture. Once made FALSE, it
has to remain false till explicitly set to TRUE. */
mWaitForI = mWaitForI && !(IV_I_FRAME == s_dec_op.e_pic_type);

if (mWaitForI) {
s_dec_op.u4_output_present = false;
} else {
ALOGV("Output timestamp: %lld, res: %ux%u",
(long long)outHeader->nTimeStamp, mWidth, mHeight);
DUMP_TO_FILE(mOutFile, outHeader->pBuffer, outHeader->nFilledLen);
outInfo->mOwnedByUs = false;
outQueue.erase(outQueue.begin());
outInfo = NULL;
notifyFillBufferDone(outHeader);
outHeader = NULL;
}
} else {
/* If in flush mode and no output is returned by the codec,
* then come out of flush mode */
mIsInFlush = false;

/* If EOS was recieved on input port and there is no output
* from the codec, then signal EOS on output port */
if (mReceivedEOS) {
outHeader->nFilledLen = 0;
outHeader->nFlags |= OMX_BUFFERFLAG_EOS;

outInfo->mOwnedByUs = false;
outQueue.erase(outQueue.begin());
outInfo = NULL;
notifyFillBufferDone(outHeader);
outHeader = NULL;
resetPlugin();
}
}
}

// TODO: Handle more than one picture data
if (inHeader != NULL) {
inInfo->mOwnedByUs = false;
inQueue.erase(inQueue.begin());
inInfo = NULL;
notifyEmptyBufferDone(inHeader);
inHeader = NULL;
}
}
}

 void SoftHEVC::onPortFlushCompleted(OMX_U32 portIndex) {
     /* Once the output buffers are flushed, ignore any buffers that are held in decoder */
 if (kOutputPortIndex == portIndex) {
        setFlushMode();

 /* Allocate a picture buffer to flushed data */
 uint32_t displayStride = outputBufferWidth();
 uint32_t displayHeight = outputBufferHeight();

 uint32_t bufferSize = displayStride * displayHeight * 3 / 2;
        mFlushOutBuffer = (uint8_t *)memalign(128, bufferSize);
 if (NULL == mFlushOutBuffer) {
            ALOGE("Could not allocate flushOutputBuffer of size %zu", bufferSize);
 return;
 }

 while (true) {
 ivd_video_decode_ip_t s_dec_ip;
 ivd_video_decode_op_t s_dec_op;
            IV_API_CALL_STATUS_T status;
 size_t sizeY, sizeUV;

            setDecodeArgs(&s_dec_ip, &s_dec_op, NULL, NULL, 0);

            status = ivdec_api_function(mCodecCtx, (void *)&s_dec_ip,
 (void *)&s_dec_op);
 if (0 == s_dec_op.u4_output_present) {
                resetPlugin();
 break;
 }
 }

 if (mFlushOutBuffer) {
            free(mFlushOutBuffer);
            mFlushOutBuffer = NULL;
 }

 }
}

android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks, OMX_PTR appData,
        OMX_COMPONENTTYPE **component) {
 return new android::SoftMPEG2(name, callbacks, appData, component);
}

static bool ParseOpusHeader(const uint8_t *data, size_t data_size,
 OpusHeader* header) {
 const size_t kOpusHeaderSize = 19;

 const size_t kOpusHeaderChannelsOffset = 9;

 const size_t kOpusHeaderSkipSamplesOffset = 10;

 const size_t kOpusHeaderGainOffset = 16;

 const size_t kOpusHeaderChannelMappingOffset = 18;

 const size_t kOpusHeaderNumStreamsOffset = kOpusHeaderSize;
 const size_t kOpusHeaderNumCoupledOffset = kOpusHeaderNumStreamsOffset + 1;
 const size_t kOpusHeaderStreamMapOffset = kOpusHeaderNumStreamsOffset + 2;

 if (data_size < kOpusHeaderSize) {
        ALOGV("Header size is too small.");
 return false;
 }
    header->channels = *(data + kOpusHeaderChannelsOffset);

 if (header->channels <= 0 || header->channels > kMaxChannels) {
        ALOGV("Invalid Header, wrong channel count: %d", header->channels);
 return false;
 }
    header->skip_samples = ReadLE16(data, data_size,
                                        kOpusHeaderSkipSamplesOffset);
    header->gain_db = static_cast<int16_t>(
 ReadLE16(data, data_size,
                                       kOpusHeaderGainOffset));
    header->channel_mapping = *(data + kOpusHeaderChannelMappingOffset);
 if (!header->channel_mapping) {
 if (header->channels > kMaxChannelsWithDefaultLayout) {
            ALOGV("Invalid Header, missing stream map.");
 return false;
 }
        header->num_streams = 1;
        header->num_coupled = header->channels > 1;
        header->stream_map[0] = 0;
        header->stream_map[1] = 1;
 return true;
 }
 if (data_size < kOpusHeaderStreamMapOffset + header->channels) {
        ALOGV("Invalid stream map; insufficient data for current channel "
 "count: %d", header->channels);
 return false;
 }
    header->num_streams = *(data + kOpusHeaderNumStreamsOffset);
    header->num_coupled = *(data + kOpusHeaderNumCoupledOffset);
 if (header->num_streams + header->num_coupled != header->channels) {
        ALOGV("Inconsistent channel mapping.");
 return false;
 }
 for (int i = 0; i < header->channels; ++i)
      header->stream_map[i] = *(data + kOpusHeaderStreamMapOffset + i);
 return true;
}

status_t SoftAVC::resetDecoder() {
 ivd_ctl_reset_ip_t s_ctl_ip;
 ivd_ctl_reset_op_t s_ctl_op;
    IV_API_CALL_STATUS_T status;

    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_RESET;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_reset_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_reset_op_t);

    status = ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip, (void *)&s_ctl_op);
 if (IV_SUCCESS != status) {
        ALOGE("Error in reset: 0x%x", s_ctl_op.u4_error_code);
 return UNKNOWN_ERROR;
 }
    mSignalledError = false;

 /* Set number of cores/threads to be used by the codec */
    setNumCores();

    mStride = 0;
 return OK;
}

status_t SoftMPEG2::setFlushMode() {
    IV_API_CALL_STATUS_T status;
 ivd_ctl_flush_ip_t s_video_flush_ip;
 ivd_ctl_flush_op_t s_video_flush_op;

    s_video_flush_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_video_flush_ip.e_sub_cmd = IVD_CMD_CTL_FLUSH;
    s_video_flush_ip.u4_size = sizeof(ivd_ctl_flush_ip_t);
    s_video_flush_op.u4_size = sizeof(ivd_ctl_flush_op_t);

 /* Set the decoder in Flush mode, subsequent decode() calls will flush */
    status = ivdec_api_function(
            mCodecCtx, (void *)&s_video_flush_ip, (void *)&s_video_flush_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in setting the decoder in flush mode: (%d) 0x%x", status,
                s_video_flush_op.u4_error_code);
 return UNKNOWN_ERROR;
 }

    mWaitForI = true;
    mIsInFlush = true;
 return OK;
}

void SoftOpus::onPortFlushCompleted(OMX_U32 portIndex) {
 if (portIndex == 0 && mDecoder != NULL) {
        mNumFramesOutput = 0;
        opus_multistream_decoder_ctl(mDecoder, OPUS_RESET_STATE);
        mAnchorTimeUs = 0;
        mSamplesToDiscard = mSeekPreRoll;
 }
}

static size_t getMinTimestampIdx(OMX_S64 *pNTimeStamp, bool *pIsTimeStampValid) {
    OMX_S64 minTimeStamp = LLONG_MAX;
 int idx = -1;
 for (size_t i = 0; i < MAX_TIME_STAMPS; i++) {
 if (pIsTimeStampValid[i]) {
 if (pNTimeStamp[i] < minTimeStamp) {
                minTimeStamp = pNTimeStamp[i];
                idx = i;
 }
 }
 }
 return idx;
}

SoftMPEG2::SoftMPEG2(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SoftVideoDecoderOMXComponent(
            name, componentName, codingType,
            kProfileLevels, ARRAY_SIZE(kProfileLevels),
 320 /* width */, 240 /* height */, callbacks,
            appData, component),
      mMemRecords(NULL),
      mFlushOutBuffer(NULL),
      mOmxColorFormat(OMX_COLOR_FormatYUV420Planar),
      mIvColorFormat(IV_YUV_420P),
      mNewWidth(mWidth),
      mNewHeight(mHeight),
      mChangingResolution(false) {
    initPorts(kNumBuffers, INPUT_BUF_SIZE, kNumBuffers, CODEC_MIME_TYPE);

    GENERATE_FILE_NAMES();
    CREATE_DUMP_FILE(mInFile);

    CHECK_EQ(initDecoder(), (status_t)OK);
}

OMX_ERRORTYPE SoftOpus::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamStandardComponentRole:
 {
 const OMX_PARAM_COMPONENTROLETYPE *roleParams =
 (const OMX_PARAM_COMPONENTROLETYPE *)params;

 if (!isValidOMXParam(roleParams)) {
 return OMX_ErrorBadParameter;
 }

 if (strncmp((const char *)roleParams->cRole,
 "audio_decoder.opus",
                        OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAndroidOpus:
 {
 const OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *opusParams =
 (const OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *)params;

 if (!isValidOMXParam(opusParams)) {
 return OMX_ErrorBadParameter;
 }

 if (opusParams->nPortIndex != 0) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

void SoftMPEG4::onQueueFilled(OMX_U32 /* portIndex */) {
if (mSignalledError || mOutputPortSettingsChange != NONE) {
return;
}

List<BufferInfo *> &inQueue = getPortQueue(0);
List<BufferInfo *> &outQueue = getPortQueue(1);

while (!inQueue.empty() && outQueue.size() == kNumOutputBuffers) {
BufferInfo *inInfo = *inQueue.begin();
OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;
if (inHeader == NULL) {
inQueue.erase(inQueue.begin());
inInfo->mOwnedByUs = false;
continue;
}

PortInfo *port = editPortInfo(1);

OMX_BUFFERHEADERTYPE *outHeader =
port->mBuffers.editItemAt(mNumSamplesOutput & 1).mHeader;

if (inHeader->nFilledLen == 0) {
inQueue.erase(inQueue.begin());
inInfo->mOwnedByUs = false;
notifyEmptyBufferDone(inHeader);

++mInputBufferCount;

if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
outHeader->nFilledLen = 0;
outHeader->nFlags = OMX_BUFFERFLAG_EOS;

List<BufferInfo *>::iterator it = outQueue.begin();
while ((*it)->mHeader != outHeader) {
++it;
}

BufferInfo *outInfo = *it;
outInfo->mOwnedByUs = false;
outQueue.erase(it);
outInfo = NULL;

notifyFillBufferDone(outHeader);
outHeader = NULL;
}
return;
}

uint8_t *bitstream = inHeader->pBuffer + inHeader->nOffset;
uint32_t *start_code = (uint32_t *)bitstream;
bool volHeader = *start_code == 0xB0010000;
if (volHeader) {
PVCleanUpVideoDecoder(mHandle);
mInitialized = false;
}

if (!mInitialized) {
uint8_t *vol_data[1];
int32_t vol_size = 0;

vol_data[0] = NULL;

if ((inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) || volHeader) {
vol_data[0] = bitstream;
vol_size = inHeader->nFilledLen;
}

MP4DecodingMode mode =
(mMode == MODE_MPEG4) ? MPEG4_MODE : H263_MODE;

Bool success = PVInitVideoDecoder(
mHandle, vol_data, &vol_size, 1,
outputBufferWidth(), outputBufferHeight(), mode);

if (!success) {
ALOGW("PVInitVideoDecoder failed. Unsupported content?");

notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
mSignalledError = true;
return;
}

MP4DecodingMode actualMode = PVGetDecBitstreamMode(mHandle);
if (mode != actualMode) {
notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
mSignalledError = true;
return;
}

PVSetPostProcType((VideoDecControls *) mHandle, 0);

bool hasFrameData = false;
if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {
inInfo->mOwnedByUs = false;
inQueue.erase(inQueue.begin());
inInfo = NULL;
notifyEmptyBufferDone(inHeader);
inHeader = NULL;
} else if (volHeader) {
hasFrameData = true;
}

mInitialized = true;

if (mode == MPEG4_MODE && handlePortSettingsChange()) {
return;
}

if (!hasFrameData) {
continue;
}
}

if (!mFramesConfigured) {
PortInfo *port = editPortInfo(1);
OMX_BUFFERHEADERTYPE *outHeader = port->mBuffers.editItemAt(1).mHeader;

PVSetReferenceYUV(mHandle, outHeader->pBuffer);

mFramesConfigured = true;
}

uint32_t useExtTimestamp = (inHeader->nOffset == 0);

// decoder deals in ms (int32_t), OMX in us (int64_t)
// so use fake timestamp instead
uint32_t timestamp = 0xFFFFFFFF;
if (useExtTimestamp) {
mPvToOmxTimeMap.add(mPvTime, inHeader->nTimeStamp);
timestamp = mPvTime;
mPvTime++;
}


int32_t bufferSize = inHeader->nFilledLen;
int32_t tmp = bufferSize;

// The PV decoder is lying to us, sometimes it'll claim to only have
// consumed a subset of the buffer when it clearly consumed all of it.
// ignore whatever it says...
if (PVDecodeVideoFrame(
mHandle, &bitstream, &timestamp, &tmp,
&useExtTimestamp,
outHeader->pBuffer) != PV_TRUE) {
ALOGE("failed to decode video frame.");

notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
mSignalledError = true;
return;
}

// H263 doesn't have VOL header, the frame size information is in short header, i.e. the
// decoder may detect size change after PVDecodeVideoFrame.
if (handlePortSettingsChange()) {
return;
}

// decoder deals in ms, OMX in us.
outHeader->nTimeStamp = mPvToOmxTimeMap.valueFor(timestamp);
mPvToOmxTimeMap.removeItem(timestamp);

inHeader->nOffset += bufferSize;
inHeader->nFilledLen = 0;
if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
outHeader->nFlags = OMX_BUFFERFLAG_EOS;
} else {
outHeader->nFlags = 0;
}

if (inHeader->nFilledLen == 0) {
inInfo->mOwnedByUs = false;
inQueue.erase(inQueue.begin());
inInfo = NULL;
notifyEmptyBufferDone(inHeader);
inHeader = NULL;
}


++mInputBufferCount;

outHeader->nOffset = 0;
        outHeader->nFilledLen = (mWidth * mHeight * 3) / 2;

List<BufferInfo *>::iterator it = outQueue.begin();
while ((*it)->mHeader != outHeader) {
++it;
}

BufferInfo *outInfo = *it;
outInfo->mOwnedByUs = false;
outQueue.erase(it);
outInfo = NULL;

notifyFillBufferDone(outHeader);
outHeader = NULL;

++mNumSamplesOutput;
}
}

void SoftOpus::onReset() {
    mInputBufferCount = 0;
    mNumFramesOutput = 0;
 if (mDecoder != NULL) {
        opus_multistream_decoder_destroy(mDecoder);
        mDecoder = NULL;
 }
 if (mHeader != NULL) {
 delete mHeader;
        mHeader = NULL;
 }

    mOutputPortSettingsChange = NONE;
}

SoftVorbis::SoftVorbis(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mInputBufferCount(0),
      mState(NULL),
      mVi(NULL),
      mAnchorTimeUs(0),
      mNumFramesOutput(0),
      mNumFramesLeftOnPage(-1),
      mSawInputEos(false),
      mSignalledOutputEos(false),
      mOutputPortSettingsChange(NONE) {
    initPorts();
    CHECK_EQ(initDecoder(), (status_t)OK);
}

SoftVorbis::~SoftVorbis() {
 if (mState != NULL) {
        vorbis_dsp_clear(mState);
 delete mState;
        mState = NULL;
 }

 if (mVi != NULL) {
        vorbis_info_clear(mVi);
 delete mVi;
        mVi = NULL;
 }
}

bool SoftOpus::isConfigured() const {
 return mInputBufferCount >= 1;
}

void SoftAVC::onPortFlushCompleted(OMX_U32 portIndex) {
 if (portIndex == kInputPortIndex) {
        mEOSStatus = INPUT_DATA_AVAILABLE;
 }
}

void SoftVorbis::onPortFlushCompleted(OMX_U32 portIndex) {
 if (portIndex == 0 && mState != NULL) {

        mNumFramesOutput = 0;
        vorbis_dsp_restart(mState);
 }
}

SoftOpus::SoftOpus(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mInputBufferCount(0),
      mDecoder(NULL),
      mHeader(NULL),
      mCodecDelay(0),
      mSeekPreRoll(0),
      mAnchorTimeUs(0),
      mNumFramesOutput(0),
      mOutputPortSettingsChange(NONE) {
    initPorts();
    CHECK_EQ(initDecoder(), (status_t)OK);
}

void SoftAVC::onQueueFilled(OMX_U32 portIndex) {
UNUSED(portIndex);

if (mSignalledError) {
return;
}
if (mOutputPortSettingsChange != NONE) {
return;
}

if (NULL == mCodecCtx) {
if (OK != initDecoder()) {
ALOGE("Failed to initialize decoder");
notify(OMX_EventError, OMX_ErrorUnsupportedSetting, 0, NULL);
mSignalledError = true;
return;
}
}
if (outputBufferWidth() != mStride) {
/* Set the run-time (dynamic) parameters */
mStride = outputBufferWidth();
setParams(mStride);
}

List<BufferInfo *> &inQueue = getPortQueue(kInputPortIndex);
List<BufferInfo *> &outQueue = getPortQueue(kOutputPortIndex);

/* If input EOS is seen and decoder is not in flush mode,
* set the decoder in flush mode.
* There can be a case where EOS is sent along with last picture data
* In that case, only after decoding that input data, decoder has to be
* put in flush. This case is handled here  */

if (mReceivedEOS && !mIsInFlush) {
setFlushMode();
}

while (!outQueue.empty()) {
BufferInfo *inInfo;
OMX_BUFFERHEADERTYPE *inHeader;

BufferInfo *outInfo;
OMX_BUFFERHEADERTYPE *outHeader;
size_t timeStampIx;

inInfo = NULL;
inHeader = NULL;

if (!mIsInFlush) {
if (!inQueue.empty()) {
inInfo = *inQueue.begin();
inHeader = inInfo->mHeader;
if (inHeader == NULL) {
inQueue.erase(inQueue.begin());
inInfo->mOwnedByUs = false;
continue;
}
} else {
break;
}
}

outInfo = *outQueue.begin();
outHeader = outInfo->mHeader;
outHeader->nFlags = 0;
outHeader->nTimeStamp = 0;
outHeader->nOffset = 0;

if (inHeader != NULL) {
if (inHeader->nFilledLen == 0) {
inQueue.erase(inQueue.begin());
inInfo->mOwnedByUs = false;
notifyEmptyBufferDone(inHeader);

if (!(inHeader->nFlags & OMX_BUFFERFLAG_EOS)) {
continue;
}

mReceivedEOS = true;
inHeader = NULL;
setFlushMode();
} else if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
mReceivedEOS = true;
}
}

/* Get a free slot in timestamp array to hold input timestamp */
{
size_t i;
timeStampIx = 0;
for (i = 0; i < MAX_TIME_STAMPS; i++) {
if (!mTimeStampsValid[i]) {
timeStampIx = i;
break;
}
}
if (inHeader != NULL) {
mTimeStampsValid[timeStampIx] = true;
mTimeStamps[timeStampIx] = inHeader->nTimeStamp;
}
}

{
ivd_video_decode_ip_t s_dec_ip;
ivd_video_decode_op_t s_dec_op;

WORD32 timeDelay, timeTaken;
size_t sizeY, sizeUV;

            setDecodeArgs(&s_dec_ip, &s_dec_op, inHeader, outHeader, timeStampIx);
// If input dump is enabled, then write to file
DUMP_TO_FILE(mInFile, s_dec_ip.pv_stream_buffer, s_dec_ip.u4_num_Bytes);

GETTIME(&mTimeStart, NULL);
/* Compute time elapsed between end of previous decode()
* to start of current decode() */
TIME_DIFF(mTimeEnd, mTimeStart, timeDelay);

IV_API_CALL_STATUS_T status;
status = ivdec_api_function(mCodecCtx, (void *)&s_dec_ip, (void *)&s_dec_op);

bool unsupportedResolution =
(IVD_STREAM_WIDTH_HEIGHT_NOT_SUPPORTED == (s_dec_op.u4_error_code & 0xFF));

/* Check for unsupported dimensions */
if (unsupportedResolution) {
ALOGE("Unsupported resolution : %dx%d", mWidth, mHeight);
notify(OMX_EventError, OMX_ErrorUnsupportedSetting, 0, NULL);
mSignalledError = true;
return;
}

bool allocationFailed = (IVD_MEM_ALLOC_FAILED == (s_dec_op.u4_error_code & 0xFF));
if (allocationFailed) {
ALOGE("Allocation failure in decoder");
notify(OMX_EventError, OMX_ErrorUnsupportedSetting, 0, NULL);
mSignalledError = true;
return;
}

bool resChanged = (IVD_RES_CHANGED == (s_dec_op.u4_error_code & 0xFF));

GETTIME(&mTimeEnd, NULL);
/* Compute time taken for decode() */
TIME_DIFF(mTimeStart, mTimeEnd, timeTaken);

PRINT_TIME("timeTaken=%6d delay=%6d numBytes=%6d", timeTaken, timeDelay,
s_dec_op.u4_num_bytes_consumed);
if (s_dec_op.u4_frame_decoded_flag && !mFlushNeeded) {
mFlushNeeded = true;
}

if ((inHeader != NULL) && (1 != s_dec_op.u4_frame_decoded_flag)) {
/* If the input did not contain picture data, then ignore
* the associated timestamp */
mTimeStampsValid[timeStampIx] = false;
}

// If the decoder is in the changing resolution mode and there is no output present,
// that means the switching is done and it's ready to reset the decoder and the plugin.
if (mChangingResolution && !s_dec_op.u4_output_present) {
mChangingResolution = false;
resetDecoder();
resetPlugin();
continue;
}

if (resChanged) {
mChangingResolution = true;
if (mFlushNeeded) {
setFlushMode();
}
continue;
}

if ((0 < s_dec_op.u4_pic_wd) && (0 < s_dec_op.u4_pic_ht)) {
uint32_t width = s_dec_op.u4_pic_wd;
uint32_t height = s_dec_op.u4_pic_ht;
bool portWillReset = false;
handlePortSettingsChange(&portWillReset, width, height);

if (portWillReset) {
resetDecoder();
return;
}
}

if (s_dec_op.u4_output_present) {
outHeader->nFilledLen = (outputBufferWidth() * outputBufferHeight() * 3) / 2;

outHeader->nTimeStamp = mTimeStamps[s_dec_op.u4_ts];
mTimeStampsValid[s_dec_op.u4_ts] = false;

outInfo->mOwnedByUs = false;
outQueue.erase(outQueue.begin());
outInfo = NULL;
notifyFillBufferDone(outHeader);
outHeader = NULL;
} else {
/* If in flush mode and no output is returned by the codec,
* then come out of flush mode */
mIsInFlush = false;

/* If EOS was recieved on input port and there is no output
* from the codec, then signal EOS on output port */
if (mReceivedEOS) {
outHeader->nFilledLen = 0;
outHeader->nFlags |= OMX_BUFFERFLAG_EOS;

outInfo->mOwnedByUs = false;
outQueue.erase(outQueue.begin());
outInfo = NULL;
notifyFillBufferDone(outHeader);
outHeader = NULL;
resetPlugin();
}
}
}

if (inHeader != NULL) {
inInfo->mOwnedByUs = false;
inQueue.erase(inQueue.begin());
inInfo = NULL;
notifyEmptyBufferDone(inHeader);
inHeader = NULL;
}
}
}

android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftVorbis(name, callbacks, appData, component);
}

void SoftAVC::onReset() {
 SoftVideoDecoderOMXComponent::onReset();

    mSignalledError = false;
    resetDecoder();

     resetPlugin();
 }

void SoftMPEG2::logVersion() {
 ivd_ctl_getversioninfo_ip_t s_ctl_ip;
 ivd_ctl_getversioninfo_op_t s_ctl_op;
    UWORD8 au1_buf[512];
    IV_API_CALL_STATUS_T status;

    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_GETVERSION;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_getversioninfo_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_getversioninfo_op_t);
    s_ctl_ip.pv_version_buffer = au1_buf;
    s_ctl_ip.u4_version_buffer_size = sizeof(au1_buf);

    status = ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip, (void *)&s_ctl_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in getting version number: 0x%x",
                s_ctl_op.u4_error_code);
 } else {
        ALOGV("Ittiam decoder version number: %s",
 (char *)s_ctl_ip.pv_version_buffer);
 }
 return;
}

SoftVideoDecoderOMXComponent::CropSettingsMode SoftAVC::handleCropParams(
 const H264SwDecInfo& decInfo) {
 if (!decInfo.croppingFlag) {
 return kCropUnSet;
 }

 const CropParams& crop = decInfo.cropParams;
 if (mCropLeft == crop.cropLeftOffset &&
        mCropTop == crop.cropTopOffset &&
        mCropWidth == crop.cropOutWidth &&
        mCropHeight == crop.cropOutHeight) {
 return kCropSet;
 }

    mCropLeft = crop.cropLeftOffset;
    mCropTop = crop.cropTopOffset;
    mCropWidth = crop.cropOutWidth;
    mCropHeight = crop.cropOutHeight;
 return kCropChanged;
}

bool SoftVorbis::isConfigured() const {
 return mInputBufferCount >= 2;
}

status_t SoftMPEG2::initDecoder() {
    IV_API_CALL_STATUS_T status;

    UWORD32 u4_num_reorder_frames;
    UWORD32 u4_num_ref_frames;
    UWORD32 u4_share_disp_buf;

    mNumCores = GetCPUCoreCount();
    mWaitForI = true;

 /* Initialize number of ref and reorder modes (for MPEG2) */
    u4_num_reorder_frames = 16;
    u4_num_ref_frames = 16;
    u4_share_disp_buf = 0;

 uint32_t displayStride = outputBufferWidth();
 uint32_t displayHeight = outputBufferHeight();
 uint32_t displaySizeY = displayStride * displayHeight;

 {
 iv_num_mem_rec_ip_t s_num_mem_rec_ip;
 iv_num_mem_rec_op_t s_num_mem_rec_op;

        s_num_mem_rec_ip.u4_size = sizeof(s_num_mem_rec_ip);
        s_num_mem_rec_op.u4_size = sizeof(s_num_mem_rec_op);
        s_num_mem_rec_ip.e_cmd = IV_CMD_GET_NUM_MEM_REC;

        status = ivdec_api_function(
                mCodecCtx, (void *)&s_num_mem_rec_ip, (void *)&s_num_mem_rec_op);
 if (IV_SUCCESS != status) {
            ALOGE("Error in getting mem records: 0x%x",
                    s_num_mem_rec_op.u4_error_code);
 return UNKNOWN_ERROR;
 }

        mNumMemRecords = s_num_mem_rec_op.u4_num_mem_rec;
 }

    mMemRecords = (iv_mem_rec_t *)ivd_aligned_malloc(
 128, mNumMemRecords * sizeof(iv_mem_rec_t));
 if (mMemRecords == NULL) {
        ALOGE("Allocation failure");
 return NO_MEMORY;
 }

    memset(mMemRecords, 0, mNumMemRecords * sizeof(iv_mem_rec_t));

 {
 size_t i;
 ivdext_fill_mem_rec_ip_t s_fill_mem_ip;
 ivdext_fill_mem_rec_op_t s_fill_mem_op;
 iv_mem_rec_t *ps_mem_rec;

        s_fill_mem_ip.s_ivd_fill_mem_rec_ip_t.u4_size =
 sizeof(ivdext_fill_mem_rec_ip_t);

        s_fill_mem_ip.u4_share_disp_buf = u4_share_disp_buf;
        s_fill_mem_ip.e_output_format = mIvColorFormat;
        s_fill_mem_ip.u4_deinterlace = 1;
        s_fill_mem_ip.s_ivd_fill_mem_rec_ip_t.e_cmd = IV_CMD_FILL_NUM_MEM_REC;
        s_fill_mem_ip.s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location = mMemRecords;
        s_fill_mem_ip.s_ivd_fill_mem_rec_ip_t.u4_max_frm_wd = displayStride;
        s_fill_mem_ip.s_ivd_fill_mem_rec_ip_t.u4_max_frm_ht = displayHeight;
        s_fill_mem_op.s_ivd_fill_mem_rec_op_t.u4_size =
 sizeof(ivdext_fill_mem_rec_op_t);

        ps_mem_rec = mMemRecords;
 for (i = 0; i < mNumMemRecords; i++) {
            ps_mem_rec[i].u4_size = sizeof(iv_mem_rec_t);
 }

        status = ivdec_api_function(
                mCodecCtx, (void *)&s_fill_mem_ip, (void *)&s_fill_mem_op);

 if (IV_SUCCESS != status) {
            ALOGE("Error in filling mem records: 0x%x",
                    s_fill_mem_op.s_ivd_fill_mem_rec_op_t.u4_error_code);
 return UNKNOWN_ERROR;
 }
        mNumMemRecords =
            s_fill_mem_op.s_ivd_fill_mem_rec_op_t.u4_num_mem_rec_filled;

        ps_mem_rec = mMemRecords;

 for (i = 0; i < mNumMemRecords; i++) {
            ps_mem_rec->pv_base = ivd_aligned_malloc(
                    ps_mem_rec->u4_mem_alignment, ps_mem_rec->u4_mem_size);
 if (ps_mem_rec->pv_base == NULL) {
                ALOGE("Allocation failure for memory record #%zu of size %u",
                        i, ps_mem_rec->u4_mem_size);
                status = IV_FAIL;
 return NO_MEMORY;
 }

            ps_mem_rec++;
 }
 }

 /* Initialize the decoder */
 {
 ivdext_init_ip_t s_init_ip;
 ivdext_init_op_t s_init_op;

 void *dec_fxns = (void *)ivdec_api_function;

        s_init_ip.s_ivd_init_ip_t.u4_size = sizeof(ivdext_init_ip_t);
        s_init_ip.s_ivd_init_ip_t.e_cmd = (IVD_API_COMMAND_TYPE_T)IV_CMD_INIT;
        s_init_ip.s_ivd_init_ip_t.pv_mem_rec_location = mMemRecords;
        s_init_ip.s_ivd_init_ip_t.u4_frm_max_wd = displayStride;
        s_init_ip.s_ivd_init_ip_t.u4_frm_max_ht = displayHeight;

        s_init_ip.u4_share_disp_buf = u4_share_disp_buf;
        s_init_ip.u4_deinterlace = 1;

        s_init_op.s_ivd_init_op_t.u4_size = sizeof(s_init_op);

        s_init_ip.s_ivd_init_ip_t.u4_num_mem_rec = mNumMemRecords;
        s_init_ip.s_ivd_init_ip_t.e_output_format = mIvColorFormat;

        mCodecCtx = (iv_obj_t *)mMemRecords[0].pv_base;
        mCodecCtx->pv_fxns = dec_fxns;
        mCodecCtx->u4_size = sizeof(iv_obj_t);

        status = ivdec_api_function(mCodecCtx, (void *)&s_init_ip, (void *)&s_init_op);
 if (status != IV_SUCCESS) {
            ALOGE("Error in init: 0x%x",
                    s_init_op.s_ivd_init_op_t.u4_error_code);
 return UNKNOWN_ERROR;
 }
 }

 /* Reset the plugin state */
    resetPlugin();

 /* Set the run time (dynamic) parameters */
    setParams(displayStride);

 /* Set number of cores/threads to be used by the codec */
    setNumCores();

 /* Get codec version */
    logVersion();

 /* Allocate internal picture buffer */
 uint32_t bufferSize = displaySizeY * 3 / 2;
    mFlushOutBuffer = (uint8_t *)ivd_aligned_malloc(128, bufferSize);
 if (NULL == mFlushOutBuffer) {
        ALOGE("Could not allocate flushOutputBuffer of size %u", bufferSize);
 return NO_MEMORY;
 }

    mInitNeeded = false;
    mFlushNeeded = false;
 return OK;
}

status_t SoftMPEG2::resetPlugin() {
    mIsInFlush = false;
    mReceivedEOS = false;
    memset(mTimeStamps, 0, sizeof(mTimeStamps));
    memset(mTimeStampsValid, 0, sizeof(mTimeStampsValid));

 /* Initialize both start and end times */
    gettimeofday(&mTimeStart, NULL);
    gettimeofday(&mTimeEnd, NULL);

 return OK;
}

void SoftOpus::onQueueFilled(OMX_U32 portIndex) {
List<BufferInfo *> &inQueue = getPortQueue(0);
List<BufferInfo *> &outQueue = getPortQueue(1);

if (mOutputPortSettingsChange != NONE) {
return;
}

if (portIndex == 0 && mInputBufferCount < 3) {
BufferInfo *info = *inQueue.begin();
OMX_BUFFERHEADERTYPE *header = info->mHeader;

const uint8_t *data = header->pBuffer + header->nOffset;
size_t size = header->nFilledLen;

if (mInputBufferCount == 0) {
CHECK(mHeader == NULL);
mHeader = new OpusHeader();
memset(mHeader, 0, sizeof(*mHeader));
if (!ParseOpusHeader(data, size, mHeader)) {
ALOGV("Parsing Opus Header failed.");
notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
return;
}

uint8_t channel_mapping[kMaxChannels] = {0};
if (mHeader->channels <= kMaxChannelsWithDefaultLayout) {
memcpy(&channel_mapping,
kDefaultOpusChannelLayout,
kMaxChannelsWithDefaultLayout);
} else {
memcpy(&channel_mapping,
mHeader->stream_map,
mHeader->channels);
}

int status = OPUS_INVALID_STATE;
mDecoder = opus_multistream_decoder_create(kRate,
mHeader->channels,
mHeader->num_streams,
mHeader->num_coupled,
channel_mapping,
&status);
if (!mDecoder || status != OPUS_OK) {
ALOGV("opus_multistream_decoder_create failed status=%s",
opus_strerror(status));
notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
return;
}
status =
opus_multistream_decoder_ctl(mDecoder,
OPUS_SET_GAIN(mHeader->gain_db));
if (status != OPUS_OK) {
ALOGV("Failed to set OPUS header gain; status=%s",
opus_strerror(status));
notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
return;
}
} else if (mInputBufferCount == 1) {
mCodecDelay = ns_to_samples(
*(reinterpret_cast<int64_t*>(header->pBuffer +
header->nOffset)),
kRate);
mSamplesToDiscard = mCodecDelay;
} else {
mSeekPreRoll = ns_to_samples(
*(reinterpret_cast<int64_t*>(header->pBuffer +
header->nOffset)),
kRate);
notify(OMX_EventPortSettingsChanged, 1, 0, NULL);
mOutputPortSettingsChange = AWAITING_DISABLED;
}

inQueue.erase(inQueue.begin());
info->mOwnedByUs = false;
notifyEmptyBufferDone(header);
++mInputBufferCount;
return;
}

while (!inQueue.empty() && !outQueue.empty()) {
BufferInfo *inInfo = *inQueue.begin();
OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

// Ignore CSD re-submissions.
if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {
inQueue.erase(inQueue.begin());
inInfo->mOwnedByUs = false;
notifyEmptyBufferDone(inHeader);
return;
}

BufferInfo *outInfo = *outQueue.begin();
OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
inQueue.erase(inQueue.begin());
inInfo->mOwnedByUs = false;
notifyEmptyBufferDone(inHeader);

outHeader->nFilledLen = 0;
outHeader->nFlags = OMX_BUFFERFLAG_EOS;

outQueue.erase(outQueue.begin());
outInfo->mOwnedByUs = false;
notifyFillBufferDone(outHeader);
return;
}

if (inHeader->nOffset == 0) {
mAnchorTimeUs = inHeader->nTimeStamp;
mNumFramesOutput = 0;
}

// When seeking to zero, |mCodecDelay| samples has to be discarded
// instead of |mSeekPreRoll| samples (as we would when seeking to any
// other timestamp).
if (inHeader->nTimeStamp == 0) {
mSamplesToDiscard = mCodecDelay;
}


const uint8_t *data = inHeader->pBuffer + inHeader->nOffset;
const uint32_t size = inHeader->nFilledLen;

int numFrames = opus_multistream_decode(mDecoder,
data,
size,
(int16_t *)outHeader->pBuffer,
                                                kMaxOpusOutputPacketSizeSamples,
0);
if (numFrames < 0) {
ALOGE("opus_multistream_decode returned %d", numFrames);
notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
return;
}

outHeader->nOffset = 0;
if (mSamplesToDiscard > 0) {
if (mSamplesToDiscard > numFrames) {
mSamplesToDiscard -= numFrames;
numFrames = 0;
} else {
numFrames -= mSamplesToDiscard;
outHeader->nOffset = mSamplesToDiscard * sizeof(int16_t) *
mHeader->channels;
mSamplesToDiscard = 0;
}
}

outHeader->nFilledLen = numFrames * sizeof(int16_t) * mHeader->channels;
outHeader->nFlags = 0;

outHeader->nTimeStamp = mAnchorTimeUs +
(mNumFramesOutput * 1000000ll) /
kRate;

mNumFramesOutput += numFrames;

inInfo->mOwnedByUs = false;
inQueue.erase(inQueue.begin());
inInfo = NULL;
notifyEmptyBufferDone(inHeader);
inHeader = NULL;

outInfo->mOwnedByUs = false;
outQueue.erase(outQueue.begin());
outInfo = NULL;
notifyFillBufferDone(outHeader);
outHeader = NULL;

++mInputBufferCount;
}
}

status_t SoftVorbis::initDecoder() {
 return OK;
}

status_t SoftAVC::deInitDecoder() {
 size_t i;
    IV_API_CALL_STATUS_T status;

 if (mCodecCtx) {
 ivdext_delete_ip_t s_delete_ip;
 ivdext_delete_op_t s_delete_op;

        s_delete_ip.s_ivd_delete_ip_t.u4_size = sizeof(ivdext_delete_ip_t);
        s_delete_ip.s_ivd_delete_ip_t.e_cmd = IVD_CMD_DELETE;

        s_delete_op.s_ivd_delete_op_t.u4_size = sizeof(ivdext_delete_op_t);

        status = ivdec_api_function(mCodecCtx, (void *)&s_delete_ip, (void *)&s_delete_op);
 if (status != IV_SUCCESS) {
            ALOGE("Error in delete: 0x%x",
                    s_delete_op.s_ivd_delete_op_t.u4_error_code);
 return UNKNOWN_ERROR;
 }
 }


    mChangingResolution = false;

 return OK;
}

void SoftHEVC::onReset() {
    ALOGV("onReset called");
 SoftVideoDecoderOMXComponent::onReset();

    mSignalledError = false;
    resetDecoder();

     resetPlugin();
 }

OMX_ERRORTYPE SoftVorbis::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {
 const OMX_PARAM_COMPONENTROLETYPE *roleParams =
 (const OMX_PARAM_COMPONENTROLETYPE *)params;

 if (!isValidOMXParam(roleParams)) {
 return OMX_ErrorBadParameter;
 }

 if (strncmp((const char *)roleParams->cRole,
 "audio_decoder.vorbis",
                        OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioVorbis:
 {
 const OMX_AUDIO_PARAM_VORBISTYPE *vorbisParams =
 (const OMX_AUDIO_PARAM_VORBISTYPE *)params;

 if (!isValidOMXParam(vorbisParams)) {
 return OMX_ErrorBadParameter;
 }

 if (vorbisParams->nPortIndex != 0) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

void SoftMPEG2::setDecodeArgs(
ivd_video_decode_ip_t *ps_dec_ip,
ivd_video_decode_op_t *ps_dec_op,
OMX_BUFFERHEADERTYPE *inHeader,
OMX_BUFFERHEADERTYPE *outHeader,

size_t timeStampIx) {
size_t sizeY = outputBufferWidth() * outputBufferHeight();
size_t sizeUV;
    uint8_t *pBuf;

ps_dec_ip->u4_size = sizeof(ivd_video_decode_ip_t);
ps_dec_op->u4_size = sizeof(ivd_video_decode_op_t);

ps_dec_ip->e_cmd = IVD_CMD_VIDEO_DECODE;

/* When in flush and after EOS with zero byte input,
* inHeader is set to zero. Hence check for non-null */
if (inHeader) {
ps_dec_ip->u4_ts = timeStampIx;
ps_dec_ip->pv_stream_buffer = inHeader->pBuffer
+ inHeader->nOffset;
ps_dec_ip->u4_num_Bytes = inHeader->nFilledLen;
} else {
ps_dec_ip->u4_ts = 0;
ps_dec_ip->pv_stream_buffer = NULL;

ps_dec_ip->u4_num_Bytes = 0;
}

    if (outHeader) {
        pBuf = outHeader->pBuffer;
    } else {
        pBuf = mFlushOutBuffer;
    }
sizeUV = sizeY / 4;
ps_dec_ip->s_out_buffer.u4_min_out_buf_size[0] = sizeY;
ps_dec_ip->s_out_buffer.u4_min_out_buf_size[1] = sizeUV;
ps_dec_ip->s_out_buffer.u4_min_out_buf_size[2] = sizeUV;

ps_dec_ip->s_out_buffer.pu1_bufs[0] = pBuf;
ps_dec_ip->s_out_buffer.pu1_bufs[1] = pBuf + sizeY;
ps_dec_ip->s_out_buffer.pu1_bufs[2] = pBuf + sizeY + sizeUV;
ps_dec_ip->s_out_buffer.u4_num_bufs = 3;
    return;
}

status_t SoftAVC::setFlushMode() {
    IV_API_CALL_STATUS_T status;
 ivd_ctl_flush_ip_t s_video_flush_ip;
 ivd_ctl_flush_op_t s_video_flush_op;

    s_video_flush_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_video_flush_ip.e_sub_cmd = IVD_CMD_CTL_FLUSH;
    s_video_flush_ip.u4_size = sizeof(ivd_ctl_flush_ip_t);
    s_video_flush_op.u4_size = sizeof(ivd_ctl_flush_op_t);

 /* Set the decoder in Flush mode, subsequent decode() calls will flush */
    status = ivdec_api_function(
            mCodecCtx, (void *)&s_video_flush_ip, (void *)&s_video_flush_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in setting the decoder in flush mode: (%d) 0x%x", status,
                s_video_flush_op.u4_error_code);
 return UNKNOWN_ERROR;
 }

    mIsInFlush = true;
 return OK;
}

status_t SoftAVC::setNumCores() {
 ivdext_ctl_set_num_cores_ip_t s_set_cores_ip;
 ivdext_ctl_set_num_cores_op_t s_set_cores_op;
    IV_API_CALL_STATUS_T status;
    s_set_cores_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_set_cores_ip.e_sub_cmd = IVDEXT_CMD_CTL_SET_NUM_CORES;
    s_set_cores_ip.u4_num_cores = MIN(mNumCores, CODEC_MAX_NUM_CORES);
    s_set_cores_ip.u4_size = sizeof(ivdext_ctl_set_num_cores_ip_t);
    s_set_cores_op.u4_size = sizeof(ivdext_ctl_set_num_cores_op_t);
    status = ivdec_api_function(
            mCodecCtx, (void *)&s_set_cores_ip, (void *)&s_set_cores_op);
 if (IV_SUCCESS != status) {
        ALOGE("Error in setting number of cores: 0x%x",
                s_set_cores_op.u4_error_code);
 return UNKNOWN_ERROR;
 }
 return OK;
}

static void makeBitReader(
 const void *data, size_t size,
        ogg_buffer *buf, ogg_reference *ref, oggpack_buffer *bits) {
    buf->data = (uint8_t *)data;
    buf->size = size;
    buf->refcount = 1;
    buf->ptr.owner = NULL;

    ref->buffer = buf;
    ref->begin = 0;
    ref->length = size;
    ref->next = NULL;

    oggpack_readinit(bits, ref);
}
