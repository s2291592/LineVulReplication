 void setNotificationMessage(const sp<AMessage> &msg) {
        mNotify = msg;
 }

void ACodec::LoadedState::onStart() {
    ALOGV("onStart");

 status_t err = mCodec->mOMX->sendCommand(mCodec->mNode, OMX_CommandStateSet, OMX_StateIdle);
 if (err != OK) {
        mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));
 } else {
        mCodec->changeState(mCodec->mLoadedToIdleState);
 }
}

bool ACodec::LoadedState::onConfigureComponent(
 const sp<AMessage> &msg) {
    ALOGV("onConfigureComponent");

    CHECK(mCodec->mNode != 0);

 status_t err = OK;
 AString mime;
 if (!msg->findString("mime", &mime)) {
        err = BAD_VALUE;
 } else {
        err = mCodec->configureCodec(mime.c_str(), msg);
 }
 if (err != OK) {
        ALOGE("[%s] configureCodec returning error %d",
              mCodec->mComponentName.c_str(), err);

        mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));
 return false;
 }

 {
        sp<AMessage> notify = mCodec->mNotify->dup();
        notify->setInt32("what", CodecBase::kWhatComponentConfigured);
        notify->setMessage("input-format", mCodec->mInputFormat);
        notify->setMessage("output-format", mCodec->mOutputFormat);
        notify->post();
 }

 return true;
}

status_t ACodec::setupAC3Codec(
 bool encoder, int32_t numChannels, int32_t sampleRate) {
 status_t err = setupRawAudioFormat(
            encoder ? kPortIndexInput : kPortIndexOutput, sampleRate, numChannels);

 if (err != OK) {
 return err;
 }

 if (encoder) {
        ALOGW("AC3 encoding is not supported.");
 return INVALID_OPERATION;
 }

    OMX_AUDIO_PARAM_ANDROID_AC3TYPE def;
 InitOMXParams(&def);
    def.nPortIndex = kPortIndexInput;

    err = mOMX->getParameter(
            mNode,
 (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidAc3,
 &def,
 sizeof(def));

 if (err != OK) {
 return err;
 }

    def.nChannels = numChannels;
    def.nSampleRate = sampleRate;

 return mOMX->setParameter(
            mNode,
 (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidAc3,
 &def,
 sizeof(def));
}

void SoftVideoDecoderOMXComponent::copyYV12FrameToOutputBuffer(
 uint8_t *dst, const uint8_t *srcY, const uint8_t *srcU, const uint8_t *srcV,
 size_t srcYStride, size_t srcUStride, size_t srcVStride) {
 size_t dstYStride = outputBufferWidth();
 size_t dstUVStride = dstYStride / 2;
 size_t dstHeight = outputBufferHeight();
 uint8_t *dstStart = dst;

 for (size_t i = 0; i < mHeight; ++i) {
         memcpy(dst, srcY, mWidth);
         srcY += srcYStride;
         dst += dstYStride;
 }

    dst = dstStart + dstYStride * dstHeight;
 for (size_t i = 0; i < mHeight / 2; ++i) {
         memcpy(dst, srcU, mWidth / 2);
         srcU += srcUStride;
         dst += dstUVStride;
 }

    dst = dstStart + (5 * dstYStride * dstHeight) / 4;
 for (size_t i = 0; i < mHeight / 2; ++i) {
         memcpy(dst, srcV, mWidth / 2);
         srcV += srcVStride;
         dst += dstUVStride;
 }
}

SoftAMRWBEncoder::SoftAMRWBEncoder(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mEncoderHandle(NULL),
      mApiHandle(NULL),
      mMemOperator(NULL),
      mBitRate(0),
      mMode(VOAMRWB_MD66),
      mInputSize(0),
      mInputTimeUs(-1ll),
      mSawInputEOS(false),
      mSignalledError(false) {
    initPorts();
    CHECK_EQ(initEncoder(), (status_t)OK);
}

status_t ACodec::allocateOutputMetadataBuffers() {
    OMX_U32 bufferCount, bufferSize, minUndequeuedBuffers;
 status_t err = configureOutputBuffersFromNativeWindow(
 &bufferCount, &bufferSize, &minUndequeuedBuffers);
 if (err != 0)
 return err;
    mNumUndequeuedBuffers = minUndequeuedBuffers;

    ALOGV("[%s] Allocating %u meta buffers on output port",
         mComponentName.c_str(), bufferCount);

 size_t bufSize = mOutputMetadataType == kMetadataBufferTypeANWBuffer ?
 sizeof(struct VideoNativeMetadata) : sizeof(struct VideoGrallocMetadata);
 size_t totalSize = bufferCount * bufSize;
    mDealer[kPortIndexOutput] = new MemoryDealer(totalSize, "ACodec");

 for (OMX_U32 i = 0; i < bufferCount; i++) {
 BufferInfo info;
        info.mStatus = BufferInfo::OWNED_BY_NATIVE_WINDOW;
        info.mFenceFd = -1;
        info.mRenderInfo = NULL;
        info.mGraphicBuffer = NULL;
        info.mDequeuedAt = mDequeueCounter;

        sp<IMemory> mem = mDealer[kPortIndexOutput]->allocate(bufSize);
 if (mem == NULL || mem->pointer() == NULL) {
 return NO_MEMORY;
 }
 if (mOutputMetadataType == kMetadataBufferTypeANWBuffer) {
 ((VideoNativeMetadata *)mem->pointer())->nFenceFd = -1;
 }
        info.mData = new ABuffer(mem->pointer(), mem->size());

        err = mOMX->useBuffer(
                mNode, kPortIndexOutput, mem, &info.mBufferID, mem->size());

        mBuffers[kPortIndexOutput].push(info);

        ALOGV("[%s] allocated meta buffer with ID %u (pointer = %p)",
             mComponentName.c_str(), info.mBufferID, mem->pointer());
 }

 if (mLegacyAdaptiveExperiment) {
 static_cast<Surface *>(mNativeWindow.get())
 ->getIGraphicBufferProducer()->allowAllocation(true);

        ALOGV("[%s] Allocating %u buffers from a native window of size %u on "
 "output port",
             mComponentName.c_str(), bufferCount, bufferSize);

 for (OMX_U32 i = 0; i < bufferCount; i++) {
 BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);

 ANativeWindowBuffer *buf;
 int fenceFd;
            err = mNativeWindow->dequeueBuffer(mNativeWindow.get(), &buf, &fenceFd);
 if (err != 0) {
                ALOGE("dequeueBuffer failed: %s (%d)", strerror(-err), -err);
 break;
 }

            sp<GraphicBuffer> graphicBuffer(new GraphicBuffer(buf, false));
            mOMX->updateGraphicBufferInMeta(
                    mNode, kPortIndexOutput, graphicBuffer, info->mBufferID);
            info->mStatus = BufferInfo::OWNED_BY_US;
            info->setWriteFence(fenceFd, "allocateOutputMetadataBuffers for legacy");
            info->mGraphicBuffer = graphicBuffer;
 }

 for (OMX_U32 i = 0; i < mBuffers[kPortIndexOutput].size(); i++) {
 BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);
 if (info->mStatus == BufferInfo::OWNED_BY_US) {
 status_t error = cancelBufferToNativeWindow(info);
 if (err == OK) {
                    err = error;
 }
 }
 }

 static_cast<Surface*>(mNativeWindow.get())
 ->getIGraphicBufferProducer()->allowAllocation(false);
 }

    mMetadataBuffersToSubmit = bufferCount - minUndequeuedBuffers;
 return err;
}

OMX_ERRORTYPE SoftAVCEncoder::initEncoder() {
    CHECK(!mStarted);

    OMX_ERRORTYPE errType = OMX_ErrorNone;
 if (OMX_ErrorNone != (errType = initEncParams())) {
        ALOGE("Failed to initialized encoder params");
        mSignalledError = true;
        notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return errType;
 }

 AVCEnc_Status err;
    err = PVAVCEncInitialize(mHandle, mEncParams, NULL, NULL);
 if (err != AVCENC_SUCCESS) {
        ALOGE("Failed to initialize the encoder: %d", err);
        mSignalledError = true;
        notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return OMX_ErrorUndefined;
 }

    mNumInputFrames = -2; // 1st two buffers contain SPS and PPS
    mSpsPpsHeaderReceived = false;
    mReadyForNextFrame = true;
    mIsIDRFrame = false;
    mStarted = true;

 return OMX_ErrorNone;
}

android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftAMRWBEncoder(name, callbacks, appData, component);
}

 virtual status_t allocateBufferWithBackup(
            node_id node, OMX_U32 port_index, const sp<IMemory> &params,
            buffer_id *buffer, OMX_U32 allottedSize) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeStrongBinder(IInterface::asBinder(params));
        data.writeInt32(allottedSize);
        remote()->transact(ALLOC_BUFFER_WITH_BACKUP, data, &reply);

 status_t err = reply.readInt32();
 if (err != OK) {
 *buffer = 0;

 return err;
 }

 *buffer = (buffer_id)reply.readInt32();

 return err;
 }

uint32_t SoftVideoDecoderOMXComponent::outputBufferHeight() {
 return mIsAdaptive ? mAdaptiveMaxHeight : mHeight;
}

 virtual bool livesLocally(node_id node, pid_t pid) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(pid);
        remote()->transact(LIVES_LOCALLY, data, &reply);

 return reply.readInt32() != 0;
 }

SoftAVCEncoder::~SoftAVCEncoder() {
    ALOGV("Destruct SoftAVCEncoder");
    releaseEncoder();
 List<BufferInfo *> &outQueue = getPortQueue(1);
 List<BufferInfo *> &inQueue = getPortQueue(0);
    CHECK(outQueue.empty());
    CHECK(inQueue.empty());
}

OMX_ERRORTYPE SoftMPEG4Encoder::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamVideoBitrate:
 {

             OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *) params;
 
             if (bitRate->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            bitRate->eControlRate = OMX_Video_ControlRateVariable;
            bitRate->nTargetBitrate = mBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoH263:
 {

             OMX_VIDEO_PARAM_H263TYPE *h263type =
                 (OMX_VIDEO_PARAM_H263TYPE *)params;
 
             if (h263type->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            h263type->nAllowedPictureTypes =
 (OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP);
            h263type->eProfile = OMX_VIDEO_H263ProfileBaseline;
            h263type->eLevel = OMX_VIDEO_H263Level45;
            h263type->bPLUSPTYPEAllowed = OMX_FALSE;
            h263type->bForceRoundingTypeToZero = OMX_FALSE;
            h263type->nPictureHeaderRepetition = 0;
            h263type->nGOBHeaderInterval = 0;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoMpeg4:
 {

             OMX_VIDEO_PARAM_MPEG4TYPE *mpeg4type =
                 (OMX_VIDEO_PARAM_MPEG4TYPE *)params;
 
             if (mpeg4type->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            mpeg4type->eProfile = OMX_VIDEO_MPEG4ProfileCore;
            mpeg4type->eLevel = OMX_VIDEO_MPEG4Level2;
            mpeg4type->nAllowedPictureTypes =
 (OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP);
            mpeg4type->nBFrames = 0;
            mpeg4type->nIDCVLCThreshold = 0;
            mpeg4type->bACPred = OMX_TRUE;
            mpeg4type->nMaxPacketSize = 256;
            mpeg4type->nTimeIncRes = 1000;
            mpeg4type->nHeaderExtension = 0;
            mpeg4type->bReversibleVLC = OMX_FALSE;

 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalGetParameter(index, params);
 }
}

bool ACodec::LoadedState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case ACodec::kWhatConfigureComponent:
 {
            onConfigureComponent(msg);
            handled = true;
 break;
 }

 case ACodec::kWhatCreateInputSurface:
 {
            onCreateInputSurface(msg);
            handled = true;
 break;
 }

 case ACodec::kWhatSetInputSurface:
 {
            onSetInputSurface(msg);
            handled = true;
 break;
 }

 case ACodec::kWhatStart:
 {
            onStart();
            handled = true;
 break;
 }

 case ACodec::kWhatShutdown:
 {
 int32_t keepComponentAllocated;
            CHECK(msg->findInt32(
 "keepComponentAllocated", &keepComponentAllocated));

            mCodec->mExplicitShutdown = true;
            onShutdown(keepComponentAllocated);

            handled = true;
 break;
 }

 case ACodec::kWhatFlush:
 {
            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatFlushCompleted);
            notify->post();

            handled = true;
 break;
 }

 default:
 return BaseState::onMessageReceived(msg);
 }

 return handled;
}

OMX_ERRORTYPE SoftAMRWBEncoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_encoder.amrwb",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPortFormat:
 {

             const OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (const OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

 if ((formatParams->nPortIndex == 0
 && formatParams->eEncoding != OMX_AUDIO_CodingPCM)
 || (formatParams->nPortIndex == 1
 && formatParams->eEncoding != OMX_AUDIO_CodingAMR)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAmr:
 {

             OMX_AUDIO_PARAM_AMRTYPE *amrParams =
                 (OMX_AUDIO_PARAM_AMRTYPE *)params;
 
             if (amrParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (amrParams->nChannels != 1
 || amrParams->eAMRDTXMode != OMX_AUDIO_AMRDTXModeOff
 || amrParams->eAMRFrameFormat
 != OMX_AUDIO_AMRFrameFormatFSF
 || amrParams->eAMRBandMode < OMX_AUDIO_AMRBandModeWB0
 || amrParams->eAMRBandMode > OMX_AUDIO_AMRBandModeWB8) {
 return OMX_ErrorUndefined;
 }

            mBitRate = amrParams->nBitRate;

            mMode = (VOAMRWBMODE)(
                    amrParams->eAMRBandMode - OMX_AUDIO_AMRBandModeWB0);

            amrParams->eAMRDTXMode = OMX_AUDIO_AMRDTXModeOff;
            amrParams->eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;

 if (VO_ERR_NONE !=
                    mApiHandle->SetParam(
                        mEncoderHandle, VO_PID_AMRWB_MODE, &mMode)) {
                ALOGE("Failed to set AMRWB encoder mode to %d", mMode);
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 if (pcmParams->nChannels != 1
 || pcmParams->nSamplingRate != (OMX_U32)kSampleRate) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }


 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

void ACodec::OutputPortSettingsChangedState::stateEntered() {
    ALOGV("[%s] Now handling output port settings change",
         mCodec->mComponentName.c_str());
}

status_t SoftRaw::initDecoder() {
 return OK;
}

FLAC__StreamEncoderWriteStatus SoftFlacEncoder::onEncodedFlacAvailable(
 const FLAC__byte buffer[],
 size_t bytes, unsigned samples,
 unsigned current_frame) {
    UNUSED_UNLESS_VERBOSE(current_frame);
    ALOGV("SoftFlacEncoder::onEncodedFlacAvailable(bytes=%zu, samples=%u, curr_frame=%u)",
            bytes, samples, current_frame);

#ifdef WRITE_FLAC_HEADER_IN_FIRST_BUFFER
 if (samples == 0) {
        ALOGI(" saving %zu bytes of header", bytes);
        memcpy(mHeader + mHeaderOffset, buffer, bytes);
        mHeaderOffset += bytes;// will contain header size when finished receiving header
 return FLAC__STREAM_ENCODER_WRITE_STATUS_OK;
 }

#endif

 if ((samples == 0) || !mEncoderWriteData) {
        ALOGV("ignoring %zu bytes of header data (samples=%d)", bytes, samples);
 return FLAC__STREAM_ENCODER_WRITE_STATUS_OK;
 }

 List<BufferInfo *> &outQueue = getPortQueue(1);
    CHECK(!outQueue.empty());
 BufferInfo *outInfo = *outQueue.begin();
    OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

#ifdef WRITE_FLAC_HEADER_IN_FIRST_BUFFER
 if (!mWroteHeader) {
        ALOGI(" writing %d bytes of header on output port", mHeaderOffset);
        memcpy(outHeader->pBuffer + outHeader->nOffset + outHeader->nFilledLen,
                mHeader, mHeaderOffset);
        outHeader->nFilledLen += mHeaderOffset;
        outHeader->nOffset    += mHeaderOffset;
        mWroteHeader = true;
 }
#endif

    ALOGV(" writing %zu bytes of encoded data on output port", bytes);
 if (bytes > outHeader->nAllocLen - outHeader->nOffset - outHeader->nFilledLen) {
        ALOGE(" not enough space left to write encoded data, dropping %zu bytes", bytes);
 return FLAC__STREAM_ENCODER_WRITE_STATUS_OK;
 }
    memcpy(outHeader->pBuffer + outHeader->nOffset, buffer, bytes);

    outHeader->nTimeStamp = mCurrentInputTimeStamp;
    outHeader->nOffset = 0;
    outHeader->nFilledLen += bytes;
    outHeader->nFlags = 0;

    mEncoderReturnedEncodedData = true;
    mEncoderReturnedNbBytes += bytes;

 return FLAC__STREAM_ENCODER_WRITE_STATUS_OK;
}

bool ACodec::IdleToExecutingState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
 switch (event) {
 case OMX_EventCmdComplete:
 {
 if (data1 != (OMX_U32)OMX_CommandStateSet
 || data2 != (OMX_U32)OMX_StateExecuting) {
                ALOGE("Unexpected command completion in IdleToExecutingState: %s(%u) %s(%u)",
                        asString((OMX_COMMANDTYPE)data1), data1,
                        asString((OMX_STATETYPE)data2), data2);
                mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return true;
 }

            mCodec->mExecutingState->resume();
            mCodec->changeState(mCodec->mExecutingState);

 return true;
 }

 default:
 return BaseState::onOMXEvent(event, data1, data2);
 }
}

bool ACodec::UninitializedState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case ACodec::kWhatSetup:
 {
            onSetup(msg);

            handled = true;
 break;
 }

 case ACodec::kWhatAllocateComponent:
 {
            onAllocateComponent(msg);
            handled = true;
 break;
 }

 case ACodec::kWhatShutdown:
 {
 int32_t keepComponentAllocated;
            CHECK(msg->findInt32(
 "keepComponentAllocated", &keepComponentAllocated));
            ALOGW_IF(keepComponentAllocated,
 "cannot keep component allocated on shutdown in Uninitialized state");

            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatShutdownCompleted);
            notify->post();

            handled = true;
 break;
 }

 case ACodec::kWhatFlush:
 {
            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatFlushCompleted);
            notify->post();

            handled = true;
 break;
 }

 case ACodec::kWhatReleaseCodecInstance:
 {
            handled = true;
 break;
 }

 default:
 return BaseState::onMessageReceived(msg);
 }

 return handled;
}

status_t ACodec::setupVideoEncoder(const char *mime, const sp<AMessage> &msg) {
 int32_t tmp;
 if (!msg->findInt32("color-format", &tmp)) {
 return INVALID_OPERATION;
 }

    OMX_COLOR_FORMATTYPE colorFormat =
 static_cast<OMX_COLOR_FORMATTYPE>(tmp);

 status_t err = setVideoPortFormatType(
            kPortIndexInput, OMX_VIDEO_CodingUnused, colorFormat);

 if (err != OK) {
        ALOGE("[%s] does not support color format %d",
              mComponentName.c_str(), colorFormat);

 return err;
 }

 /* Input port configuration */

    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);

    OMX_VIDEO_PORTDEFINITIONTYPE *video_def = &def.format.video;

    def.nPortIndex = kPortIndexInput;

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

 int32_t width, height, bitrate;
 if (!msg->findInt32("width", &width)
 || !msg->findInt32("height", &height)
 || !msg->findInt32("bitrate", &bitrate)) {
 return INVALID_OPERATION;
 }

    video_def->nFrameWidth = width;
    video_def->nFrameHeight = height;

 int32_t stride;
 if (!msg->findInt32("stride", &stride)) {
        stride = width;
 }

    video_def->nStride = stride;

 int32_t sliceHeight;
 if (!msg->findInt32("slice-height", &sliceHeight)) {
        sliceHeight = height;
 }

    video_def->nSliceHeight = sliceHeight;

    def.nBufferSize = (video_def->nStride * video_def->nSliceHeight * 3) / 2;

 float frameRate;
 if (!msg->findFloat("frame-rate", &frameRate)) {
 int32_t tmp;
 if (!msg->findInt32("frame-rate", &tmp)) {
 return INVALID_OPERATION;
 }
        frameRate = (float)tmp;
        mTimePerFrameUs = (int64_t) (1000000.0f / frameRate);
 }

    video_def->xFramerate = (OMX_U32)(frameRate * 65536.0f);
    video_def->eCompressionFormat = OMX_VIDEO_CodingUnused;
 if (colorFormat != OMX_COLOR_FormatYUV420Flexible) {
        video_def->eColorFormat = colorFormat;
 }

    err = mOMX->setParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
        ALOGE("[%s] failed to set input port definition parameters.",
              mComponentName.c_str());

 return err;
 }

 /* Output port configuration */

    OMX_VIDEO_CODINGTYPE compressionFormat;
    err = GetVideoCodingTypeFromMime(mime, &compressionFormat);

 if (err != OK) {
 return err;
 }

    err = setVideoPortFormatType(
            kPortIndexOutput, compressionFormat, OMX_COLOR_FormatUnused);

 if (err != OK) {
        ALOGE("[%s] does not support compression format %d",
             mComponentName.c_str(), compressionFormat);

 return err;
 }

    def.nPortIndex = kPortIndexOutput;

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

    video_def->nFrameWidth = width;
    video_def->nFrameHeight = height;
    video_def->xFramerate = 0;
    video_def->nBitrate = bitrate;
    video_def->eCompressionFormat = compressionFormat;
    video_def->eColorFormat = OMX_COLOR_FormatUnused;

    err = mOMX->setParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
        ALOGE("[%s] failed to set output port definition parameters.",
              mComponentName.c_str());

 return err;
 }

 switch (compressionFormat) {
 case OMX_VIDEO_CodingMPEG4:
            err = setupMPEG4EncoderParameters(msg);
 break;

 case OMX_VIDEO_CodingH263:
            err = setupH263EncoderParameters(msg);
 break;

 case OMX_VIDEO_CodingAVC:
            err = setupAVCEncoderParameters(msg);
 break;

 case OMX_VIDEO_CodingHEVC:
            err = setupHEVCEncoderParameters(msg);
 break;

 case OMX_VIDEO_CodingVP8:
 case OMX_VIDEO_CodingVP9:
            err = setupVPXEncoderParameters(msg);
 break;

 default:
 break;
 }

 if (err == OK) {
        ALOGI("setupVideoEncoder succeeded");
 }

 return err;
}

OMX_ERRORTYPE SoftMPEG4Encoder::initEncParams() {
    CHECK(mHandle != NULL);
    memset(mHandle, 0, sizeof(tagvideoEncControls));

    CHECK(mEncParams != NULL);
    memset(mEncParams, 0, sizeof(tagvideoEncOptions));
 if (!PVGetDefaultEncOption(mEncParams, 0)) {
        ALOGE("Failed to get default encoding parameters");
 return OMX_ErrorUndefined;
 }
    mEncParams->encMode = mEncodeMode;
    mEncParams->encWidth[0] = mWidth;
    mEncParams->encHeight[0] = mHeight;
    mEncParams->encFrameRate[0] = mFramerate >> 16; // mFramerate is in Q16 format
    mEncParams->rcType = VBR_1;
    mEncParams->vbvDelay = 5.0f;

    mEncParams->profile_level = CORE_PROFILE_LEVEL2;
    mEncParams->packetSize = 32;
    mEncParams->rvlcEnable = PV_OFF;
    mEncParams->numLayers = 1;
    mEncParams->timeIncRes = 1000;
    mEncParams->tickPerSrc = ((int64_t)mEncParams->timeIncRes << 16) / mFramerate;

    mEncParams->bitRate[0] = mBitrate;
    mEncParams->iQuant[0] = 15;
    mEncParams->pQuant[0] = 12;
    mEncParams->quantType[0] = 0;
    mEncParams->noFrameSkipped = PV_OFF;

 if (mColorFormat != OMX_COLOR_FormatYUV420Planar || mInputDataIsMeta) {
        free(mInputFrameData);
        mInputFrameData = NULL;
 if (((uint64_t)mWidth * mHeight) > ((uint64_t)INT32_MAX / 3)) {
            ALOGE("b/25812794, Buffer size is too big.");
 return OMX_ErrorBadParameter;
 }
        mInputFrameData =
 (uint8_t *) malloc((mWidth * mHeight * 3 ) >> 1);
        CHECK(mInputFrameData != NULL);
 }

 if (mWidth % 16 != 0 || mHeight % 16 != 0) {
        ALOGE("Video frame size %dx%d must be a multiple of 16",
            mWidth, mHeight);
 return OMX_ErrorBadParameter;
 }

 if (mIDRFrameRefreshIntervalInSec < 0) {
        mEncParams->intraPeriod = -1;
 } else if (mIDRFrameRefreshIntervalInSec == 0) {
        mEncParams->intraPeriod = 1; // All I frames
 } else {
        mEncParams->intraPeriod =
 (mIDRFrameRefreshIntervalInSec * mFramerate) >> 16;
 }

    mEncParams->numIntraMB = 0;
    mEncParams->sceneDetect = PV_ON;
    mEncParams->searchRange = 16;
    mEncParams->mv8x8Enable = PV_OFF;
    mEncParams->gobHeaderInterval = 0;
    mEncParams->useACPred = PV_ON;
    mEncParams->intraDCVlcTh = 0;

 return OMX_ErrorNone;
}

 virtual status_t signalEndOfInputStream(node_id node) {
 Parcel data, reply;
 status_t err;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        err = remote()->transact(SIGNAL_END_OF_INPUT_STREAM, data, &reply);
 if (err != OK) {
            ALOGW("binder transaction failed: %d", err);
 return err;
 }

 return reply.readInt32();
 }

OMX_ERRORTYPE SoftG711::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
 if (pcmParams->nPortIndex == 0) {
                pcmParams->ePCMMode = mIsMLaw ? OMX_AUDIO_PCMModeMULaw
 : OMX_AUDIO_PCMModeALaw;
 } else {
                pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
 }
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

void ACodec::notifyOfRenderedFrames(bool dropIncomplete, FrameRenderTracker::Info *until) {
    sp<AMessage> msg = mNotify->dup();
    msg->setInt32("what", CodecBase::kWhatOutputFramesRendered);
    std::list<FrameRenderTracker::Info> done =
        mRenderTracker.checkFencesAndGetRenderedFrames(until, dropIncomplete);

 for (std::list<FrameRenderTracker::Info>::const_iterator it = done.cbegin();
            it != done.cend(); ++it) {
 ssize_t index = it->getIndex();
 if (index >= 0 && (size_t)index < mBuffers[kPortIndexOutput].size()) {
            mBuffers[kPortIndexOutput].editItemAt(index).mRenderInfo = NULL;
 } else if (index >= 0) {
            ALOGE("invalid index %zd in %zu", index, mBuffers[kPortIndexOutput].size());
 }
 }

 if (MediaCodec::CreateFramesRenderedMessage(done, msg)) {
        msg->post();
 }
}

 virtual status_t updateGraphicBufferInMeta(
            node_id node, OMX_U32 port_index,
 const sp<GraphicBuffer> &graphicBuffer, buffer_id buffer) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.write(*graphicBuffer);
        data.writeInt32((int32_t)buffer);
        remote()->transact(UPDATE_GRAPHIC_BUFFER_IN_META, data, &reply);

 status_t err = reply.readInt32();
 return err;
 }

void ACodec::FlushingState::stateEntered() {
    ALOGV("[%s] Now Flushing", mCodec->mComponentName.c_str());

    mFlushComplete[kPortIndexInput] = mFlushComplete[kPortIndexOutput] = false;
}

void ACodec::BaseState::getMoreInputDataIfPossible() {
 if (mCodec->mPortEOS[kPortIndexInput]) {
 return;
 }

 BufferInfo *eligible = NULL;

 for (size_t i = 0; i < mCodec->mBuffers[kPortIndexInput].size(); ++i) {
 BufferInfo *info = &mCodec->mBuffers[kPortIndexInput].editItemAt(i);

#if 0
 if (info->mStatus == BufferInfo::OWNED_BY_UPSTREAM) {
 return;
 }
#endif

 if (info->mStatus == BufferInfo::OWNED_BY_US) {
            eligible = info;
 }
 }

 if (eligible == NULL) {
 return;
 }

    postFillThisBuffer(eligible);
}

status_t BnOMX::onTransact(
uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {
switch (code) {
case LIVES_LOCALLY:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);
node_id node = (node_id)data.readInt32();
pid_t pid = (pid_t)data.readInt32();
reply->writeInt32(livesLocally(node, pid));

return OK;
}

case LIST_NODES:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

List<ComponentInfo> list;
listNodes(&list);

reply->writeInt32(list.size());
for (List<ComponentInfo>::iterator it = list.begin();
it != list.end(); ++it) {
ComponentInfo &cur = *it;

reply->writeString8(cur.mName);
reply->writeInt32(cur.mRoles.size());
for (List<String8>::iterator role_it = cur.mRoles.begin();
role_it != cur.mRoles.end(); ++role_it) {
reply->writeString8(*role_it);
}
}

return NO_ERROR;
}

case ALLOCATE_NODE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

const char *name = data.readCString();

sp<IOMXObserver> observer =
interface_cast<IOMXObserver>(data.readStrongBinder());

node_id node;

status_t err = allocateNode(name, observer, &node);
reply->writeInt32(err);
if (err == OK) {
reply->writeInt32((int32_t)node);
}

return NO_ERROR;
}

case FREE_NODE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();

reply->writeInt32(freeNode(node));

return NO_ERROR;
}

case SEND_COMMAND:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();

OMX_COMMANDTYPE cmd =
static_cast<OMX_COMMANDTYPE>(data.readInt32());

OMX_S32 param = data.readInt32();
reply->writeInt32(sendCommand(node, cmd, param));

return NO_ERROR;
}

case GET_PARAMETER:
case SET_PARAMETER:
case GET_CONFIG:
case SET_CONFIG:
case SET_INTERNAL_OPTION:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_INDEXTYPE index = static_cast<OMX_INDEXTYPE>(data.readInt32());


size_t size = data.readInt64();

            status_t err = NO_MEMORY;
            void *params = calloc(size, 1);
            if (params) {
                err = data.read(params, size);
                if (err != OK) {
                    android_errorWriteLog(0x534e4554, "26914474");
} else {
                    switch (code) {
                        case GET_PARAMETER:
                            err = getParameter(node, index, params, size);
                            break;
                        case SET_PARAMETER:
                            err = setParameter(node, index, params, size);
                            break;
                        case GET_CONFIG:
                            err = getConfig(node, index, params, size);
                            break;
                        case SET_CONFIG:
                            err = setConfig(node, index, params, size);
                            break;
                        case SET_INTERNAL_OPTION:
                        {
                            InternalOptionType type =
                                (InternalOptionType)data.readInt32();

                            err = setInternalOption(node, index, type, params, size);
                            break;
}
                        default:
                            TRESPASS();
}
}
}

reply->writeInt32(err);

if ((code == GET_PARAMETER || code == GET_CONFIG) && err == OK) {

reply->write(params, size);
}

            free(params);
params = NULL;

return NO_ERROR;
}

case GET_STATE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_STATETYPE state = OMX_StateInvalid;

status_t err = getState(node, &state);
reply->writeInt32(state);
reply->writeInt32(err);

return NO_ERROR;
}

case ENABLE_GRAPHIC_BUFFERS:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL enable = (OMX_BOOL)data.readInt32();

status_t err = enableGraphicBuffers(node, port_index, enable);
reply->writeInt32(err);

return NO_ERROR;
}

case GET_GRAPHIC_BUFFER_USAGE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();

OMX_U32 usage = 0;
status_t err = getGraphicBufferUsage(node, port_index, &usage);
reply->writeInt32(err);
reply->writeInt32(usage);

return NO_ERROR;
}

case USE_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<IMemory> params =
interface_cast<IMemory>(data.readStrongBinder());
OMX_U32 allottedSize = data.readInt32();

buffer_id buffer;
status_t err = useBuffer(node, port_index, params, &buffer, allottedSize);
reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
}

return NO_ERROR;
}

case USE_GRAPHIC_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();
data.read(*graphicBuffer);

buffer_id buffer;
status_t err = useGraphicBuffer(
node, port_index, graphicBuffer, &buffer);
reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
}

return NO_ERROR;
}

case UPDATE_GRAPHIC_BUFFER_IN_META:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();
data.read(*graphicBuffer);
buffer_id buffer = (buffer_id)data.readInt32();

status_t err = updateGraphicBufferInMeta(
node, port_index, graphicBuffer, buffer);
reply->writeInt32(err);

return NO_ERROR;
}

case CREATE_INPUT_SURFACE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();

sp<IGraphicBufferProducer> bufferProducer;
MetadataBufferType type = kMetadataBufferTypeInvalid;
status_t err = createInputSurface(node, port_index, &bufferProducer, &type);

if ((err != OK) && (type == kMetadataBufferTypeInvalid)) {
android_errorWriteLog(0x534e4554, "26324358");
}

reply->writeInt32(type);
reply->writeInt32(err);

if (err == OK) {
reply->writeStrongBinder(IInterface::asBinder(bufferProducer));
}

return NO_ERROR;
}

case CREATE_PERSISTENT_INPUT_SURFACE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

sp<IGraphicBufferProducer> bufferProducer;
sp<IGraphicBufferConsumer> bufferConsumer;
status_t err = createPersistentInputSurface(
&bufferProducer, &bufferConsumer);

reply->writeInt32(err);

if (err == OK) {
reply->writeStrongBinder(IInterface::asBinder(bufferProducer));
reply->writeStrongBinder(IInterface::asBinder(bufferConsumer));
}

return NO_ERROR;
}

case SET_INPUT_SURFACE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();

sp<IGraphicBufferConsumer> bufferConsumer =
interface_cast<IGraphicBufferConsumer>(data.readStrongBinder());

MetadataBufferType type = kMetadataBufferTypeInvalid;
status_t err = setInputSurface(node, port_index, bufferConsumer, &type);

if ((err != OK) && (type == kMetadataBufferTypeInvalid)) {
android_errorWriteLog(0x534e4554, "26324358");
}

reply->writeInt32(type);
reply->writeInt32(err);
return NO_ERROR;
}

case SIGNAL_END_OF_INPUT_STREAM:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();

status_t err = signalEndOfInputStream(node);
reply->writeInt32(err);

return NO_ERROR;
}

case STORE_META_DATA_IN_BUFFERS:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL enable = (OMX_BOOL)data.readInt32();

MetadataBufferType type = kMetadataBufferTypeInvalid;
status_t err = storeMetaDataInBuffers(node, port_index, enable, &type);

reply->writeInt32(type);
reply->writeInt32(err);

return NO_ERROR;
}

case PREPARE_FOR_ADAPTIVE_PLAYBACK:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL enable = (OMX_BOOL)data.readInt32();
OMX_U32 max_width = data.readInt32();
OMX_U32 max_height = data.readInt32();

status_t err = prepareForAdaptivePlayback(
node, port_index, enable, max_width, max_height);
reply->writeInt32(err);

return NO_ERROR;
}

case CONFIGURE_VIDEO_TUNNEL_MODE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();
OMX_U32 audio_hw_sync = data.readInt32();

native_handle_t *sideband_handle = NULL;
status_t err = configureVideoTunnelMode(
node, port_index, tunneled, audio_hw_sync, &sideband_handle);
reply->writeInt32(err);
if(err == OK){
reply->writeNativeHandle(sideband_handle);
}

return NO_ERROR;
}

case ALLOC_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
if (!isSecure(node) || port_index != 0 /* kPortIndexInput */) {
ALOGE("b/24310423");
reply->writeInt32(INVALID_OPERATION);
return NO_ERROR;
}

size_t size = data.readInt64();

buffer_id buffer;
void *buffer_data;
status_t err = allocateBuffer(
node, port_index, size, &buffer, &buffer_data);
reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
reply->writeInt64((uintptr_t)buffer_data);
}

return NO_ERROR;
}

case ALLOC_BUFFER_WITH_BACKUP:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<IMemory> params =
interface_cast<IMemory>(data.readStrongBinder());
OMX_U32 allottedSize = data.readInt32();

buffer_id buffer;
status_t err = allocateBufferWithBackup(
node, port_index, params, &buffer, allottedSize);

reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
}

return NO_ERROR;
}

case FREE_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
buffer_id buffer = (buffer_id)data.readInt32();
reply->writeInt32(freeBuffer(node, port_index, buffer));

return NO_ERROR;
}

case FILL_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
buffer_id buffer = (buffer_id)data.readInt32();
bool haveFence = data.readInt32();
int fenceFd = haveFence ? ::dup(data.readFileDescriptor()) : -1;
reply->writeInt32(fillBuffer(node, buffer, fenceFd));

return NO_ERROR;
}

case EMPTY_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
buffer_id buffer = (buffer_id)data.readInt32();
OMX_U32 range_offset = data.readInt32();
OMX_U32 range_length = data.readInt32();
OMX_U32 flags = data.readInt32();
OMX_TICKS timestamp = data.readInt64();
bool haveFence = data.readInt32();
int fenceFd = haveFence ? ::dup(data.readFileDescriptor()) : -1;
reply->writeInt32(emptyBuffer(
node, buffer, range_offset, range_length, flags, timestamp, fenceFd));

return NO_ERROR;
}

case GET_EXTENSION_INDEX:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
const char *parameter_name = data.readCString();

OMX_INDEXTYPE index;
status_t err = getExtensionIndex(node, parameter_name, &index);

reply->writeInt32(err);

if (err == OK) {
reply->writeInt32(index);
}

return OK;
}

default:
return BBinder::onTransact(code, data, reply, flags);
}
}

OMX_ERRORTYPE SoftVPXEncoder::internalGetParameter(OMX_INDEXTYPE index,
OMX_PTR param) {
// can include extension index OMX_INDEXEXTTYPE
const int32_t indexFull = index;

switch (indexFull) {
case OMX_IndexParamVideoBitrate: {

OMX_VIDEO_PARAM_BITRATETYPE *bitrate =
(OMX_VIDEO_PARAM_BITRATETYPE *)param;

                if (bitrate->nPortIndex != kOutputPortIndex) {
                    return OMX_ErrorUnsupportedIndex;
                }

                bitrate->nTargetBitrate = mBitrate;

                if (mBitrateControlMode == VPX_VBR) {
                    bitrate->eControlRate = OMX_Video_ControlRateVariable;
                } else if (mBitrateControlMode == VPX_CBR) {
                    bitrate->eControlRate = OMX_Video_ControlRateConstant;
                } else {
                    return OMX_ErrorUnsupportedSetting;
                }
                return OMX_ErrorNone;
}

// VP8 specific parameters that use extension headers
case OMX_IndexParamVideoVp8: {

OMX_VIDEO_PARAM_VP8TYPE *vp8Params =
(OMX_VIDEO_PARAM_VP8TYPE *)param;

                if (vp8Params->nPortIndex != kOutputPortIndex) {
                    return OMX_ErrorUnsupportedIndex;
                }

                vp8Params->eProfile = OMX_VIDEO_VP8ProfileMain;
                vp8Params->eLevel = mLevel;
                vp8Params->nDCTPartitions = mDCTPartitions;
                vp8Params->bErrorResilientMode = mErrorResilience;
                return OMX_ErrorNone;
}

case OMX_IndexParamVideoAndroidVp8Encoder: {
OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE *vp8AndroidParams =
(OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE *)param;

                if (vp8AndroidParams->nPortIndex != kOutputPortIndex) {
                    return OMX_ErrorUnsupportedIndex;
                }

                vp8AndroidParams->nKeyFrameInterval = mKeyFrameInterval;
                vp8AndroidParams->eTemporalPattern = mTemporalPatternType;
                vp8AndroidParams->nTemporalLayerCount = mTemporalLayers;
                vp8AndroidParams->nMinQuantizer = mMinQuantizer;
                vp8AndroidParams->nMaxQuantizer = mMaxQuantizer;
                memcpy(vp8AndroidParams->nTemporalLayerBitrateRatio,
                       mTemporalLayerBitrateRatio, sizeof(mTemporalLayerBitrateRatio));
                return OMX_ErrorNone;
}

default:
return SoftVideoEncoderOMXComponent::internalGetParameter(index, param);
}
}

bool ACodec::allYourBuffersAreBelongToUs(
        OMX_U32 portIndex) {
 for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
 BufferInfo *info = &mBuffers[portIndex].editItemAt(i);

 if (info->mStatus != BufferInfo::OWNED_BY_US
 && info->mStatus != BufferInfo::OWNED_BY_NATIVE_WINDOW) {
            ALOGV("[%s] Buffer %u on port %u still has status %d",
                    mComponentName.c_str(),
                    info->mBufferID, portIndex, info->mStatus);
 return false;
 }
 }

 return true;
}

status_t ACodec::setVideoFormatOnPort(
        OMX_U32 portIndex,
 int32_t width, int32_t height, OMX_VIDEO_CODINGTYPE compressionFormat,
 float frameRate) {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

    OMX_VIDEO_PORTDEFINITIONTYPE *video_def = &def.format.video;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
 if (err != OK) {
 return err;
 }

 if (portIndex == kPortIndexInput) {
 const size_t X = 64 * 1024;
 if (def.nBufferSize < X) {
            def.nBufferSize = X;
 }
 }

 if (def.eDomain != OMX_PortDomainVideo) {
        ALOGE("expected video port, got %s(%d)", asString(def.eDomain), def.eDomain);
 return FAILED_TRANSACTION;
 }

    video_def->nFrameWidth = width;
    video_def->nFrameHeight = height;

 if (portIndex == kPortIndexInput) {
        video_def->eCompressionFormat = compressionFormat;
        video_def->eColorFormat = OMX_COLOR_FormatUnused;
 if (frameRate >= 0) {
            video_def->xFramerate = (OMX_U32)(frameRate * 65536.0f);
 }
 }

    err = mOMX->setParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 return err;
}

SoftAACEncoder::~SoftAACEncoder() {
 delete[] mInputFrame;
    mInputFrame = NULL;

 if (mEncoderHandle) {
        CHECK_EQ(VO_ERR_NONE, mApiHandle->Uninit(mEncoderHandle));
        mEncoderHandle = NULL;
 }

 delete mApiHandle;
    mApiHandle = NULL;

 delete mMemOperator;
    mMemOperator = NULL;
}

void ACodec::IdleToExecutingState::stateEntered() {
    ALOGV("[%s] Now Idle->Executing", mCodec->mComponentName.c_str());
}

void SimpleSoftOMXComponent::onPortEnable(OMX_U32 portIndex, bool enable) {
    CHECK_LT(portIndex, mPorts.size());

 PortInfo *port = &mPorts.editItemAt(portIndex);
    CHECK_EQ((int)port->mTransition, (int)PortInfo::NONE);
    CHECK(port->mDef.bEnabled == !enable);

 if (!enable) {
        port->mDef.bEnabled = OMX_FALSE;
        port->mTransition = PortInfo::DISABLING;

 for (size_t i = 0; i < port->mBuffers.size(); ++i) {
 BufferInfo *buffer = &port->mBuffers.editItemAt(i);

 if (buffer->mOwnedByUs) {
                buffer->mOwnedByUs = false;

 if (port->mDef.eDir == OMX_DirInput) {
                    notifyEmptyBufferDone(buffer->mHeader);
 } else {
                    CHECK_EQ(port->mDef.eDir, OMX_DirOutput);
                    notifyFillBufferDone(buffer->mHeader);
 }
 }
 }

        port->mQueue.clear();
 } else {
        port->mTransition = PortInfo::ENABLING;
 }

    checkTransitions();
}

OMX_ERRORTYPE SoftFlacEncoder::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
    ALOGV("SoftFlacEncoder::internalGetParameter(index=0x%x)", index);

 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSampleRate;

 return OMX_ErrorNone;
 }


         case OMX_IndexParamAudioFlac:
         {
             OMX_AUDIO_PARAM_FLACTYPE *flacParams = (OMX_AUDIO_PARAM_FLACTYPE *)params;
             flacParams->nCompressionLevel = mCompressionLevel;
             flacParams->nChannels = mNumChannels;
             flacParams->nSampleRate = mSampleRate;
 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

static status_t ConvertOmxAvcLevelToAvcSpecLevel(
        OMX_U32 omxLevel, AVCLevel *avcLevel) {
 for (size_t i = 0, n = sizeof(ConversionTable)/sizeof(ConversionTable[0]);
        i < n; ++i) {
 if (omxLevel == ConversionTable[i].omxLevel) {
 *avcLevel = ConversionTable[i].avcLevel;
 return OK;
 }
 }

    ALOGE("ConvertOmxAvcLevelToAvcSpecLevel: %d level not supported",
 (int32_t)omxLevel);

 return BAD_VALUE;
}

OMX_ERRORTYPE SoftAMRWBEncoder::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPortFormat:
 {

             OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

            formatParams->eEncoding =
 (formatParams->nPortIndex == 0)
 ? OMX_AUDIO_CodingPCM : OMX_AUDIO_CodingAMR;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAmr:
 {

             OMX_AUDIO_PARAM_AMRTYPE *amrParams =
                 (OMX_AUDIO_PARAM_AMRTYPE *)params;
 
             if (amrParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            amrParams->nChannels = 1;
            amrParams->nBitRate = mBitRate;

            amrParams->eAMRBandMode =
 (OMX_AUDIO_AMRBANDMODETYPE)(mMode + OMX_AUDIO_AMRBandModeWB0);

            amrParams->eAMRDTXMode = OMX_AUDIO_AMRDTXModeOff;
            amrParams->eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelCF;

            pcmParams->nChannels = 1;
            pcmParams->nSamplingRate = kSampleRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

status_t SoftAMRNBEncoder::initEncoder() {
 if (AMREncodeInit(&mEncState, &mSidState, false /* dtx_enable */) != 0) {
 return UNKNOWN_ERROR;
 }

 return OK;
}

OMX_ERRORTYPE SoftFlacEncoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             ALOGV("SoftFlacEncoder::internalSetParameter(OMX_IndexParamAudioPcm)");
             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams = (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0 && pcmParams->nPortIndex != 1) {
                 ALOGE("SoftFlacEncoder::internalSetParameter() Error #1");
                 return OMX_ErrorUndefined;
 }

 if (pcmParams->nChannels < 1 || pcmParams->nChannels > 2) {
 return OMX_ErrorUndefined;
 }

            mNumChannels = pcmParams->nChannels;
            mSampleRate = pcmParams->nSamplingRate;
            ALOGV("will encode %d channels at %dHz", mNumChannels, mSampleRate);

 return configureEncoder();
 }

 case OMX_IndexParamStandardComponentRole:
 {
            ALOGV("SoftFlacEncoder::internalSetParameter(OMX_IndexParamStandardComponentRole)");

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                     "audio_encoder.flac",
                     OMX_MAX_STRINGNAME_SIZE - 1)) {
                ALOGE("SoftFlacEncoder::internalSetParameter(OMX_IndexParamStandardComponentRole)"
 "error");
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioFlac:

         {
             OMX_AUDIO_PARAM_FLACTYPE *flacParams = (OMX_AUDIO_PARAM_FLACTYPE *)params;
             mCompressionLevel = flacParams->nCompressionLevel; // range clamping done inside encoder
             return OMX_ErrorNone;
         }

 case OMX_IndexParamPortDefinition:
 {

             OMX_PARAM_PORTDEFINITIONTYPE *defParams =
                 (OMX_PARAM_PORTDEFINITIONTYPE *)params;
 
             if (defParams->nPortIndex == 0) {
                 if (defParams->nBufferSize > kMaxInputBufferSize) {
                     ALOGE("Input buffer size must be at most %d bytes",
                        kMaxInputBufferSize);
 return OMX_ErrorUnsupportedSetting;
 }
 }

 }

 default:
            ALOGV("SoftFlacEncoder::internalSetParameter(default)");
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

 virtual status_t storeMetaDataInBuffers(
            node_id node, OMX_U32 port_index, OMX_BOOL enable, MetadataBufferType *type) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeInt32((uint32_t)enable);
        remote()->transact(STORE_META_DATA_IN_BUFFERS, data, &reply);

 int negotiatedType = reply.readInt32();
 if (type != NULL) {
 *type = (MetadataBufferType)negotiatedType;
 }

 return reply.readInt32();
 }

void ACodec::ExecutingState::submitOutputMetaBuffers() {
 for (size_t i = 0; i < mCodec->mBuffers[kPortIndexInput].size(); ++i) {
 BufferInfo *info = &mCodec->mBuffers[kPortIndexInput].editItemAt(i);

 if (info->mStatus == BufferInfo::OWNED_BY_COMPONENT) {
 if (mCodec->submitOutputMetadataBuffer() != OK)
 break;
 }
 }

    mCodec->signalSubmitOutputMetadataBufferIfEOS_workaround();
}

bool ACodec::BaseState::onMessageReceived(const sp<AMessage> &msg) {
 switch (msg->what()) {
 case kWhatInputBufferFilled:
 {
            onInputBufferFilled(msg);
 break;
 }

 case kWhatOutputBufferDrained:
 {
            onOutputBufferDrained(msg);
 break;
 }

 case ACodec::kWhatOMXMessageList:
 {
 return checkOMXMessage(msg) ? onOMXMessageList(msg) : true;
 }

 case ACodec::kWhatOMXMessageItem:
 {
 return onOMXMessage(msg);
 }

 case ACodec::kWhatOMXMessage:
 {
 return checkOMXMessage(msg) ? onOMXMessage(msg) : true;
 }

 case ACodec::kWhatSetSurface:
 {
            sp<AReplyToken> replyID;
            CHECK(msg->senderAwaitsResponse(&replyID));

            sp<RefBase> obj;
            CHECK(msg->findObject("surface", &obj));

 status_t err = mCodec->handleSetSurface(static_cast<Surface *>(obj.get()));

            sp<AMessage> response = new AMessage;
            response->setInt32("err", err);
            response->postReply(replyID);
 break;
 }

 case ACodec::kWhatCreateInputSurface:
 case ACodec::kWhatSetInputSurface:
 case ACodec::kWhatSignalEndOfInputStream:
 {
            ALOGE("Message 0x%x was not handled", msg->what());
            mCodec->signalError(OMX_ErrorUndefined, INVALID_OPERATION);
 return true;
 }

 case ACodec::kWhatOMXDied:
 {
            ALOGE("OMX/mediaserver died, signalling error!");
            mCodec->signalError(OMX_ErrorResourcesLost, DEAD_OBJECT);
 break;
 }

 case ACodec::kWhatReleaseCodecInstance:
 {
            ALOGI("[%s] forcing the release of codec",
                    mCodec->mComponentName.c_str());
 status_t err = mCodec->mOMX->freeNode(mCodec->mNode);
            ALOGE_IF("[%s] failed to release codec instance: err=%d",
                       mCodec->mComponentName.c_str(), err);
            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatShutdownCompleted);
            notify->post();
 break;
 }

 default:
 return false;
 }

 return true;
}

void SoftVPXEncoder::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mCodecContext == NULL) {
 if (OK != initEncoder()) {
            ALOGE("Failed to initialize encoder");
            notify(OMX_EventError,
                   OMX_ErrorUndefined,
 0, // Extra notification data
                   NULL); // Notification data pointer
 return;
 }
 }

 vpx_codec_err_t codec_return;
 List<BufferInfo *> &inputBufferInfoQueue = getPortQueue(kInputPortIndex);
 List<BufferInfo *> &outputBufferInfoQueue = getPortQueue(kOutputPortIndex);

 while (!inputBufferInfoQueue.empty() && !outputBufferInfoQueue.empty()) {
 BufferInfo *inputBufferInfo = *inputBufferInfoQueue.begin();
        OMX_BUFFERHEADERTYPE *inputBufferHeader = inputBufferInfo->mHeader;

 BufferInfo *outputBufferInfo = *outputBufferInfoQueue.begin();
        OMX_BUFFERHEADERTYPE *outputBufferHeader = outputBufferInfo->mHeader;

 if ((inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) &&
                inputBufferHeader->nFilledLen == 0) {
            inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());
            inputBufferInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inputBufferHeader);

            outputBufferHeader->nFilledLen = 0;
            outputBufferHeader->nFlags = OMX_BUFFERFLAG_EOS;

            outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());
            outputBufferInfo->mOwnedByUs = false;
            notifyFillBufferDone(outputBufferHeader);
 return;
 }

 const uint8_t *source =
            inputBufferHeader->pBuffer + inputBufferHeader->nOffset;

 size_t frameSize = mWidth * mHeight * 3 / 2;
 if (mInputDataIsMeta) {
            source = extractGraphicBuffer(
                    mConversionBuffer, frameSize,
                    source, inputBufferHeader->nFilledLen,
                    mWidth, mHeight);
 if (source == NULL) {
                ALOGE("Unable to extract gralloc buffer in metadata mode");
                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return;
 }
 } else {
 if (inputBufferHeader->nFilledLen < frameSize) {
                android_errorWriteLog(0x534e4554, "27569635");
                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return;
 } else if (inputBufferHeader->nFilledLen > frameSize) {
                ALOGW("Input buffer contains too many pixels");
 }

 if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {
 ConvertYUV420SemiPlanarToYUV420Planar(
                        source, mConversionBuffer, mWidth, mHeight);

                source = mConversionBuffer;
 }
 }
 vpx_image_t raw_frame;
        vpx_img_wrap(&raw_frame, VPX_IMG_FMT_I420, mWidth, mHeight,
                     kInputBufferAlignment, (uint8_t *)source);

 vpx_enc_frame_flags_t flags = 0;
 if (mTemporalPatternLength > 0) {
            flags = getEncodeFlags();
 }
 if (mKeyFrameRequested) {
            flags |= VPX_EFLAG_FORCE_KF;
            mKeyFrameRequested = false;
 }

 if (mBitrateUpdated) {
            mCodecConfiguration->rc_target_bitrate = mBitrate/1000;
 vpx_codec_err_t res = vpx_codec_enc_config_set(mCodecContext,
                                                           mCodecConfiguration);
 if (res != VPX_CODEC_OK) {
                ALOGE("vp8 encoder failed to update bitrate: %s",
                      vpx_codec_err_to_string(res));
                notify(OMX_EventError,
                       OMX_ErrorUndefined,
 0, // Extra notification data
                       NULL); // Notification data pointer
 }
            mBitrateUpdated = false;
 }

 uint32_t frameDuration;
 if (inputBufferHeader->nTimeStamp > mLastTimestamp) {
            frameDuration = (uint32_t)(inputBufferHeader->nTimeStamp - mLastTimestamp);
 } else {
            frameDuration = (uint32_t)(((uint64_t)1000000 << 16) / mFramerate);
 }
        mLastTimestamp = inputBufferHeader->nTimeStamp;
        codec_return = vpx_codec_encode(
                mCodecContext,
 &raw_frame,
                inputBufferHeader->nTimeStamp, // in timebase units
                frameDuration, // frame duration in timebase units
                flags, // frame flags
                VPX_DL_REALTIME); // encoding deadline
 if (codec_return != VPX_CODEC_OK) {
            ALOGE("vpx encoder failed to encode frame");
            notify(OMX_EventError,
                   OMX_ErrorUndefined,
 0, // Extra notification data
                   NULL); // Notification data pointer
 return;
 }

 vpx_codec_iter_t encoded_packet_iterator = NULL;
 const vpx_codec_cx_pkt_t* encoded_packet;

 while ((encoded_packet = vpx_codec_get_cx_data(
                        mCodecContext, &encoded_packet_iterator))) {
 if (encoded_packet->kind == VPX_CODEC_CX_FRAME_PKT) {
                outputBufferHeader->nTimeStamp = encoded_packet->data.frame.pts;
                outputBufferHeader->nFlags = 0;
 if (encoded_packet->data.frame.flags & VPX_FRAME_IS_KEY)
                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;
                outputBufferHeader->nOffset = 0;
                outputBufferHeader->nFilledLen = encoded_packet->data.frame.sz;
 if (outputBufferHeader->nFilledLen > outputBufferHeader->nAllocLen) {
                    android_errorWriteLog(0x534e4554, "27569635");
                    notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return;
 }
                memcpy(outputBufferHeader->pBuffer,
                       encoded_packet->data.frame.buf,
                       encoded_packet->data.frame.sz);
                outputBufferInfo->mOwnedByUs = false;
                outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());
 if (inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_EOS;
 }
                notifyFillBufferDone(outputBufferHeader);
 }
 }

        inputBufferInfo->mOwnedByUs = false;
        inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());
        notifyEmptyBufferDone(inputBufferHeader);
 }
}

OMX_ERRORTYPE SoftAAC2::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.aac",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {

             const OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
                 (const OMX_AUDIO_PARAM_AACPROFILETYPE *)params;
 
             if (aacParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 if (aacParams->eAACStreamFormat == OMX_AUDIO_AACStreamFormatMP4FF) {
                mIsADTS = false;
 } else if (aacParams->eAACStreamFormat
 == OMX_AUDIO_AACStreamFormatMP4ADTS) {
                mIsADTS = true;
 } else {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAndroidAacPresentation:

         {
             const OMX_AUDIO_PARAM_ANDROID_AACPRESENTATIONTYPE *aacPresParams =
                     (const OMX_AUDIO_PARAM_ANDROID_AACPRESENTATIONTYPE *)params;
 if (aacPresParams->nMaxOutputChannels >= 0) {
 int max;
 if (aacPresParams->nMaxOutputChannels >= 8) { max = 8; }
 else if (aacPresParams->nMaxOutputChannels >= 6) { max = 6; }
 else if (aacPresParams->nMaxOutputChannels >= 2) { max = 2; }
 else {
                    max = aacPresParams->nMaxOutputChannels;
 }
                ALOGV("set nMaxOutputChannels=%d", max);
                aacDecoder_SetParam(mAACDecoder, AAC_PCM_MAX_OUTPUT_CHANNELS, max);
 }
 bool updateDrcWrapper = false;
 if (aacPresParams->nDrcBoost >= 0) {
                ALOGV("set nDrcBoost=%d", aacPresParams->nDrcBoost);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_BOOST_FACTOR,
                        aacPresParams->nDrcBoost);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nDrcCut >= 0) {
                ALOGV("set nDrcCut=%d", aacPresParams->nDrcCut);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_ATT_FACTOR, aacPresParams->nDrcCut);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nHeavyCompression >= 0) {
                ALOGV("set nHeavyCompression=%d", aacPresParams->nHeavyCompression);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_HEAVY,
                        aacPresParams->nHeavyCompression);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nTargetReferenceLevel >= 0) {
                ALOGV("set nTargetReferenceLevel=%d", aacPresParams->nTargetReferenceLevel);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_TARGET,
                        aacPresParams->nTargetReferenceLevel);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nEncodedTargetLevel >= 0) {
                ALOGV("set nEncodedTargetLevel=%d", aacPresParams->nEncodedTargetLevel);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_ENCODER_TARGET,
                        aacPresParams->nEncodedTargetLevel);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nPCMLimiterEnable >= 0) {
                aacDecoder_SetParam(mAACDecoder, AAC_PCM_LIMITER_ENABLE,
 (aacPresParams->nPCMLimiterEnable != 0));
 }
 if (updateDrcWrapper) {
                mDrcWrap.update();
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

status_t ACodec::configureOutputBuffersFromNativeWindow(
        OMX_U32 *bufferCount, OMX_U32 *bufferSize,
        OMX_U32 *minUndequeuedBuffers) {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = kPortIndexOutput;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err == OK) {
        err = setupNativeWindowSizeFormatAndUsage(mNativeWindow.get(), &mNativeWindowUsageBits);
 }
 if (err != OK) {
        mNativeWindowUsageBits = 0;
 return err;
 }

 if (mTunneled) {
        ALOGV("Tunneled Playback: skipping native window buffer allocation.");
        def.nBufferCountActual = 0;
        err = mOMX->setParameter(
                mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 *minUndequeuedBuffers = 0;
 *bufferCount = 0;
 *bufferSize = 0;
 return err;
 }

 *minUndequeuedBuffers = 0;
    err = mNativeWindow->query(
            mNativeWindow.get(), NATIVE_WINDOW_MIN_UNDEQUEUED_BUFFERS,
 (int *)minUndequeuedBuffers);

 if (err != 0) {
        ALOGE("NATIVE_WINDOW_MIN_UNDEQUEUED_BUFFERS query failed: %s (%d)",
                strerror(-err), -err);
 return err;
 }


 for (OMX_U32 extraBuffers = 2 + 1; /* condition inside loop */; extraBuffers--) {
        OMX_U32 newBufferCount =
            def.nBufferCountMin + *minUndequeuedBuffers + extraBuffers;
        def.nBufferCountActual = newBufferCount;
        err = mOMX->setParameter(
                mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err == OK) {
 *minUndequeuedBuffers += extraBuffers;
 break;
 }

        ALOGW("[%s] setting nBufferCountActual to %u failed: %d",
                mComponentName.c_str(), newBufferCount, err);
 /* exit condition */
 if (extraBuffers == 0) {
 return err;
 }
 }

    err = native_window_set_buffer_count(
            mNativeWindow.get(), def.nBufferCountActual);

 if (err != 0) {
        ALOGE("native_window_set_buffer_count failed: %s (%d)", strerror(-err),
 -err);
 return err;
 }

 *bufferCount = def.nBufferCountActual;
 *bufferSize =  def.nBufferSize;
 return err;
}

status_t ACodec::configureTunneledVideoPlayback(
 int32_t audioHwSync, const sp<ANativeWindow> &nativeWindow) {
 native_handle_t* sidebandHandle;

 status_t err = mOMX->configureVideoTunnelMode(
            mNode, kPortIndexOutput, OMX_TRUE, audioHwSync, &sidebandHandle);
 if (err != OK) {
        ALOGE("configureVideoTunnelMode failed! (err %d).", err);
 return err;
 }

    err = native_window_set_sideband_stream(nativeWindow.get(), sidebandHandle);
 if (err != OK) {
        ALOGE("native_window_set_sideband_stream(%p) failed! (err %d).",
                sidebandHandle, err);
 return err;
 }

 return OK;
}

    std::list<sp<AMessage> > &getList() { return mList; }

OMX_ERRORTYPE SoftAVC::releaseEncoder() {
    IV_STATUS_T status = IV_SUCCESS;
 iv_retrieve_mem_rec_ip_t s_retrieve_mem_ip;
 iv_retrieve_mem_rec_op_t s_retrieve_mem_op;
 iv_mem_rec_t *ps_mem_rec;

 if (!mStarted) {
 return OMX_ErrorNone;
 }

    s_retrieve_mem_ip.u4_size = sizeof(iv_retrieve_mem_rec_ip_t);
    s_retrieve_mem_op.u4_size = sizeof(iv_retrieve_mem_rec_op_t);
    s_retrieve_mem_ip.e_cmd = IV_CMD_RETRIEVE_MEMREC;
    s_retrieve_mem_ip.ps_mem_rec = mMemRecords;

    status = ive_api_function(mCodecCtx, &s_retrieve_mem_ip, &s_retrieve_mem_op);

 if (status != IV_SUCCESS) {
        ALOGE("Unable to retrieve memory records = 0x%x\n",
                s_retrieve_mem_op.u4_error_code);
 return OMX_ErrorUndefined;
 }

 /* Free memory records */
    ps_mem_rec = mMemRecords;
 for (size_t i = 0; i < s_retrieve_mem_op.u4_num_mem_rec_filled; i++) {
        ive_aligned_free(ps_mem_rec->pv_base);
        ps_mem_rec++;
 }

    free(mMemRecords);

 for (size_t i = 0; i < MAX_CONVERSION_BUFFERS; i++) {
 if (mConversionBuffers[i]) {
            free(mConversionBuffers[i]);
            mConversionBuffers[i] = NULL;
 }
 }

    mStarted = false;

 return OMX_ErrorNone;
}

OMX_ERRORTYPE SoftAVC::initEncoder() {
    IV_STATUS_T status;
    WORD32 level;
 uint32_t displaySizeY;
    CHECK(!mStarted);

    OMX_ERRORTYPE errType = OMX_ErrorNone;

    displaySizeY = mWidth * mHeight;
 if (displaySizeY > (1920 * 1088)) {
        level = 50;
 } else if (displaySizeY > (1280 * 720)) {
        level = 40;
 } else if (displaySizeY > (720 * 576)) {
        level = 31;
 } else if (displaySizeY > (624 * 320)) {
        level = 30;
 } else if (displaySizeY > (352 * 288)) {
        level = 21;
 } else {
        level = 20;
 }
    mAVCEncLevel = MAX(level, mAVCEncLevel);

    mStride = mWidth;

 if (mInputDataIsMeta) {
 for (size_t i = 0; i < MAX_CONVERSION_BUFFERS; i++) {
 if (mConversionBuffers[i] != NULL) {
                free(mConversionBuffers[i]);
                mConversionBuffers[i] = 0;
 }

 if (((uint64_t)mStride * mHeight) > ((uint64_t)INT32_MAX / 3)) {
                ALOGE("Buffer size is too big.");
 return OMX_ErrorUndefined;
 }
            mConversionBuffers[i] = (uint8_t *)malloc(mStride * mHeight * 3 / 2);

 if (mConversionBuffers[i] == NULL) {
                ALOGE("Allocating conversion buffer failed.");
 return OMX_ErrorUndefined;
 }

            mConversionBuffersFree[i] = 1;
 }
 }

 switch (mColorFormat) {
 case OMX_COLOR_FormatYUV420SemiPlanar:
            mIvVideoColorFormat = IV_YUV_420SP_UV;
            ALOGV("colorFormat YUV_420SP");
 break;
 default:
 case OMX_COLOR_FormatYUV420Planar:
            mIvVideoColorFormat = IV_YUV_420P;
            ALOGV("colorFormat YUV_420P");
 break;
 }

    ALOGD("Params width %d height %d level %d colorFormat %d", mWidth,
            mHeight, mAVCEncLevel, mIvVideoColorFormat);

 /* Getting Number of MemRecords */
 {
 iv_num_mem_rec_ip_t s_num_mem_rec_ip;
 iv_num_mem_rec_op_t s_num_mem_rec_op;

        s_num_mem_rec_ip.u4_size = sizeof(iv_num_mem_rec_ip_t);
        s_num_mem_rec_op.u4_size = sizeof(iv_num_mem_rec_op_t);

        s_num_mem_rec_ip.e_cmd = IV_CMD_GET_NUM_MEM_REC;

        status = ive_api_function(0, &s_num_mem_rec_ip, &s_num_mem_rec_op);

 if (status != IV_SUCCESS) {
            ALOGE("Get number of memory records failed = 0x%x\n",
                    s_num_mem_rec_op.u4_error_code);
 return OMX_ErrorUndefined;
 }

        mNumMemRecords = s_num_mem_rec_op.u4_num_mem_rec;
 }

 /* Allocate array to hold memory records */
 if (mNumMemRecords > SIZE_MAX / sizeof(iv_mem_rec_t)) {
        ALOGE("requested memory size is too big.");
 return OMX_ErrorUndefined;
 }
    mMemRecords = (iv_mem_rec_t *)malloc(mNumMemRecords * sizeof(iv_mem_rec_t));
 if (NULL == mMemRecords) {
        ALOGE("Unable to allocate memory for hold memory records: Size %zu",
                mNumMemRecords * sizeof(iv_mem_rec_t));
        mSignalledError = true;
        notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return OMX_ErrorUndefined;
 }

 {
 iv_mem_rec_t *ps_mem_rec;
        ps_mem_rec = mMemRecords;
 for (size_t i = 0; i < mNumMemRecords; i++) {
            ps_mem_rec->u4_size = sizeof(iv_mem_rec_t);
            ps_mem_rec->pv_base = NULL;
            ps_mem_rec->u4_mem_size = 0;
            ps_mem_rec->u4_mem_alignment = 0;
            ps_mem_rec->e_mem_type = IV_NA_MEM_TYPE;

            ps_mem_rec++;
 }
 }

 /* Getting MemRecords Attributes */
 {
 iv_fill_mem_rec_ip_t s_fill_mem_rec_ip;
 iv_fill_mem_rec_op_t s_fill_mem_rec_op;

        s_fill_mem_rec_ip.u4_size = sizeof(iv_fill_mem_rec_ip_t);
        s_fill_mem_rec_op.u4_size = sizeof(iv_fill_mem_rec_op_t);

        s_fill_mem_rec_ip.e_cmd = IV_CMD_FILL_NUM_MEM_REC;
        s_fill_mem_rec_ip.ps_mem_rec = mMemRecords;
        s_fill_mem_rec_ip.u4_num_mem_rec = mNumMemRecords;
        s_fill_mem_rec_ip.u4_max_wd = mWidth;
        s_fill_mem_rec_ip.u4_max_ht = mHeight;
        s_fill_mem_rec_ip.u4_max_level = mAVCEncLevel;
        s_fill_mem_rec_ip.e_color_format = DEFAULT_INP_COLOR_FORMAT;
        s_fill_mem_rec_ip.u4_max_ref_cnt = DEFAULT_MAX_REF_FRM;
        s_fill_mem_rec_ip.u4_max_reorder_cnt = DEFAULT_MAX_REORDER_FRM;
        s_fill_mem_rec_ip.u4_max_srch_rng_x = DEFAULT_MAX_SRCH_RANGE_X;
        s_fill_mem_rec_ip.u4_max_srch_rng_y = DEFAULT_MAX_SRCH_RANGE_Y;

        status = ive_api_function(0, &s_fill_mem_rec_ip, &s_fill_mem_rec_op);

 if (status != IV_SUCCESS) {
            ALOGE("Fill memory records failed = 0x%x\n",
                    s_fill_mem_rec_op.u4_error_code);
            mSignalledError = true;
            notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return OMX_ErrorUndefined;
 }
 }

 /* Allocating Memory for Mem Records */
 {
        WORD32 total_size;
 iv_mem_rec_t *ps_mem_rec;
        total_size = 0;
        ps_mem_rec = mMemRecords;

 for (size_t i = 0; i < mNumMemRecords; i++) {
            ps_mem_rec->pv_base = ive_aligned_malloc(
                    ps_mem_rec->u4_mem_alignment, ps_mem_rec->u4_mem_size);
 if (ps_mem_rec->pv_base == NULL) {
                ALOGE("Allocation failure for mem record id %zu size %u\n", i,
                        ps_mem_rec->u4_mem_size);
                mSignalledError = true;
                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return OMX_ErrorUndefined;

 }
            total_size += ps_mem_rec->u4_mem_size;

            ps_mem_rec++;
 }
 }

 /* Codec Instance Creation */
 {
 ive_init_ip_t s_init_ip;
 ive_init_op_t s_init_op;

        mCodecCtx = (iv_obj_t *)mMemRecords[0].pv_base;
        mCodecCtx->u4_size = sizeof(iv_obj_t);
        mCodecCtx->pv_fxns = (void *)ive_api_function;

        s_init_ip.u4_size = sizeof(ive_init_ip_t);
        s_init_op.u4_size = sizeof(ive_init_op_t);

        s_init_ip.e_cmd = IV_CMD_INIT;
        s_init_ip.u4_num_mem_rec = mNumMemRecords;
        s_init_ip.ps_mem_rec = mMemRecords;
        s_init_ip.u4_max_wd = mWidth;
        s_init_ip.u4_max_ht = mHeight;
        s_init_ip.u4_max_ref_cnt = DEFAULT_MAX_REF_FRM;
        s_init_ip.u4_max_reorder_cnt = DEFAULT_MAX_REORDER_FRM;
        s_init_ip.u4_max_level = mAVCEncLevel;
        s_init_ip.e_inp_color_fmt = mIvVideoColorFormat;

 if (mReconEnable || mPSNREnable) {
            s_init_ip.u4_enable_recon = 1;
 } else {
            s_init_ip.u4_enable_recon = 0;
 }
        s_init_ip.e_recon_color_fmt = DEFAULT_RECON_COLOR_FORMAT;
        s_init_ip.e_rc_mode = DEFAULT_RC_MODE;
        s_init_ip.u4_max_framerate = DEFAULT_MAX_FRAMERATE;
        s_init_ip.u4_max_bitrate = DEFAULT_MAX_BITRATE;
        s_init_ip.u4_num_bframes = mBframes;
        s_init_ip.e_content_type = IV_PROGRESSIVE;
        s_init_ip.u4_max_srch_rng_x = DEFAULT_MAX_SRCH_RANGE_X;
        s_init_ip.u4_max_srch_rng_y = DEFAULT_MAX_SRCH_RANGE_Y;
        s_init_ip.e_slice_mode = mSliceMode;
        s_init_ip.u4_slice_param = mSliceParam;
        s_init_ip.e_arch = mArch;
        s_init_ip.e_soc = DEFAULT_SOC;

        status = ive_api_function(mCodecCtx, &s_init_ip, &s_init_op);

 if (status != IV_SUCCESS) {
            ALOGE("Init memory records failed = 0x%x\n",
                    s_init_op.u4_error_code);
            mSignalledError = true;
            notify(OMX_EventError, OMX_ErrorUndefined, 0 /* arg2 */, NULL /* data */);
 return OMX_ErrorUndefined;
 }
 }

 /* Get Codec Version */
    logVersion();

 /* set processor details */
    setNumCores();

 /* Video control Set Frame dimensions */
    setDimensions();

 /* Video control Set Frame rates */
    setFrameRate();

 /* Video control Set IPE Params */
    setIpeParams();

 /* Video control Set Bitrate */
    setBitRate();

 /* Video control Set QP */
    setQp();

 /* Video control Set AIR params */
    setAirParams();

 /* Video control Set VBV params */
    setVbvParams();

 /* Video control Set Motion estimation params */
    setMeParams();

 /* Video control Set GOP params */
    setGopParams();

 /* Video control Set Deblock params */
    setDeblockParams();

 /* Video control Set Profile params */
    setProfileParams();

 /* Video control Set in Encode header mode */
    setEncMode(IVE_ENC_MODE_HEADER);

    ALOGV("init_codec successfull");

    mSpsPpsHeaderReceived = false;
    mStarted = true;

 return OMX_ErrorNone;
}

const char *ACodec::_asString(BufferInfo::Status s) {
 switch (s) {
 case BufferInfo::OWNED_BY_US: return "OUR";
 case BufferInfo::OWNED_BY_COMPONENT: return "COMPONENT";
 case BufferInfo::OWNED_BY_UPSTREAM: return "UPSTREAM";
 case BufferInfo::OWNED_BY_DOWNSTREAM: return "DOWNSTREAM";
 case BufferInfo::OWNED_BY_NATIVE_WINDOW: return "SURFACE";
 case BufferInfo::UNRECOGNIZED: return "UNRECOGNIZED";
 default: return "?";
 }
}

 virtual status_t emptyBuffer(
            node_id node,
            buffer_id buffer,
            OMX_U32 range_offset, OMX_U32 range_length,
            OMX_U32 flags, OMX_TICKS timestamp, int fenceFd) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32((int32_t)buffer);
        data.writeInt32(range_offset);
        data.writeInt32(range_length);
        data.writeInt32(flags);
        data.writeInt64(timestamp);
        data.writeInt32(fenceFd >= 0);
 if (fenceFd >= 0) {
            data.writeFileDescriptor(fenceFd, true /* takeOwnership */);
 }
        remote()->transact(EMPTY_BUFFER, data, &reply);

 return reply.readInt32();
 }

SoftVideoDecoderOMXComponent::SoftVideoDecoderOMXComponent(
 const char *name,
 const char *componentRole,
        OMX_VIDEO_CODINGTYPE codingType,
 const CodecProfileLevel *profileLevels,
 size_t numProfileLevels,
 int32_t width,
 int32_t height,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
        mIsAdaptive(false),
        mAdaptiveMaxWidth(0),
        mAdaptiveMaxHeight(0),
        mWidth(width),
        mHeight(height),
        mCropLeft(0),
        mCropTop(0),
        mCropWidth(width),
        mCropHeight(height),
        mOutputPortSettingsChange(NONE),
        mMinInputBufferSize(384), // arbitrary, using one uncompressed macroblock
        mMinCompressionRatio(1), // max input size is normally the output size
        mComponentRole(componentRole),
        mCodingType(codingType),
        mProfileLevels(profileLevels),
        mNumProfileLevels(numProfileLevels) {
}

static inline status_t makeNoSideEffectStatus(status_t err) {
 switch (err) {
 case INVALID_OPERATION:
 case DEAD_OBJECT:
 return UNKNOWN_ERROR;
 default:
 return err;
 }
}

int32_t SoftAVCEncoder::allocOutputBuffers(
 unsigned int sizeInMbs, unsigned int numBuffers) {
    CHECK(mOutputBuffers.isEmpty());
 size_t frameSize = (sizeInMbs << 7) * 3;
 for (unsigned int i = 0; i <  numBuffers; ++i) {
 MediaBuffer *buffer = new MediaBuffer(frameSize);
        buffer->setObserver(this);
        mOutputBuffers.push(buffer);
 }

 return 1;
}

void ACodec::LoadedToIdleState::stateEntered() {
    ALOGV("[%s] Now Loaded->Idle", mCodec->mComponentName.c_str());

 status_t err;
 if ((err = allocateBuffers()) != OK) {
        ALOGE("Failed to allocate buffers after transitioning to IDLE state "
 "(error 0x%08x)",
             err);

        mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));

        mCodec->changeState(mCodec->mLoadedState);
 }
}

static void FreeWrapper(void * /* userData */, void* ptr) {
    free(ptr);
}

status_t ACodec::setupVPXEncoderParameters(const sp<AMessage> &msg) {
 int32_t bitrate;
 int32_t iFrameInterval = 0;
 size_t tsLayers = 0;
    OMX_VIDEO_ANDROID_VPXTEMPORALLAYERPATTERNTYPE pattern =
        OMX_VIDEO_VPXTemporalLayerPatternNone;
 static const uint32_t kVp8LayerRateAlloction
 [OMX_VIDEO_ANDROID_MAXVP8TEMPORALLAYERS]
 [OMX_VIDEO_ANDROID_MAXVP8TEMPORALLAYERS] = {
 {100, 100, 100}, // 1 layer
 { 60, 100, 100}, // 2 layers {60%, 40%}
 { 40, 60, 100}, // 3 layers {40%, 20%, 40%}
 };
 if (!msg->findInt32("bitrate", &bitrate)) {
 return INVALID_OPERATION;
 }
    msg->findInt32("i-frame-interval", &iFrameInterval);

    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);

 float frameRate;
 if (!msg->findFloat("frame-rate", &frameRate)) {
 int32_t tmp;
 if (!msg->findInt32("frame-rate", &tmp)) {
 return INVALID_OPERATION;
 }
        frameRate = (float)tmp;
 }

 AString tsSchema;
 if (msg->findString("ts-schema", &tsSchema)) {
 if (tsSchema == "webrtc.vp8.1-layer") {
            pattern = OMX_VIDEO_VPXTemporalLayerPatternWebRTC;
            tsLayers = 1;
 } else if (tsSchema == "webrtc.vp8.2-layer") {
            pattern = OMX_VIDEO_VPXTemporalLayerPatternWebRTC;
            tsLayers = 2;
 } else if (tsSchema == "webrtc.vp8.3-layer") {
            pattern = OMX_VIDEO_VPXTemporalLayerPatternWebRTC;
            tsLayers = 3;
 } else {
            ALOGW("Unsupported ts-schema [%s]", tsSchema.c_str());
 }
 }

    OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE vp8type;
 InitOMXParams(&vp8type);
    vp8type.nPortIndex = kPortIndexOutput;
 status_t err = mOMX->getParameter(
            mNode, (OMX_INDEXTYPE)OMX_IndexParamVideoAndroidVp8Encoder,
 &vp8type, sizeof(vp8type));

 if (err == OK) {
 if (iFrameInterval > 0) {
            vp8type.nKeyFrameInterval = setPFramesSpacing(iFrameInterval, frameRate);
 }
        vp8type.eTemporalPattern = pattern;
        vp8type.nTemporalLayerCount = tsLayers;
 if (tsLayers > 0) {
 for (size_t i = 0; i < OMX_VIDEO_ANDROID_MAXVP8TEMPORALLAYERS; i++) {
                vp8type.nTemporalLayerBitrateRatio[i] =
                    kVp8LayerRateAlloction[tsLayers - 1][i];
 }
 }
 if (bitrateMode == OMX_Video_ControlRateConstant) {
            vp8type.nMinQuantizer = 2;
            vp8type.nMaxQuantizer = 63;
 }

        err = mOMX->setParameter(
                mNode, (OMX_INDEXTYPE)OMX_IndexParamVideoAndroidVp8Encoder,
 &vp8type, sizeof(vp8type));
 if (err != OK) {
            ALOGW("Extended VP8 parameters set failed: %d", err);
 }
 }

 return configureBitrate(bitrate, bitrateMode);
}

 MessageList() {
 }

static void UnbindFrameWrapper(void *userData, int32_t index) {
 SoftAVCEncoder *encoder = static_cast<SoftAVCEncoder *>(userData);
    CHECK(encoder != NULL);
 return encoder->unbindOutputBuffer(index);
}

status_t OMXCodec::allocateBuffersOnPort(OMX_U32 portIndex) {
 if (mNativeWindow != NULL && portIndex == kPortIndexOutput) {
 return allocateOutputBuffersFromNativeWindow();
 }

 if ((mFlags & kEnableGrallocUsageProtected) && portIndex == kPortIndexOutput) {
        ALOGE("protected output buffers must be stent to an ANativeWindow");
 return PERMISSION_DENIED;
 }

 status_t err = OK;
 if ((mFlags & kStoreMetaDataInVideoBuffers)
 && portIndex == kPortIndexInput) {
        err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE);
 if (err != OK) {
            ALOGE("Storing meta data in video buffers is not supported");
 return err;
 }
 }

    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

    CODEC_LOGV("allocating %u buffers of size %u on %s port",
            def.nBufferCountActual, def.nBufferSize,
            portIndex == kPortIndexInput ? "input" : "output");

 if (def.nBufferSize != 0 && def.nBufferCountActual > SIZE_MAX / def.nBufferSize) {
 return BAD_VALUE;
 }
 size_t totalSize = def.nBufferCountActual * def.nBufferSize;
    mDealer[portIndex] = new MemoryDealer(totalSize, "OMXCodec");

 for (OMX_U32 i = 0; i < def.nBufferCountActual; ++i) {
        sp<IMemory> mem = mDealer[portIndex]->allocate(def.nBufferSize);
        CHECK(mem.get() != NULL);

 BufferInfo info;
        info.mData = NULL;
        info.mSize = def.nBufferSize;

        IOMX::buffer_id buffer;
 if (portIndex == kPortIndexInput
 && ((mQuirks & kRequiresAllocateBufferOnInputPorts)
 || (mFlags & kUseSecureInputBuffers))) {
 if (mOMXLivesLocally) {
                mem.clear();

                err = mOMX->allocateBuffer(
                        mNode, portIndex, def.nBufferSize, &buffer,
 &info.mData);
 } else {
                err = mOMX->allocateBufferWithBackup(
                        mNode, portIndex, mem, &buffer, mem->size());
 }
 } else if (portIndex == kPortIndexOutput
 && (mQuirks & kRequiresAllocateBufferOnOutputPorts)) {
 if (mOMXLivesLocally) {
                mem.clear();

                err = mOMX->allocateBuffer(
                        mNode, portIndex, def.nBufferSize, &buffer,
 &info.mData);
 } else {
                err = mOMX->allocateBufferWithBackup(
                        mNode, portIndex, mem, &buffer, mem->size());
 }
 } else {
            err = mOMX->useBuffer(mNode, portIndex, mem, &buffer, mem->size());
 }

 if (err != OK) {
            ALOGE("allocate_buffer_with_backup failed");
 return err;
 }

 if (mem != NULL) {
            info.mData = mem->pointer();
 }

        info.mBuffer = buffer;
        info.mStatus = OWNED_BY_US;
        info.mMem = mem;
        info.mMediaBuffer = NULL;

 if (portIndex == kPortIndexOutput) {
            LOG_ALWAYS_FATAL_IF((mOMXLivesLocally
 && (mQuirks & kRequiresAllocateBufferOnOutputPorts)
 && (mQuirks & kDefersOutputBufferAllocation)),
 "allocateBuffersOnPort cannot defer buffer allocation");

            info.mMediaBuffer = new MediaBuffer(info.mData, info.mSize);
            info.mMediaBuffer->setObserver(this);
 }

        mPortBuffers[portIndex].push(info);

        CODEC_LOGV("allocated buffer %u on %s port", buffer,
             portIndex == kPortIndexInput ? "input" : "output");
 }

 if (portIndex == kPortIndexOutput) {

        sp<MetaData> meta = mSource->getFormat();
 int32_t delay = 0;
 if (!meta->findInt32(kKeyEncoderDelay, &delay)) {
            delay = 0;
 }
 int32_t padding = 0;
 if (!meta->findInt32(kKeyEncoderPadding, &padding)) {
            padding = 0;
 }
 int32_t numchannels = 0;
 if (delay + padding) {
 if (mOutputFormat->findInt32(kKeyChannelCount, &numchannels)) {
 size_t frameSize = numchannels * sizeof(int16_t);
 if (mSkipCutBuffer != NULL) {
 size_t prevbuffersize = mSkipCutBuffer->size();
 if (prevbuffersize != 0) {
                        ALOGW("Replacing SkipCutBuffer holding %zu bytes", prevbuffersize);
 }
 }
                mSkipCutBuffer = new SkipCutBuffer(delay * frameSize, padding * frameSize);
 }
 }
 }


 if (portIndex == kPortIndexInput && (mFlags & kUseSecureInputBuffers)) {
 Vector<MediaBuffer *> buffers;
 for (size_t i = 0; i < def.nBufferCountActual; ++i) {
 const BufferInfo &info = mPortBuffers[kPortIndexInput].itemAt(i);

 MediaBuffer *mbuf = new MediaBuffer(info.mData, info.mSize);
            buffers.push(mbuf);
 }

 status_t err = mSource->setBuffers(buffers);

 if (err != OK) {
 for (size_t i = 0; i < def.nBufferCountActual; ++i) {
                buffers.editItemAt(i)->release();
 }
            buffers.clear();

            CODEC_LOGE(
 "Codec requested to use secure input buffers but "
 "upstream source didn't support that.");

 return err;
 }
 }

 return OK;
}

void ACodec::signalRequestIDRFrame() {
 (new AMessage(kWhatRequestIDRFrame, this))->post();
}

static status_t GetVideoCodingTypeFromMime(
 const char *mime, OMX_VIDEO_CODINGTYPE *codingType) {
 for (size_t i = 0;
         i < sizeof(kVideoCodingMapEntry) / sizeof(kVideoCodingMapEntry[0]);
 ++i) {
 if (!strcasecmp(mime, kVideoCodingMapEntry[i].mMime)) {
 *codingType = kVideoCodingMapEntry[i].mVideoCodingType;
 return OK;
 }
 }

 *codingType = OMX_VIDEO_CodingUnused;

 return ERROR_UNSUPPORTED;
}

OMX_ERRORTYPE SoftAMRNBEncoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_encoder.amrnb",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPortFormat:
 {

             const OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (const OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

 if ((formatParams->nPortIndex == 0
 && formatParams->eEncoding != OMX_AUDIO_CodingPCM)
 || (formatParams->nPortIndex == 1
 && formatParams->eEncoding != OMX_AUDIO_CodingAMR)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAmr:
 {

             OMX_AUDIO_PARAM_AMRTYPE *amrParams =
                 (OMX_AUDIO_PARAM_AMRTYPE *)params;
 
             if (amrParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (amrParams->nChannels != 1
 || amrParams->eAMRDTXMode != OMX_AUDIO_AMRDTXModeOff
 || amrParams->eAMRFrameFormat
 != OMX_AUDIO_AMRFrameFormatFSF
 || amrParams->eAMRBandMode < OMX_AUDIO_AMRBandModeNB0
 || amrParams->eAMRBandMode > OMX_AUDIO_AMRBandModeNB7) {
 return OMX_ErrorUndefined;
 }

            mBitRate = amrParams->nBitRate;
            mMode = amrParams->eAMRBandMode - 1;

            amrParams->eAMRDTXMode = OMX_AUDIO_AMRDTXModeOff;
            amrParams->eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 if (pcmParams->nChannels != 1
 || pcmParams->nSamplingRate != (OMX_U32)kSampleRate) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }


 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftAVC::setConfig(
        OMX_INDEXTYPE index, const OMX_PTR _params) {
 switch (index) {
 case OMX_IndexConfigVideoIntraVOPRefresh:
 {

             OMX_CONFIG_INTRAREFRESHVOPTYPE *params =
                 (OMX_CONFIG_INTRAREFRESHVOPTYPE *)_params;
 
             if (params->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

            mKeyFrameRequested = params->IntraRefreshVOP;
 return OMX_ErrorNone;
 }

 case OMX_IndexConfigVideoBitrate:
 {

             OMX_VIDEO_CONFIG_BITRATETYPE *params =
                 (OMX_VIDEO_CONFIG_BITRATETYPE *)_params;
 
             if (params->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

 if (mBitrate != params->nEncodeBitrate) {
                mBitrate = params->nEncodeBitrate;
                mBitrateUpdated = true;
 }
 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::setConfig(index, _params);
 }
}

sp<MediaSource> OMXCodec::Create(
const sp<IOMX> &omx,
const sp<MetaData> &meta, bool createEncoder,
const sp<MediaSource> &source,
const char *matchComponentName,
uint32_t flags,
const sp<ANativeWindow> &nativeWindow) {
int32_t requiresSecureBuffers;
if (source->getFormat()->findInt32(
kKeyRequiresSecureBuffers,
&requiresSecureBuffers)
&& requiresSecureBuffers) {
flags |= kIgnoreCodecSpecificData;
flags |= kUseSecureInputBuffers;
}

const char *mime;
bool success = meta->findCString(kKeyMIMEType, &mime);
CHECK(success);

Vector<CodecNameAndQuirks> matchingCodecs;
findMatchingCodecs(
mime, createEncoder, matchComponentName, flags, &matchingCodecs);

if (matchingCodecs.isEmpty()) {
ALOGV("No matching codecs! (mime: %s, createEncoder: %s, "
"matchComponentName: %s, flags: 0x%x)",
mime, createEncoder ? "true" : "false", matchComponentName, flags);
return NULL;
}

sp<OMXCodecObserver> observer = new OMXCodecObserver;
IOMX::node_id node = 0;

for (size_t i = 0; i < matchingCodecs.size(); ++i) {
const char *componentNameBase = matchingCodecs[i].mName.string();
uint32_t quirks = matchingCodecs[i].mQuirks;
const char *componentName = componentNameBase;

AString tmp;
if (flags & kUseSecureInputBuffers) {
tmp = componentNameBase;
tmp.append(".secure");

componentName = tmp.c_str();
}

if (createEncoder) {
sp<MediaSource> softwareCodec =
InstantiateSoftwareEncoder(componentName, source, meta);

if (softwareCodec != NULL) {
ALOGV("Successfully allocated software codec '%s'", componentName);

return softwareCodec;
}
}


ALOGV("Attempting to allocate OMX node '%s'", componentName);

        if (!createEncoder
                && (quirks & kOutputBuffersAreUnreadable)
                && (flags & kClientNeedsFramebuffer)) {
            if (strncmp(componentName, "OMX.SEC.", 8)) {
                // For OMX.SEC.* decoders we can enable a special mode that
                // gives the client access to the framebuffer contents.
                ALOGW("Component '%s' does not give the client access to "
                     "the framebuffer contents. Skipping.",
                     componentName);
                continue;
            }
        }
status_t err = omx->allocateNode(componentName, observer, &node);
if (err == OK) {
ALOGV("Successfully allocated OMX node '%s'", componentName);

sp<OMXCodec> codec = new OMXCodec(
omx, node, quirks, flags,
createEncoder, mime, componentName,
source, nativeWindow);

observer->setCodec(codec);

err = codec->configureCodec(meta);
if (err == OK) {
return codec;
}

ALOGV("Failed to configure codec '%s'", componentName);
}
}

return NULL;
}

 virtual status_t useGraphicBuffer(
            node_id node, OMX_U32 port_index,
 const sp<GraphicBuffer> &graphicBuffer, buffer_id *buffer) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.write(*graphicBuffer);
        remote()->transact(USE_GRAPHIC_BUFFER, data, &reply);

 status_t err = reply.readInt32();
 if (err != OK) {
 *buffer = 0;

 return err;
 }

 *buffer = (buffer_id)reply.readInt32();

 return err;
 }

ACodec::BaseState::PortMode ACodec::OutputPortSettingsChangedState::getPortMode(
        OMX_U32 portIndex) {
 if (portIndex == kPortIndexOutput) {
 return FREE_BUFFERS;
 }

    CHECK_EQ(portIndex, (OMX_U32)kPortIndexInput);

 return RESUBMIT_BUFFERS;
}

status_t ACodec::allocateOutputBuffersFromNativeWindow() {
    OMX_U32 bufferCount, bufferSize, minUndequeuedBuffers;
 status_t err = configureOutputBuffersFromNativeWindow(
 &bufferCount, &bufferSize, &minUndequeuedBuffers);
 if (err != 0)
 return err;
    mNumUndequeuedBuffers = minUndequeuedBuffers;

 if (!storingMetadataInDecodedBuffers()) {
 static_cast<Surface*>(mNativeWindow.get())
 ->getIGraphicBufferProducer()->allowAllocation(true);
 }

    ALOGV("[%s] Allocating %u buffers from a native window of size %u on "
 "output port",
         mComponentName.c_str(), bufferCount, bufferSize);

 for (OMX_U32 i = 0; i < bufferCount; i++) {
 ANativeWindowBuffer *buf;
 int fenceFd;
        err = mNativeWindow->dequeueBuffer(mNativeWindow.get(), &buf, &fenceFd);
 if (err != 0) {
            ALOGE("dequeueBuffer failed: %s (%d)", strerror(-err), -err);
 break;
 }

        sp<GraphicBuffer> graphicBuffer(new GraphicBuffer(buf, false));
 BufferInfo info;
        info.mStatus = BufferInfo::OWNED_BY_US;
        info.mFenceFd = fenceFd;
        info.mIsReadFence = false;
        info.mRenderInfo = NULL;
        info.mData = new ABuffer(NULL /* data */, bufferSize /* capacity */);
        info.mGraphicBuffer = graphicBuffer;
        mBuffers[kPortIndexOutput].push(info);

        IOMX::buffer_id bufferId;
        err = mOMX->useGraphicBuffer(mNode, kPortIndexOutput, graphicBuffer,
 &bufferId);
 if (err != 0) {
            ALOGE("registering GraphicBuffer %u with OMX IL component failed: "
 "%d", i, err);
 break;
 }

        mBuffers[kPortIndexOutput].editItemAt(i).mBufferID = bufferId;

        ALOGV("[%s] Registered graphic buffer with ID %u (pointer = %p)",
             mComponentName.c_str(),
             bufferId, graphicBuffer.get());
 }

    OMX_U32 cancelStart;
    OMX_U32 cancelEnd;

 if (err != 0) {
        cancelStart = 0;
        cancelEnd = mBuffers[kPortIndexOutput].size();
 } else {
        cancelStart = bufferCount - minUndequeuedBuffers;
        cancelEnd = bufferCount;
 }

 for (OMX_U32 i = cancelStart; i < cancelEnd; i++) {
 BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);
 if (info->mStatus == BufferInfo::OWNED_BY_US) {
 status_t error = cancelBufferToNativeWindow(info);
 if (err == 0) {
                err = error;
 }
 }
 }

 if (!storingMetadataInDecodedBuffers()) {
 static_cast<Surface*>(mNativeWindow.get())
 ->getIGraphicBufferProducer()->allowAllocation(false);
 }

 return err;
}

FLAC__StreamEncoderWriteStatus SoftFlacEncoder::flacEncoderWriteCallback(
 const FLAC__StreamEncoder * /* encoder */,
 const FLAC__byte buffer[],
 size_t bytes,
 unsigned samples,
 unsigned current_frame,
 void *client_data) {
 return ((SoftFlacEncoder*) client_data)->onEncodedFlacAvailable(
            buffer, bytes, samples, current_frame);
}

status_t ACodec::setMinBufferSize(OMX_U32 portIndex, size_t size) {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

 if (def.nBufferSize >= size) {
 return OK;
 }

    def.nBufferSize = size;

    err = mOMX->setParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

 if (def.nBufferSize < size) {
        ALOGE("failed to set min buffer size to %zu (is still %u)", size, def.nBufferSize);
 return FAILED_TRANSACTION;
 }

 return OK;
}

ACodec::ACodec()
 : mQuirks(0),
      mNode(0),
      mNativeWindowUsageBits(0),
      mSentFormat(false),
      mIsVideo(false),
      mIsEncoder(false),
      mFatalError(false),
      mShutdownInProgress(false),
      mExplicitShutdown(false),
      mEncoderDelay(0),
      mEncoderPadding(0),
      mRotationDegrees(0),
      mChannelMaskPresent(false),
      mChannelMask(0),
      mDequeueCounter(0),
      mInputMetadataType(kMetadataBufferTypeInvalid),
      mOutputMetadataType(kMetadataBufferTypeInvalid),
      mLegacyAdaptiveExperiment(false),
      mMetadataBuffersToSubmit(0),
      mRepeatFrameDelayUs(-1ll),
      mMaxPtsGapUs(-1ll),
      mMaxFps(-1),
      mTimePerFrameUs(-1ll),
      mTimePerCaptureUs(-1ll),
      mCreateInputBuffersSuspended(false),
      mTunneled(false) {
    mUninitializedState = new UninitializedState(this);
    mLoadedState = new LoadedState(this);
    mLoadedToIdleState = new LoadedToIdleState(this);
    mIdleToExecutingState = new IdleToExecutingState(this);
    mExecutingState = new ExecutingState(this);

    mOutputPortSettingsChangedState =
 new OutputPortSettingsChangedState(this);

    mExecutingToIdleState = new ExecutingToIdleState(this);
    mIdleToLoadedState = new IdleToLoadedState(this);
    mFlushingState = new FlushingState(this);

    mPortEOS[kPortIndexInput] = mPortEOS[kPortIndexOutput] = false;
    mInputEOSResult = OK;

    changeState(mUninitializedState);
}

status_t ACodec::setupH263EncoderParameters(const sp<AMessage> &msg) {
 int32_t bitrate, iFrameInterval;
 if (!msg->findInt32("bitrate", &bitrate)
 || !msg->findInt32("i-frame-interval", &iFrameInterval)) {
 return INVALID_OPERATION;
 }

    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);

 float frameRate;
 if (!msg->findFloat("frame-rate", &frameRate)) {
 int32_t tmp;
 if (!msg->findInt32("frame-rate", &tmp)) {
 return INVALID_OPERATION;
 }
        frameRate = (float)tmp;
 }

    OMX_VIDEO_PARAM_H263TYPE h263type;
 InitOMXParams(&h263type);
    h263type.nPortIndex = kPortIndexOutput;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamVideoH263, &h263type, sizeof(h263type));

 if (err != OK) {
 return err;
 }

    h263type.nAllowedPictureTypes =
        OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP;

    h263type.nPFrames = setPFramesSpacing(iFrameInterval, frameRate);
 if (h263type.nPFrames == 0) {
        h263type.nAllowedPictureTypes = OMX_VIDEO_PictureTypeI;
 }
    h263type.nBFrames = 0;

 int32_t profile;
 if (msg->findInt32("profile", &profile)) {
 int32_t level;
 if (!msg->findInt32("level", &level)) {
 return INVALID_OPERATION;
 }

        err = verifySupportForProfileAndLevel(profile, level);

 if (err != OK) {
 return err;
 }

        h263type.eProfile = static_cast<OMX_VIDEO_H263PROFILETYPE>(profile);
        h263type.eLevel = static_cast<OMX_VIDEO_H263LEVELTYPE>(level);
 }

    h263type.bPLUSPTYPEAllowed = OMX_FALSE;
    h263type.bForceRoundingTypeToZero = OMX_FALSE;
    h263type.nPictureHeaderRepetition = 0;
    h263type.nGOBHeaderInterval = 0;

    err = mOMX->setParameter(
            mNode, OMX_IndexParamVideoH263, &h263type, sizeof(h263type));

 if (err != OK) {
 return err;
 }

    err = configureBitrate(bitrate, bitrateMode);

 if (err != OK) {
 return err;
 }

 return setupErrorCorrectionParameters();
}

void SoftAACEncoder2::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 if (!mSentCodecSpecificData) {

 if (outQueue.empty()) {
 return;
 }

 if (AACENC_OK != aacEncEncode(mAACEncoder, NULL, NULL, NULL, NULL)) {
            ALOGE("Unable to initialize encoder for profile / sample-rate / bit-rate / channels");
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
            mSignalledError = true;
 return;
 }

        OMX_U32 actualBitRate  = aacEncoder_GetParam(mAACEncoder, AACENC_BITRATE);
 if (mBitRate != actualBitRate) {
            ALOGW("Requested bitrate %u unsupported, using %u", mBitRate, actualBitRate);
 }

        AACENC_InfoStruct encInfo;
 if (AACENC_OK != aacEncInfo(mAACEncoder, &encInfo)) {
            ALOGE("Failed to get AAC encoder info");
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
            mSignalledError = true;
 return;
 }

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;
        outHeader->nFilledLen = encInfo.confSize;
        outHeader->nFlags = OMX_BUFFERFLAG_CODECCONFIG;

 uint8_t *out = outHeader->pBuffer + outHeader->nOffset;
        memcpy(out, encInfo.confBuf, encInfo.confSize);

        outQueue.erase(outQueue.begin());
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

        mSentCodecSpecificData = true;
 }

 size_t numBytesPerInputFrame =
        mNumChannels * kNumSamplesPerFrame * sizeof(int16_t);

 if (mAACProfile == OMX_AUDIO_AACObjectELD && numBytesPerInputFrame > 512) {
        numBytesPerInputFrame = 512;
 }

 for (;;) {

 while (mInputSize < numBytesPerInputFrame) {

 if (mSawInputEOS || inQueue.empty()) {
 return;
 }

 BufferInfo *inInfo = *inQueue.begin();
            OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 const void *inData = inHeader->pBuffer + inHeader->nOffset;

 size_t copy = numBytesPerInputFrame - mInputSize;
 if (copy > inHeader->nFilledLen) {
                copy = inHeader->nFilledLen;
 }

 if (mInputFrame == NULL) {
                mInputFrame = new int16_t[numBytesPerInputFrame / sizeof(int16_t)];
 }

 if (mInputSize == 0) {
                mInputTimeUs = inHeader->nTimeStamp;
 }

            memcpy((uint8_t *)mInputFrame + mInputSize, inData, copy);
            mInputSize += copy;

            inHeader->nOffset += copy;
            inHeader->nFilledLen -= copy;

            inHeader->nTimeStamp +=
 (copy * 1000000ll / mSampleRate)
 / (mNumChannels * sizeof(int16_t));

 if (inHeader->nFilledLen == 0) {
 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                    mSawInputEOS = true;

                    memset((uint8_t *)mInputFrame + mInputSize,
 0,
                           numBytesPerInputFrame - mInputSize);

                    mInputSize = numBytesPerInputFrame;
 }

                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);

                inData = NULL;
                inHeader = NULL;
                inInfo = NULL;
 }
 }


 if (outQueue.empty()) {
 return;
 }

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 uint8_t *outPtr = (uint8_t *)outHeader->pBuffer + outHeader->nOffset;
 size_t outAvailable = outHeader->nAllocLen - outHeader->nOffset;

        AACENC_InArgs inargs;
        AACENC_OutArgs outargs;
        memset(&inargs, 0, sizeof(inargs));
        memset(&outargs, 0, sizeof(outargs));
        inargs.numInSamples = numBytesPerInputFrame / sizeof(int16_t);

 void* inBuffer[] = { (unsigned char *)mInputFrame };
        INT   inBufferIds[] = { IN_AUDIO_DATA };
        INT   inBufferSize[] = { (INT)numBytesPerInputFrame };
        INT   inBufferElSize[] = { sizeof(int16_t) };

        AACENC_BufDesc inBufDesc;
        inBufDesc.numBufs           = sizeof(inBuffer) / sizeof(void*);
        inBufDesc.bufs              = (void**)&inBuffer;
        inBufDesc.bufferIdentifiers = inBufferIds;
        inBufDesc.bufSizes          = inBufferSize;
        inBufDesc.bufElSizes        = inBufferElSize;

 void* outBuffer[] = { outPtr };
        INT   outBufferIds[] = { OUT_BITSTREAM_DATA };
        INT   outBufferSize[] = { 0 };
        INT   outBufferElSize[] = { sizeof(UCHAR) };

        AACENC_BufDesc outBufDesc;
        outBufDesc.numBufs           = sizeof(outBuffer) / sizeof(void*);
        outBufDesc.bufs              = (void**)&outBuffer;
        outBufDesc.bufferIdentifiers = outBufferIds;
        outBufDesc.bufSizes          = outBufferSize;
        outBufDesc.bufElSizes        = outBufferElSize;

        AACENC_ERROR encoderErr = AACENC_OK;
 size_t nOutputBytes = 0;

 do {
            memset(&outargs, 0, sizeof(outargs));

            outBuffer[0] = outPtr;
            outBufferSize[0] = outAvailable - nOutputBytes;

            encoderErr = aacEncEncode(mAACEncoder,
 &inBufDesc,
 &outBufDesc,
 &inargs,
 &outargs);

 if (encoderErr == AACENC_OK) {
                outPtr += outargs.numOutBytes;
                nOutputBytes += outargs.numOutBytes;

 if (outargs.numInSamples > 0) {
 int numRemainingSamples = inargs.numInSamples - outargs.numInSamples;
 if (numRemainingSamples > 0) {
                        memmove(mInputFrame,
 &mInputFrame[outargs.numInSamples],
 sizeof(int16_t) * numRemainingSamples);
 }
                    inargs.numInSamples -= outargs.numInSamples;
 }
 }
 } while (encoderErr == AACENC_OK && inargs.numInSamples > 0);

        outHeader->nFilledLen = nOutputBytes;

        outHeader->nFlags = OMX_BUFFERFLAG_ENDOFFRAME;

 if (mSawInputEOS) {
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;
 }

        outHeader->nTimeStamp = mInputTimeUs;

#if 0
        ALOGI("sending %d bytes of data (time = %lld us, flags = 0x%08lx)",
              nOutputBytes, mInputTimeUs, outHeader->nFlags);

        hexdump(outHeader->pBuffer + outHeader->nOffset, outHeader->nFilledLen);
#endif

        outQueue.erase(outQueue.begin());
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

        outHeader = NULL;
        outInfo = NULL;

        mInputSize = 0;
 }
}

 virtual status_t fillBuffer(node_id node, buffer_id buffer, int fenceFd) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32((int32_t)buffer);
        data.writeInt32(fenceFd >= 0);
 if (fenceFd >= 0) {
            data.writeFileDescriptor(fenceFd, true /* takeOwnership */);
 }
        remote()->transact(FILL_BUFFER, data, &reply);

 return reply.readInt32();
 }

 bool active() const { return mActive; }

void ACodec::LoadedState::onSetInputSurface(
 const sp<AMessage> &msg) {
    ALOGV("onSetInputSurface");

    sp<AMessage> notify = mCodec->mNotify->dup();
    notify->setInt32("what", CodecBase::kWhatInputSurfaceAccepted);

    sp<RefBase> obj;
    CHECK(msg->findObject("input-surface", &obj));
    sp<PersistentSurface> surface = static_cast<PersistentSurface *>(obj.get());

 status_t err = mCodec->mOMX->setInputSurface(
            mCodec->mNode, kPortIndexInput, surface->getBufferConsumer(),
 &mCodec->mInputMetadataType);

 if (err == OK) {
        err = setupInputSurface();
 }

 if (err != OK) {
        ALOGE("[%s] onSetInputSurface returning error %d",
                mCodec->mComponentName.c_str(), err);
        notify->setInt32("err", err);
 }
    notify->post();
}

OMX_ERRORTYPE SoftAACEncoder2::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_encoder.aac",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPortFormat:
 {

             const OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (const OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

 if ((formatParams->nPortIndex == 0
 && formatParams->eEncoding != OMX_AUDIO_CodingPCM)
 || (formatParams->nPortIndex == 1
 && formatParams->eEncoding != OMX_AUDIO_CodingAAC)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {

             OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
                 (OMX_AUDIO_PARAM_AACPROFILETYPE *)params;
 
             if (aacParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            mBitRate = aacParams->nBitRate;
            mNumChannels = aacParams->nChannels;
            mSampleRate = aacParams->nSampleRate;
 if (aacParams->eAACProfile != OMX_AUDIO_AACObjectNull) {
                mAACProfile = aacParams->eAACProfile;
 }

 if (!(aacParams->nAACtools & OMX_AUDIO_AACToolAndroidSSBR)
 && !(aacParams->nAACtools & OMX_AUDIO_AACToolAndroidDSBR)) {
                mSBRMode = 0;
                mSBRRatio = 0;
 } else if ((aacParams->nAACtools & OMX_AUDIO_AACToolAndroidSSBR)
 && !(aacParams->nAACtools & OMX_AUDIO_AACToolAndroidDSBR)) {
                mSBRMode = 1;
                mSBRRatio = 1;
 } else if (!(aacParams->nAACtools & OMX_AUDIO_AACToolAndroidSSBR)
 && (aacParams->nAACtools & OMX_AUDIO_AACToolAndroidDSBR)) {
                mSBRMode = 1;
                mSBRRatio = 2;
 } else {
                mSBRMode = -1; // codec default sbr mode
                mSBRRatio = 0;
 }

 if (setAudioParams() != OK) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            mNumChannels = pcmParams->nChannels;
            mSampleRate = pcmParams->nSamplingRate;
 if (setAudioParams() != OK) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

void SoftGSM::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 while (!inQueue.empty() && !outQueue.empty()) {
 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
            inQueue.erase(inQueue.begin());
            inInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inHeader);

            outHeader->nFilledLen = 0;
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;

            outQueue.erase(outQueue.begin());
            outInfo->mOwnedByUs = false;
            notifyFillBufferDone(outHeader);
 return;
 }

 if (inHeader->nFilledLen > kMaxNumSamplesPerFrame) {
            ALOGE("input buffer too large (%d).", inHeader->nFilledLen);
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
            mSignalledError = true;
 }

 if(((inHeader->nFilledLen / kMSGSMFrameSize) * kMSGSMFrameSize) != inHeader->nFilledLen) {
            ALOGE("input buffer not multiple of %d (%d).", kMSGSMFrameSize, inHeader->nFilledLen);
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
            mSignalledError = true;
 }

 uint8_t *inputptr = inHeader->pBuffer + inHeader->nOffset;

 int n = mSignalledError ? 0 : DecodeGSM(mGsm,
 reinterpret_cast<int16_t *>(outHeader->pBuffer), inputptr, inHeader->nFilledLen);

        outHeader->nTimeStamp = inHeader->nTimeStamp;
        outHeader->nOffset = 0;
        outHeader->nFilledLen = n * sizeof(int16_t);
        outHeader->nFlags = 0;

        inInfo->mOwnedByUs = false;
        inQueue.erase(inQueue.begin());
        inInfo = NULL;
        notifyEmptyBufferDone(inHeader);
        inHeader = NULL;

        outInfo->mOwnedByUs = false;
        outQueue.erase(outQueue.begin());
        outInfo = NULL;
        notifyFillBufferDone(outHeader);
        outHeader = NULL;
 }
}

void ACodec::LoadedState::stateEntered() {
    ALOGV("[%s] Now Loaded", mCodec->mComponentName.c_str());

    mCodec->mPortEOS[kPortIndexInput] =
        mCodec->mPortEOS[kPortIndexOutput] = false;

    mCodec->mInputEOSResult = OK;

    mCodec->mDequeueCounter = 0;
    mCodec->mMetadataBuffersToSubmit = 0;
    mCodec->mRepeatFrameDelayUs = -1ll;
    mCodec->mInputFormat.clear();
    mCodec->mOutputFormat.clear();
    mCodec->mBaseOutputFormat.clear();

 if (mCodec->mShutdownInProgress) {
 bool keepComponentAllocated = mCodec->mKeepComponentAllocated;

        mCodec->mShutdownInProgress = false;
        mCodec->mKeepComponentAllocated = false;

        onShutdown(keepComponentAllocated);
 }
    mCodec->mExplicitShutdown = false;

    mCodec->processDeferredMessages();
}

 virtual status_t setParameter(
            node_id node, OMX_INDEXTYPE index,
 const void *params, size_t size) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(index);
        data.writeInt64(size);
        data.write(params, size);
        remote()->transact(SET_PARAMETER, data, &reply);

 return reply.readInt32();
 }

OMX_ERRORTYPE SoftVorbis::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.vorbis",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioVorbis:
 {

             const OMX_AUDIO_PARAM_VORBISTYPE *vorbisParams =
                 (const OMX_AUDIO_PARAM_VORBISTYPE *)params;
 
             if (vorbisParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

int /* OMX_VIDEO_AVCLEVELTYPE */ ACodec::getAVCLevelFor(
 int width, int height, int rate, int bitrate,
        OMX_VIDEO_AVCPROFILETYPE profile) {
 switch (profile) {
 case OMX_VIDEO_AVCProfileHigh10:
            bitrate = divUp(bitrate, 3000); break;
 case OMX_VIDEO_AVCProfileHigh:
            bitrate = divUp(bitrate, 1250); break;
 default:
            bitrate = divUp(bitrate, 1000); break;
 }

    width = divUp(width, 16);
    height = divUp(height, 16);
 int mbs = width * height;
    rate *= mbs;
 int maxDimension = max(width, height);

 static const int limits[][5] = {
 /*   MBps     MB   dim  bitrate        level */
 { 1485, 99, 28, 64, OMX_VIDEO_AVCLevel1  },
 { 1485, 99, 28, 128, OMX_VIDEO_AVCLevel1b },
 { 3000, 396, 56, 192, OMX_VIDEO_AVCLevel11 },
 { 6000, 396, 56, 384, OMX_VIDEO_AVCLevel12 },
 { 11880, 396, 56, 768, OMX_VIDEO_AVCLevel13 },
 { 11880, 396, 56, 2000, OMX_VIDEO_AVCLevel2  },
 { 19800, 792, 79, 4000, OMX_VIDEO_AVCLevel21 },
 { 20250, 1620, 113, 4000, OMX_VIDEO_AVCLevel22 },
 { 40500, 1620, 113, 10000, OMX_VIDEO_AVCLevel3  },
 { 108000, 3600, 169, 14000, OMX_VIDEO_AVCLevel31 },
 { 216000, 5120, 202, 20000, OMX_VIDEO_AVCLevel32 },
 { 245760, 8192, 256, 20000, OMX_VIDEO_AVCLevel4  },
 { 245760, 8192, 256, 50000, OMX_VIDEO_AVCLevel41 },
 { 522240, 8704, 263, 50000, OMX_VIDEO_AVCLevel42 },
 { 589824, 22080, 420, 135000, OMX_VIDEO_AVCLevel5  },
 { 983040, 36864, 543, 240000, OMX_VIDEO_AVCLevel51 },
 { 2073600, 36864, 543, 240000, OMX_VIDEO_AVCLevel52 },
 };

 for (size_t i = 0; i < ARRAY_SIZE(limits); i++) {
 const int (&limit)[5] = limits[i];
 if (rate <= limit[0] && mbs <= limit[1] && maxDimension <= limit[2]
 && bitrate <= limit[3]) {
 return limit[4];
 }
 }
 return 0;
}

OMX_ERRORTYPE SoftAACEncoder::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPortFormat:
 {

             OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

            formatParams->eEncoding =
 (formatParams->nPortIndex == 0)
 ? OMX_AUDIO_CodingPCM : OMX_AUDIO_CodingAAC;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {

             OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
                 (OMX_AUDIO_PARAM_AACPROFILETYPE *)params;
 
             if (aacParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            aacParams->nBitRate = mBitRate;
            aacParams->nAudioBandWidth = 0;
            aacParams->nAACtools = 0;
            aacParams->nAACERtools = 0;
            aacParams->eAACProfile = OMX_AUDIO_AACObjectMain;
            aacParams->eAACStreamFormat = OMX_AUDIO_AACStreamFormatMP4FF;
            aacParams->eChannelMode = OMX_AUDIO_ChannelModeStereo;

            aacParams->nChannels = mNumChannels;
            aacParams->nSampleRate = mSampleRate;
            aacParams->nFrameLength = 0;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSampleRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftVideoDecoderOMXComponent::getExtensionIndex(
 const char *name, OMX_INDEXTYPE *index) {
 if (!strcmp(name, "OMX.google.android.index.prepareForAdaptivePlayback")) {
 *(int32_t*)index = kPrepareForAdaptivePlaybackIndex;
 return OMX_ErrorNone;
 }

 return SimpleSoftOMXComponent::getExtensionIndex(name, index);
}

OMX_ERRORTYPE SoftAVCEncoder::releaseEncoder() {
 if (!mStarted) {
 return OMX_ErrorNone;
 }

 PVAVCCleanUpEncoder(mHandle);
    releaseOutputBuffers();

    free(mInputFrameData);
    mInputFrameData = NULL;

    free(mSliceGroup);
    mSliceGroup = NULL;

 delete mEncParams;
    mEncParams = NULL;

 delete mHandle;
    mHandle = NULL;

    mStarted = false;

 return OMX_ErrorNone;
}

void SoftAVCEncoder::signalBufferReturned(MediaBuffer *buffer) {
    UNUSED_UNLESS_VERBOSE(buffer);
    ALOGV("signalBufferReturned: %p", buffer);
}

void ACodec::initiateStart() {
 (new AMessage(kWhatStart, this))->post();
}

void SoftOpus::onQueueFilled(OMX_U32 portIndex) {
 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 if (mOutputPortSettingsChange != NONE) {
 return;
 }

 if (portIndex == 0 && mInputBufferCount < 3) {
 BufferInfo *info = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *header = info->mHeader;

 const uint8_t *data = header->pBuffer + header->nOffset;
 size_t size = header->nFilledLen;

 if (mInputBufferCount == 0) {
            CHECK(mHeader == NULL);
            mHeader = new OpusHeader();
            memset(mHeader, 0, sizeof(*mHeader));
 if (!ParseOpusHeader(data, size, mHeader)) {
                ALOGV("Parsing Opus Header failed.");
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }

 uint8_t channel_mapping[kMaxChannels] = {0};
 if (mHeader->channels <= kMaxChannelsWithDefaultLayout) {
                memcpy(&channel_mapping,
                       kDefaultOpusChannelLayout,
                       kMaxChannelsWithDefaultLayout);
 } else {
                memcpy(&channel_mapping,
                       mHeader->stream_map,
                       mHeader->channels);
 }

 int status = OPUS_INVALID_STATE;
            mDecoder = opus_multistream_decoder_create(kRate,
                                                       mHeader->channels,
                                                       mHeader->num_streams,
                                                       mHeader->num_coupled,
                                                       channel_mapping,
 &status);
 if (!mDecoder || status != OPUS_OK) {
                ALOGV("opus_multistream_decoder_create failed status=%s",
                      opus_strerror(status));
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
            status =
                opus_multistream_decoder_ctl(mDecoder,
                                             OPUS_SET_GAIN(mHeader->gain_db));
 if (status != OPUS_OK) {
                ALOGV("Failed to set OPUS header gain; status=%s",
                      opus_strerror(status));
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 } else if (mInputBufferCount == 1) {
            mCodecDelay = ns_to_samples(
 *(reinterpret_cast<int64_t*>(header->pBuffer +
                                                           header->nOffset)),
                              kRate);
            mSamplesToDiscard = mCodecDelay;
 } else {
            mSeekPreRoll = ns_to_samples(
 *(reinterpret_cast<int64_t*>(header->pBuffer +
                                                            header->nOffset)),
                               kRate);
            notify(OMX_EventPortSettingsChanged, 1, 0, NULL);
            mOutputPortSettingsChange = AWAITING_DISABLED;
 }

        inQueue.erase(inQueue.begin());
        info->mOwnedByUs = false;
        notifyEmptyBufferDone(header);
 ++mInputBufferCount;
 return;
 }

 while (!inQueue.empty() && !outQueue.empty()) {
 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {
            inQueue.erase(inQueue.begin());
            inInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inHeader);
 return;
 }

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
            inQueue.erase(inQueue.begin());
            inInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inHeader);

            outHeader->nFilledLen = 0;
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;

            outQueue.erase(outQueue.begin());
            outInfo->mOwnedByUs = false;
            notifyFillBufferDone(outHeader);
 return;
 }

 if (inHeader->nOffset == 0) {
            mAnchorTimeUs = inHeader->nTimeStamp;
            mNumFramesOutput = 0;
 }

 if (inHeader->nTimeStamp == 0) {
            mSamplesToDiscard = mCodecDelay;
 }

 const uint8_t *data = inHeader->pBuffer + inHeader->nOffset;
 const uint32_t size = inHeader->nFilledLen;

 int numFrames = opus_multistream_decode(mDecoder,
                                                data,
                                                size,
 (int16_t *)outHeader->pBuffer,
                                                kMaxOpusOutputPacketSizeSamples,
 0);
 if (numFrames < 0) {
            ALOGE("opus_multistream_decode returned %d", numFrames);
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }

        outHeader->nOffset = 0;
 if (mSamplesToDiscard > 0) {
 if (mSamplesToDiscard > numFrames) {
                mSamplesToDiscard -= numFrames;
                numFrames = 0;
 } else {
                numFrames -= mSamplesToDiscard;
                outHeader->nOffset = mSamplesToDiscard * sizeof(int16_t) *
                                     mHeader->channels;
                mSamplesToDiscard = 0;
 }
 }

        outHeader->nFilledLen = numFrames * sizeof(int16_t) * mHeader->channels;
        outHeader->nFlags = 0;

        outHeader->nTimeStamp = mAnchorTimeUs +
 (mNumFramesOutput * 1000000ll) /
                                kRate;

        mNumFramesOutput += numFrames;

        inInfo->mOwnedByUs = false;
        inQueue.erase(inQueue.begin());
        inInfo = NULL;
        notifyEmptyBufferDone(inHeader);
        inHeader = NULL;

        outInfo->mOwnedByUs = false;
        outQueue.erase(outQueue.begin());
        outInfo = NULL;
        notifyFillBufferDone(outHeader);
        outHeader = NULL;

 ++mInputBufferCount;
 }
}

status_t ACodec::setupAMRCodec(bool encoder, bool isWAMR, int32_t bitrate) {
    OMX_AUDIO_PARAM_AMRTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = encoder ? kPortIndexOutput : kPortIndexInput;

 status_t err =
        mOMX->getParameter(mNode, OMX_IndexParamAudioAmr, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

    def.eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;
    def.eAMRBandMode = pickModeFromBitRate(isWAMR, bitrate);

    err = mOMX->setParameter(
            mNode, OMX_IndexParamAudioAmr, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

 return setupRawAudioFormat(
            encoder ? kPortIndexInput : kPortIndexOutput,
            isWAMR ? 16000 : 8000 /* sampleRate */,
 1 /* numChannels */);
}

 virtual status_t getGraphicBufferUsage(
            node_id node, OMX_U32 port_index, OMX_U32* usage) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        remote()->transact(GET_GRAPHIC_BUFFER_USAGE, data, &reply);

 status_t err = reply.readInt32();
 *usage = reply.readInt32();
 return err;
 }

bool ACodec::describeDefaultColorFormat(DescribeColorFormatParams &params) {
 MediaImage &image = params.sMediaImage;
    memset(&image, 0, sizeof(image));

    image.mType = MediaImage::MEDIA_IMAGE_TYPE_UNKNOWN;
    image.mNumPlanes = 0;

 const OMX_COLOR_FORMATTYPE fmt = params.eColorFormat;
    image.mWidth = params.nFrameWidth;
    image.mHeight = params.nFrameHeight;

 if (fmt != OMX_COLOR_FormatYUV420Planar &&
        fmt != OMX_COLOR_FormatYUV420PackedPlanar &&
        fmt != OMX_COLOR_FormatYUV420SemiPlanar &&
        fmt != OMX_COLOR_FormatYUV420PackedSemiPlanar &&
        fmt != HAL_PIXEL_FORMAT_YV12) {
        ALOGW("do not know color format 0x%x = %d", fmt, fmt);
 return false;
 }

 if (params.nStride != 0 && params.nSliceHeight == 0) {
        ALOGW("using sliceHeight=%u instead of what codec advertised (=0)",
                params.nFrameHeight);
        params.nSliceHeight = params.nFrameHeight;
 }

 if (params.nStride == 0 || params.nSliceHeight == 0) {
        ALOGW("cannot describe color format 0x%x = %d with stride=%u and sliceHeight=%u",
                fmt, fmt, params.nStride, params.nSliceHeight);
 return false;
 }

    image.mType = MediaImage::MEDIA_IMAGE_TYPE_YUV;
    image.mNumPlanes = 3;
    image.mBitDepth = 8;
    image.mPlane[image.Y].mOffset = 0;
    image.mPlane[image.Y].mColInc = 1;
    image.mPlane[image.Y].mRowInc = params.nStride;
    image.mPlane[image.Y].mHorizSubsampling = 1;
    image.mPlane[image.Y].mVertSubsampling = 1;

 switch ((int)fmt) {
 case HAL_PIXEL_FORMAT_YV12:
 if (params.bUsingNativeBuffers) {
 size_t ystride = align(params.nStride, 16);
 size_t cstride = align(params.nStride / 2, 16);
                image.mPlane[image.Y].mRowInc = ystride;

                image.mPlane[image.V].mOffset = ystride * params.nSliceHeight;
                image.mPlane[image.V].mColInc = 1;
                image.mPlane[image.V].mRowInc = cstride;
                image.mPlane[image.V].mHorizSubsampling = 2;
                image.mPlane[image.V].mVertSubsampling = 2;

                image.mPlane[image.U].mOffset = image.mPlane[image.V].mOffset
 + (cstride * params.nSliceHeight / 2);
                image.mPlane[image.U].mColInc = 1;
                image.mPlane[image.U].mRowInc = cstride;
                image.mPlane[image.U].mHorizSubsampling = 2;
                image.mPlane[image.U].mVertSubsampling = 2;
 break;
 } else {
 }

 case OMX_COLOR_FormatYUV420Planar:
 case OMX_COLOR_FormatYUV420PackedPlanar:
            image.mPlane[image.U].mOffset = params.nStride * params.nSliceHeight;
            image.mPlane[image.U].mColInc = 1;
            image.mPlane[image.U].mRowInc = params.nStride / 2;
            image.mPlane[image.U].mHorizSubsampling = 2;
            image.mPlane[image.U].mVertSubsampling = 2;

            image.mPlane[image.V].mOffset = image.mPlane[image.U].mOffset
 + (params.nStride * params.nSliceHeight / 4);
            image.mPlane[image.V].mColInc = 1;
            image.mPlane[image.V].mRowInc = params.nStride / 2;
            image.mPlane[image.V].mHorizSubsampling = 2;
            image.mPlane[image.V].mVertSubsampling = 2;
 break;

 case OMX_COLOR_FormatYUV420SemiPlanar:
 case OMX_COLOR_FormatYUV420PackedSemiPlanar:
            image.mPlane[image.U].mOffset = params.nStride * params.nSliceHeight;
            image.mPlane[image.U].mColInc = 2;
            image.mPlane[image.U].mRowInc = params.nStride;
            image.mPlane[image.U].mHorizSubsampling = 2;
            image.mPlane[image.U].mVertSubsampling = 2;

            image.mPlane[image.V].mOffset = image.mPlane[image.U].mOffset + 1;
            image.mPlane[image.V].mColInc = 2;
            image.mPlane[image.V].mRowInc = params.nStride;
            image.mPlane[image.V].mHorizSubsampling = 2;
            image.mPlane[image.V].mVertSubsampling = 2;
 break;

 default:
            TRESPASS();
 }
 return true;
}

 virtual status_t freeBuffer(
            node_id node, OMX_U32 port_index, buffer_id buffer) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeInt32((int32_t)buffer);
        remote()->transact(FREE_BUFFER, data, &reply);

 return reply.readInt32();
 }

static OMX_AUDIO_AMRBANDMODETYPE pickModeFromBitRate(
 bool isAMRWB, int32_t bps) {
 if (isAMRWB) {
 if (bps <= 6600) {
 return OMX_AUDIO_AMRBandModeWB0;
 } else if (bps <= 8850) {
 return OMX_AUDIO_AMRBandModeWB1;
 } else if (bps <= 12650) {
 return OMX_AUDIO_AMRBandModeWB2;
 } else if (bps <= 14250) {
 return OMX_AUDIO_AMRBandModeWB3;
 } else if (bps <= 15850) {
 return OMX_AUDIO_AMRBandModeWB4;
 } else if (bps <= 18250) {
 return OMX_AUDIO_AMRBandModeWB5;
 } else if (bps <= 19850) {
 return OMX_AUDIO_AMRBandModeWB6;
 } else if (bps <= 23050) {
 return OMX_AUDIO_AMRBandModeWB7;
 }

 return OMX_AUDIO_AMRBandModeWB8;
 } else { // AMRNB
 if (bps <= 4750) {
 return OMX_AUDIO_AMRBandModeNB0;
 } else if (bps <= 5150) {
 return OMX_AUDIO_AMRBandModeNB1;
 } else if (bps <= 5900) {
 return OMX_AUDIO_AMRBandModeNB2;
 } else if (bps <= 6700) {
 return OMX_AUDIO_AMRBandModeNB3;
 } else if (bps <= 7400) {
 return OMX_AUDIO_AMRBandModeNB4;
 } else if (bps <= 7950) {
 return OMX_AUDIO_AMRBandModeNB5;
 } else if (bps <= 10200) {
 return OMX_AUDIO_AMRBandModeNB6;
 }

 return OMX_AUDIO_AMRBandModeNB7;
 }
}

bool ACodec::ExecutingState::onOMXFrameRendered(int64_t mediaTimeUs, nsecs_t systemNano) {
    mCodec->onFrameRendered(mediaTimeUs, systemNano);
 return true;
}

static void* MallocWrapper(
 void * /* userData */, int32_t size, int32_t /* attrs */) {
 void *ptr = malloc(size);
 if (ptr)
        memset(ptr, 0, size);
 return ptr;
}

status_t ACodec::setParameters(const sp<AMessage> &params) {
 int32_t videoBitrate;
 if (params->findInt32("video-bitrate", &videoBitrate)) {
        OMX_VIDEO_CONFIG_BITRATETYPE configParams;
 InitOMXParams(&configParams);
        configParams.nPortIndex = kPortIndexOutput;
        configParams.nEncodeBitrate = videoBitrate;

 status_t err = mOMX->setConfig(
                mNode,
                OMX_IndexConfigVideoBitrate,
 &configParams,
 sizeof(configParams));

 if (err != OK) {
            ALOGE("setConfig(OMX_IndexConfigVideoBitrate, %d) failed w/ err %d",
                   videoBitrate, err);

 return err;
 }
 }

 int64_t skipFramesBeforeUs;
 if (params->findInt64("skip-frames-before", &skipFramesBeforeUs)) {
 status_t err =
            mOMX->setInternalOption(
                     mNode,
                     kPortIndexInput,
                     IOMX::INTERNAL_OPTION_START_TIME,
 &skipFramesBeforeUs,
 sizeof(skipFramesBeforeUs));

 if (err != OK) {
            ALOGE("Failed to set parameter 'skip-frames-before' (err %d)", err);
 return err;
 }
 }

 int32_t dropInputFrames;
 if (params->findInt32("drop-input-frames", &dropInputFrames)) {
 bool suspend = dropInputFrames != 0;

 status_t err =
            mOMX->setInternalOption(
                     mNode,
                     kPortIndexInput,
                     IOMX::INTERNAL_OPTION_SUSPEND,
 &suspend,
 sizeof(suspend));

 if (err != OK) {
            ALOGE("Failed to set parameter 'drop-input-frames' (err %d)", err);
 return err;
 }
 }

 int32_t dummy;
 if (params->findInt32("request-sync", &dummy)) {
 status_t err = requestIDRFrame();

 if (err != OK) {
            ALOGE("Requesting a sync frame failed w/ err %d", err);
 return err;
 }
 }

 float rate;
 if (params->findFloat("operating-rate", &rate) && rate > 0) {
 status_t err = setOperatingRate(rate, mIsVideo);
 if (err != OK) {
            ALOGE("Failed to set parameter 'operating-rate' (err %d)", err);
 return err;
 }
 }

 return OK;
}

void ACodec::LoadedState::onShutdown(bool keepComponentAllocated) {
 if (!keepComponentAllocated) {
 (void)mCodec->mOMX->freeNode(mCodec->mNode);

        mCodec->changeState(mCodec->mUninitializedState);
 }

 if (mCodec->mExplicitShutdown) {
        sp<AMessage> notify = mCodec->mNotify->dup();
        notify->setInt32("what", CodecBase::kWhatShutdownCompleted);
        notify->post();
        mCodec->mExplicitShutdown = false;
 }
}

 virtual void onMessages(const std::list<omx_message> &messages) {
 if (messages.empty()) {
 return;
 }

        sp<AMessage> notify = mNotify->dup();
 bool first = true;
        sp<MessageList> msgList = new MessageList();
 for (std::list<omx_message>::const_iterator it = messages.cbegin();
              it != messages.cend(); ++it) {
 const omx_message &omx_msg = *it;
 if (first) {
                notify->setInt32("node", omx_msg.node);
                first = false;
 }

            sp<AMessage> msg = new AMessage;
            msg->setInt32("type", omx_msg.type);
 switch (omx_msg.type) {
 case omx_message::EVENT:
 {
                    msg->setInt32("event", omx_msg.u.event_data.event);
                    msg->setInt32("data1", omx_msg.u.event_data.data1);
                    msg->setInt32("data2", omx_msg.u.event_data.data2);
 break;
 }

 case omx_message::EMPTY_BUFFER_DONE:
 {
                    msg->setInt32("buffer", omx_msg.u.buffer_data.buffer);
                    msg->setInt32("fence_fd", omx_msg.fenceFd);
 break;
 }

 case omx_message::FILL_BUFFER_DONE:
 {
                    msg->setInt32(
 "buffer", omx_msg.u.extended_buffer_data.buffer);
                    msg->setInt32(
 "range_offset",
                            omx_msg.u.extended_buffer_data.range_offset);
                    msg->setInt32(
 "range_length",
                            omx_msg.u.extended_buffer_data.range_length);
                    msg->setInt32(
 "flags",
                            omx_msg.u.extended_buffer_data.flags);
                    msg->setInt64(
 "timestamp",
                            omx_msg.u.extended_buffer_data.timestamp);
                    msg->setInt32(
 "fence_fd", omx_msg.fenceFd);
 break;
 }

 case omx_message::FRAME_RENDERED:
 {
                    msg->setInt64(
 "media_time_us", omx_msg.u.render_data.timestamp);
                    msg->setInt64(
 "system_nano", omx_msg.u.render_data.nanoTime);
 break;
 }

 default:
                    ALOGE("Unrecognized message type: %d", omx_msg.type);
 break;
 }
            msgList->getList().push_back(msg);
 }
        notify->setObject("messages", msgList);
        notify->post();
 }

void ACodec::ExecutingToIdleState::stateEntered() {
    ALOGV("[%s] Now Executing->Idle", mCodec->mComponentName.c_str());

    mComponentNowIdle = false;
    mCodec->mSentFormat = false;
}

bool ACodec::IdleToLoadedState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
 switch (event) {
 case OMX_EventCmdComplete:
 {
 if (data1 != (OMX_U32)OMX_CommandStateSet
 || data2 != (OMX_U32)OMX_StateLoaded) {
                ALOGE("Unexpected command completion in IdleToLoadedState: %s(%u) %s(%u)",
                        asString((OMX_COMMANDTYPE)data1), data1,
                        asString((OMX_STATETYPE)data2), data2);
                mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return true;
 }

            mCodec->changeState(mCodec->mLoadedState);

 return true;
 }

 default:
 return BaseState::onOMXEvent(event, data1, data2);
 }
}

void ACodec::dumpBuffers(OMX_U32 portIndex) {
    CHECK(portIndex == kPortIndexInput || portIndex == kPortIndexOutput);
    ALOGI("[%s] %s port has %zu buffers:", mComponentName.c_str(),
            portIndex == kPortIndexInput ? "input" : "output", mBuffers[portIndex].size());
 for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
 const BufferInfo &info = mBuffers[portIndex][i];
        ALOGI("  slot %2zu: #%8u %p/%p %s(%d) dequeued:%u",
                i, info.mBufferID, info.mGraphicBuffer.get(),
                info.mGraphicBuffer == NULL ? NULL : info.mGraphicBuffer->getNativeBuffer(),
                _asString(info.mStatus), info.mStatus, info.mDequeuedAt);
 }
}

void SoftVideoDecoderOMXComponent::onReset() {
    mOutputPortSettingsChange = NONE;
}

OMX_ERRORTYPE SoftAVCEncoder::initEncParams() {
    CHECK(mHandle != NULL);
    memset(mHandle, 0, sizeof(tagAVCHandle));
    mHandle->AVCObject = NULL;
    mHandle->userData = this;
    mHandle->CBAVC_DPBAlloc = DpbAllocWrapper;
    mHandle->CBAVC_FrameBind = BindFrameWrapper;
    mHandle->CBAVC_FrameUnbind = UnbindFrameWrapper;
    mHandle->CBAVC_Malloc = MallocWrapper;
    mHandle->CBAVC_Free = FreeWrapper;

    CHECK(mEncParams != NULL);
    memset(mEncParams, 0, sizeof(*mEncParams));
    mEncParams->rate_control = AVC_ON;
    mEncParams->initQP = 0;
    mEncParams->init_CBP_removal_delay = 1600;

    mEncParams->intramb_refresh = 0;
    mEncParams->auto_scd = AVC_ON;
    mEncParams->out_of_band_param_set = AVC_ON;
    mEncParams->poc_type = 2;
    mEncParams->log2_max_poc_lsb_minus_4 = 12;
    mEncParams->delta_poc_zero_flag = 0;
    mEncParams->offset_poc_non_ref = 0;
    mEncParams->offset_top_bottom = 0;
    mEncParams->num_ref_in_cycle = 0;
    mEncParams->offset_poc_ref = NULL;

    mEncParams->num_ref_frame = 1;
    mEncParams->num_slice_group = 1;
    mEncParams->fmo_type = 0;

    mEncParams->db_filter = AVC_ON;
    mEncParams->disable_db_idc = 0;

    mEncParams->alpha_offset = 0;
    mEncParams->beta_offset = 0;
    mEncParams->constrained_intra_pred = AVC_OFF;

    mEncParams->data_par = AVC_OFF;
    mEncParams->fullsearch = AVC_OFF;
    mEncParams->search_range = 16;
    mEncParams->sub_pel = AVC_OFF;
    mEncParams->submb_pred = AVC_OFF;
    mEncParams->rdopt_mode = AVC_OFF;
    mEncParams->bidir_pred = AVC_OFF;

    mEncParams->use_overrun_buffer = AVC_OFF;

 if (mColorFormat != OMX_COLOR_FormatYUV420Planar || mInputDataIsMeta) {
        free(mInputFrameData);
 if (((uint64_t)mWidth * mHeight) > ((uint64_t)INT32_MAX / 3)) {
            ALOGE("Buffer size is too big.");
 return OMX_ErrorUndefined;
 }
        mInputFrameData =
 (uint8_t *) malloc((mWidth * mHeight * 3 ) >> 1);
        CHECK(mInputFrameData != NULL);
 }

 if (mWidth % 16 != 0 || mHeight % 16 != 0) {
        ALOGE("Video frame size %dx%d must be a multiple of 16",
            mWidth, mHeight);
 return OMX_ErrorBadParameter;
 }

    mEncParams->width = mWidth;
    mEncParams->height = mHeight;
    mEncParams->bitrate = mBitrate;
    mEncParams->frame_rate = (1000 * mFramerate) >> 16; // In frames/ms!, mFramerate is in Q16
    mEncParams->CPB_size = (uint32_t) (mBitrate >> 1);

 int32_t nMacroBlocks = divUp(mWidth, 16) * divUp(mHeight, 16);
    CHECK(mSliceGroup == NULL);
 if ((size_t)nMacroBlocks > SIZE_MAX / sizeof(uint32_t)) {
        ALOGE("requested memory size is too big.");
 return OMX_ErrorUndefined;
 }
    mSliceGroup = (uint32_t *) malloc(sizeof(uint32_t) * nMacroBlocks);
    CHECK(mSliceGroup != NULL);
 for (int ii = 0, idx = 0; ii < nMacroBlocks; ++ii) {
        mSliceGroup[ii] = idx++;
 if (idx >= mEncParams->num_slice_group) {
            idx = 0;
 }
 }
    mEncParams->slice_group = mSliceGroup;

 if (mIDRFrameRefreshIntervalInSec < 0) {
        mEncParams->idr_period = -1;
 } else if (mIDRFrameRefreshIntervalInSec == 0) {
        mEncParams->idr_period = 1; // All I frames
 } else {
        mEncParams->idr_period =
 (mIDRFrameRefreshIntervalInSec * mFramerate) >> 16; // mFramerate is in Q16
 }

    mEncParams->profile = mAVCEncProfile;
    mEncParams->level = mAVCEncLevel;

 return OMX_ErrorNone;
}

void SoftVideoDecoderOMXComponent::onPortEnableCompleted(OMX_U32 portIndex, bool enabled) {
 if (portIndex != kOutputPortIndex) {
 return;
 }

 switch (mOutputPortSettingsChange) {
 case NONE:
 break;

 case AWAITING_DISABLED:
 {
            CHECK(!enabled);
            mOutputPortSettingsChange = AWAITING_ENABLED;
 break;
 }

 default:
 {
            CHECK_EQ((int)mOutputPortSettingsChange, (int)AWAITING_ENABLED);
            CHECK(enabled);
            mOutputPortSettingsChange = NONE;
 break;
 }
 }
}

size_t ACodec::countBuffersOwnedByComponent(OMX_U32 portIndex) const {
 size_t n = 0;

 for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
 const BufferInfo &info = mBuffers[portIndex].itemAt(i);

 if (info.mStatus == BufferInfo::OWNED_BY_COMPONENT) {
 ++n;
 }
 }

 return n;
}

status_t ACodec::setupAVCEncoderParameters(const sp<AMessage> &msg) {
 int32_t bitrate, iFrameInterval;
 if (!msg->findInt32("bitrate", &bitrate)
 || !msg->findInt32("i-frame-interval", &iFrameInterval)) {
 return INVALID_OPERATION;
 }

    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);

 float frameRate;
 if (!msg->findFloat("frame-rate", &frameRate)) {
 int32_t tmp;
 if (!msg->findInt32("frame-rate", &tmp)) {
 return INVALID_OPERATION;
 }
        frameRate = (float)tmp;
 }

 status_t err = OK;
 int32_t intraRefreshMode = 0;
 if (msg->findInt32("intra-refresh-mode", &intraRefreshMode)) {
        err = setCyclicIntraMacroblockRefresh(msg, intraRefreshMode);
 if (err != OK) {
            ALOGE("Setting intra macroblock refresh mode (%d) failed: 0x%x",
                    err, intraRefreshMode);
 return err;
 }
 }

    OMX_VIDEO_PARAM_AVCTYPE h264type;
 InitOMXParams(&h264type);
    h264type.nPortIndex = kPortIndexOutput;

    err = mOMX->getParameter(
            mNode, OMX_IndexParamVideoAvc, &h264type, sizeof(h264type));

 if (err != OK) {
 return err;
 }

    h264type.nAllowedPictureTypes =
        OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP;

 int32_t profile;
 if (msg->findInt32("profile", &profile)) {
 int32_t level;
 if (!msg->findInt32("level", &level)) {
 return INVALID_OPERATION;
 }

        err = verifySupportForProfileAndLevel(profile, level);

 if (err != OK) {
 return err;
 }

        h264type.eProfile = static_cast<OMX_VIDEO_AVCPROFILETYPE>(profile);
        h264type.eLevel = static_cast<OMX_VIDEO_AVCLEVELTYPE>(level);
 }

 if (h264type.eProfile != OMX_VIDEO_AVCProfileBaseline) {
        ALOGW("Use baseline profile instead of %d for AVC recording",
            h264type.eProfile);
        h264type.eProfile = OMX_VIDEO_AVCProfileBaseline;
 }

 if (h264type.eProfile == OMX_VIDEO_AVCProfileBaseline) {
        h264type.nSliceHeaderSpacing = 0;
        h264type.bUseHadamard = OMX_TRUE;
        h264type.nRefFrames = 1;
        h264type.nBFrames = 0;
        h264type.nPFrames = setPFramesSpacing(iFrameInterval, frameRate);
 if (h264type.nPFrames == 0) {
            h264type.nAllowedPictureTypes = OMX_VIDEO_PictureTypeI;
 }
        h264type.nRefIdx10ActiveMinus1 = 0;
        h264type.nRefIdx11ActiveMinus1 = 0;
        h264type.bEntropyCodingCABAC = OMX_FALSE;
        h264type.bWeightedPPrediction = OMX_FALSE;
        h264type.bconstIpred = OMX_FALSE;
        h264type.bDirect8x8Inference = OMX_FALSE;
        h264type.bDirectSpatialTemporal = OMX_FALSE;
        h264type.nCabacInitIdc = 0;
 }

 if (h264type.nBFrames != 0) {
        h264type.nAllowedPictureTypes |= OMX_VIDEO_PictureTypeB;
 }

    h264type.bEnableUEP = OMX_FALSE;
    h264type.bEnableFMO = OMX_FALSE;
    h264type.bEnableASO = OMX_FALSE;
    h264type.bEnableRS = OMX_FALSE;
    h264type.bFrameMBsOnly = OMX_TRUE;
    h264type.bMBAFF = OMX_FALSE;
    h264type.eLoopFilterMode = OMX_VIDEO_AVCLoopFilterEnable;

    err = mOMX->setParameter(
            mNode, OMX_IndexParamVideoAvc, &h264type, sizeof(h264type));

 if (err != OK) {
 return err;
 }

 return configureBitrate(bitrate, bitrateMode);
}

android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftFlacEncoder(name, callbacks, appData, component);
}

void SoftAVCEncoder::unbindOutputBuffer(int32_t index) {
    CHECK(index >= 0);
}

SoftRaw::~SoftRaw() {
}

ACodec::PortDescription::PortDescription() {
}

 CodecObserver() {}

 virtual status_t allocateNode(
 const char *name, const sp<IOMXObserver> &observer, node_id *node) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeCString(name);
        data.writeStrongBinder(IInterface::asBinder(observer));
        remote()->transact(ALLOCATE_NODE, data, &reply);

 status_t err = reply.readInt32();
 if (err == OK) {
 *node = (node_id)reply.readInt32();
 } else {
 *node = 0;
 }

 return err;
 }

status_t SoftAMRWBEncoder::initEncoder() {
    mApiHandle = new VO_AUDIO_CODECAPI;

 if (VO_ERR_NONE != voGetAMRWBEncAPI(mApiHandle)) {
        ALOGE("Failed to get api handle");
 return UNKNOWN_ERROR;
 }

    mMemOperator = new VO_MEM_OPERATOR;
    mMemOperator->Alloc = cmnMemAlloc;
    mMemOperator->Copy = cmnMemCopy;
    mMemOperator->Free = cmnMemFree;
    mMemOperator->Set = cmnMemSet;
    mMemOperator->Check = cmnMemCheck;

    VO_CODEC_INIT_USERDATA userData;
    memset(&userData, 0, sizeof(userData));
    userData.memflag = VO_IMF_USERMEMOPERATOR;
    userData.memData = (VO_PTR) mMemOperator;

 if (VO_ERR_NONE != mApiHandle->Init(
 &mEncoderHandle, VO_AUDIO_CodingAMRWB, &userData)) {
        ALOGE("Failed to init AMRWB encoder");
 return UNKNOWN_ERROR;
 }

    VOAMRWBFRAMETYPE type = VOAMRWB_RFC3267;
 if (VO_ERR_NONE != mApiHandle->SetParam(
                mEncoderHandle, VO_PID_AMRWB_FRAMETYPE, &type)) {
        ALOGE("Failed to set AMRWB encoder frame type to %d", type);
 return UNKNOWN_ERROR;
 }

 return OK;
}

bool ACodec::ExecutingToIdleState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
 switch (event) {
 case OMX_EventCmdComplete:
 {
 if (data1 != (OMX_U32)OMX_CommandStateSet
 || data2 != (OMX_U32)OMX_StateIdle) {
                ALOGE("Unexpected command completion in ExecutingToIdleState: %s(%u) %s(%u)",
                        asString((OMX_COMMANDTYPE)data1), data1,
                        asString((OMX_STATETYPE)data2), data2);
                mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return true;
 }

            mComponentNowIdle = true;

            changeStateIfWeOwnAllBuffers();

 return true;
 }

 case OMX_EventPortSettingsChanged:
 case OMX_EventBufferFlag:
 {
 return true;
 }

 default:
 return BaseState::onOMXEvent(event, data1, data2);
 }
}

void ACodec::onSignalEndOfInputStream() {
    sp<AMessage> notify = mNotify->dup();
    notify->setInt32("what", CodecBase::kWhatSignaledInputEOS);

 status_t err = mOMX->signalEndOfInputStream(mNode);
 if (err != OK) {
        notify->setInt32("err", err);
 }
    notify->post();
}

void ACodec::signalEndOfInputStream() {
 (new AMessage(kWhatSignalEndOfInputStream, this))->post();
}

void ACodec::ExecutingState::submitOutputBuffers() {
    submitRegularOutputBuffers();
 if (mCodec->storingMetadataInDecodedBuffers()) {
        submitOutputMetaBuffers();
 }
}

void SoftG711::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 while (!inQueue.empty() && !outQueue.empty()) {
 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
            inQueue.erase(inQueue.begin());
            inInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inHeader);

            outHeader->nFilledLen = 0;
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;

            outQueue.erase(outQueue.begin());
            outInfo->mOwnedByUs = false;
            notifyFillBufferDone(outHeader);
 return;
 }

 if (inHeader->nFilledLen > kMaxNumSamplesPerFrame) {
            ALOGE("input buffer too large (%d).", inHeader->nFilledLen);

            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
            mSignalledError = true;
 }

 const uint8_t *inputptr = inHeader->pBuffer + inHeader->nOffset;

 if (mIsMLaw) {
 DecodeMLaw(
 reinterpret_cast<int16_t *>(outHeader->pBuffer),
                    inputptr, inHeader->nFilledLen);
 } else {
 DecodeALaw(
 reinterpret_cast<int16_t *>(outHeader->pBuffer),
                    inputptr, inHeader->nFilledLen);
 }

        outHeader->nTimeStamp = inHeader->nTimeStamp;
        outHeader->nOffset = 0;
        outHeader->nFilledLen = inHeader->nFilledLen * sizeof(int16_t);
        outHeader->nFlags = 0;

        inInfo->mOwnedByUs = false;
        inQueue.erase(inQueue.begin());
        inInfo = NULL;
        notifyEmptyBufferDone(inHeader);
        inHeader = NULL;

        outInfo->mOwnedByUs = false;
        outQueue.erase(outQueue.begin());
        outInfo = NULL;
        notifyFillBufferDone(outHeader);
        outHeader = NULL;
 }
}

OMX_ERRORTYPE SoftFlacEncoder::configureEncoder() {
    ALOGV("SoftFlacEncoder::configureEncoder() numChannel=%d, sampleRate=%d",
            mNumChannels, mSampleRate);

 if (mSignalledError || (mFlacStreamEncoder == NULL)) {
        ALOGE("can't configure encoder: no encoder or invalid state");
 return OMX_ErrorInvalidState;
 }

    FLAC__bool ok = true;
    ok = ok && FLAC__stream_encoder_set_channels(mFlacStreamEncoder, mNumChannels);
    ok = ok && FLAC__stream_encoder_set_sample_rate(mFlacStreamEncoder, mSampleRate);
    ok = ok && FLAC__stream_encoder_set_bits_per_sample(mFlacStreamEncoder, 16);
    ok = ok && FLAC__stream_encoder_set_compression_level(mFlacStreamEncoder,
 (unsigned)mCompressionLevel);
    ok = ok && FLAC__stream_encoder_set_verify(mFlacStreamEncoder, false);
 if (!ok) { goto return_result; }

    ok &= FLAC__STREAM_ENCODER_INIT_STATUS_OK ==
            FLAC__stream_encoder_init_stream(mFlacStreamEncoder,
                    flacEncoderWriteCallback    /*write_callback*/,
                    NULL /*seek_callback*/,
                    NULL /*tell_callback*/,
                    NULL /*metadata_callback*/,
 (void *) this /*client_data*/);

return_result:
 if (ok) {
        ALOGV("encoder successfully configured");
 return OMX_ErrorNone;
 } else {
        ALOGE("unknown error when configuring encoder");
 return OMX_ErrorUndefined;
 }
}

OMX_ERRORTYPE SoftAVC::setFrameType(IV_PICTURE_CODING_TYPE_T e_frame_type) {
 ive_ctl_set_frame_type_ip_t s_frame_type_ip;
 ive_ctl_set_frame_type_op_t s_frame_type_op;
    IV_STATUS_T status;
    s_frame_type_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_frame_type_ip.e_sub_cmd = IVE_CMD_CTL_SET_FRAMETYPE;

    s_frame_type_ip.e_frame_type = e_frame_type;

    s_frame_type_ip.u4_timestamp_high = -1;
    s_frame_type_ip.u4_timestamp_low = -1;

    s_frame_type_ip.u4_size = sizeof(ive_ctl_set_frame_type_ip_t);
    s_frame_type_op.u4_size = sizeof(ive_ctl_set_frame_type_op_t);

    status = ive_api_function(mCodecCtx, &s_frame_type_ip, &s_frame_type_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set frame type = 0x%x\n",
                s_frame_type_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

bool ACodec::UninitializedState::onAllocateComponent(const sp<AMessage> &msg) {
    ALOGV("onAllocateComponent");

    CHECK(mCodec->mNode == 0);

 OMXClient client;
 if (client.connect() != OK) {
        mCodec->signalError(OMX_ErrorUndefined, NO_INIT);
 return false;
 }

    sp<IOMX> omx = client.interface();

    sp<AMessage> notify = new AMessage(kWhatOMXDied, mCodec);

    mDeathNotifier = new DeathNotifier(notify);
 if (IInterface::asBinder(omx)->linkToDeath(mDeathNotifier) != OK) {
        mDeathNotifier.clear();
 }

 Vector<OMXCodec::CodecNameAndQuirks> matchingCodecs;

 AString mime;

 AString componentName;
 uint32_t quirks = 0;
 int32_t encoder = false;
 if (msg->findString("componentName", &componentName)) {
 ssize_t index = matchingCodecs.add();
 OMXCodec::CodecNameAndQuirks *entry = &matchingCodecs.editItemAt(index);
        entry->mName = String8(componentName.c_str());

 if (!OMXCodec::findCodecQuirks(
                    componentName.c_str(), &entry->mQuirks)) {
            entry->mQuirks = 0;
 }
 } else {
        CHECK(msg->findString("mime", &mime));

 if (!msg->findInt32("encoder", &encoder)) {
            encoder = false;
 }

 OMXCodec::findMatchingCodecs(
                mime.c_str(),
                encoder, // createEncoder
                NULL, // matchComponentName
 0, // flags
 &matchingCodecs);
 }

    sp<CodecObserver> observer = new CodecObserver;
    IOMX::node_id node = 0;

 status_t err = NAME_NOT_FOUND;
 for (size_t matchIndex = 0; matchIndex < matchingCodecs.size();
 ++matchIndex) {
        componentName = matchingCodecs.itemAt(matchIndex).mName.string();
        quirks = matchingCodecs.itemAt(matchIndex).mQuirks;

 pid_t tid = gettid();
 int prevPriority = androidGetThreadPriority(tid);
        androidSetThreadPriority(tid, ANDROID_PRIORITY_FOREGROUND);
        err = omx->allocateNode(componentName.c_str(), observer, &node);
        androidSetThreadPriority(tid, prevPriority);

 if (err == OK) {
 break;
 } else {
            ALOGW("Allocating component '%s' failed, try next one.", componentName.c_str());
 }

        node = 0;
 }

 if (node == 0) {
 if (!mime.empty()) {
            ALOGE("Unable to instantiate a %scoder for type '%s' with err %#x.",
                    encoder ? "en" : "de", mime.c_str(), err);
 } else {
            ALOGE("Unable to instantiate codec '%s' with err %#x.", componentName.c_str(), err);
 }

        mCodec->signalError((OMX_ERRORTYPE)err, makeNoSideEffectStatus(err));
 return false;
 }

    notify = new AMessage(kWhatOMXMessageList, mCodec);
    observer->setNotificationMessage(notify);

    mCodec->mComponentName = componentName;
    mCodec->mRenderTracker.setComponentName(componentName);
    mCodec->mFlags = 0;

 if (componentName.endsWith(".secure")) {
        mCodec->mFlags |= kFlagIsSecure;
        mCodec->mFlags |= kFlagIsGrallocUsageProtected;
        mCodec->mFlags |= kFlagPushBlankBuffersToNativeWindowOnShutdown;
 }

    mCodec->mQuirks = quirks;
    mCodec->mOMX = omx;
    mCodec->mNode = node;

 {
        sp<AMessage> notify = mCodec->mNotify->dup();
        notify->setInt32("what", CodecBase::kWhatComponentAllocated);
        notify->setString("componentName", mCodec->mComponentName.c_str());
        notify->post();
 }

    mCodec->changeState(mCodec->mLoadedState);

 return true;
}

OMX_ERRORTYPE SoftAVC::setFrameRate() {
 ive_ctl_set_frame_rate_ip_t s_frame_rate_ip;
 ive_ctl_set_frame_rate_op_t s_frame_rate_op;
    IV_STATUS_T status;

    s_frame_rate_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_frame_rate_ip.e_sub_cmd = IVE_CMD_CTL_SET_FRAMERATE;

    s_frame_rate_ip.u4_src_frame_rate = mFramerate >> 16;
    s_frame_rate_ip.u4_tgt_frame_rate = mFramerate >> 16;

    s_frame_rate_ip.u4_timestamp_high = -1;
    s_frame_rate_ip.u4_timestamp_low = -1;

    s_frame_rate_ip.u4_size = sizeof(ive_ctl_set_frame_rate_ip_t);
    s_frame_rate_op.u4_size = sizeof(ive_ctl_set_frame_rate_op_t);

    status = ive_api_function(mCodecCtx, &s_frame_rate_ip, &s_frame_rate_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set frame rate = 0x%x\n",
                s_frame_rate_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

void ACodec::LoadedState::onCreateInputSurface(
 const sp<AMessage> & /* msg */) {
    ALOGV("onCreateInputSurface");

    sp<AMessage> notify = mCodec->mNotify->dup();
    notify->setInt32("what", CodecBase::kWhatInputSurfaceCreated);

    sp<IGraphicBufferProducer> bufferProducer;
 status_t err = mCodec->mOMX->createInputSurface(
            mCodec->mNode, kPortIndexInput, &bufferProducer, &mCodec->mInputMetadataType);

 if (err == OK) {
        err = setupInputSurface();
 }

 if (err == OK) {
        notify->setObject("input-surface",
 new BufferProducerWrapper(bufferProducer));
 } else {
        ALOGE("[%s] onCreateInputSurface returning error %d",
                mCodec->mComponentName.c_str(), err);
        notify->setInt32("err", err);
 }
    notify->post();
}

status_t ACodec::setOperatingRate(float rateFloat, bool isVideo) {
 if (rateFloat < 0) {
 return BAD_VALUE;
 }
    OMX_U32 rate;
 if (isVideo) {
 if (rateFloat > 65535) {
 return BAD_VALUE;
 }
        rate = (OMX_U32)(rateFloat * 65536.0f + 0.5f);
 } else {
 if (rateFloat > UINT_MAX) {
 return BAD_VALUE;
 }
        rate = (OMX_U32)(rateFloat);
 }
    OMX_PARAM_U32TYPE config;
 InitOMXParams(&config);
    config.nU32 = rate;
 status_t err = mOMX->setConfig(
            mNode, (OMX_INDEXTYPE)OMX_IndexConfigOperatingRate,
 &config, sizeof(config));
 if (err != OK) {
        ALOGI("codec does not support config operating rate (err %d)", err);
 }
 return OK;
}

ACodec::BaseState::PortMode ACodec::ExecutingState::getPortMode(
        OMX_U32 /* portIndex */) {
 return RESUBMIT_BUFFERS;
}

void ACodec::waitUntilAllPossibleNativeWindowBuffersAreReturnedToUs() {
 if (mNativeWindow == NULL) {
 return;
 }

 while (countBuffersOwnedByNativeWindow() > mNumUndequeuedBuffers
 && dequeueBufferFromNativeWindow() != NULL) {
 if (storingMetadataInDecodedBuffers() && mMetadataBuffersToSubmit > 0) {
 --mMetadataBuffersToSubmit;
 }
 }
}

SoftAVCEncoder::SoftAVCEncoder(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
            OMX_PTR appData,
            OMX_COMPONENTTYPE **component)
 : SoftVideoEncoderOMXComponent(
            name, "video_encoder.avc", OMX_VIDEO_CodingAVC,
            kProfileLevels, NELEM(kProfileLevels),
 176 /* width */, 144 /* height */,
            callbacks, appData, component),
      mIDRFrameRefreshIntervalInSec(1),
      mAVCEncProfile(AVC_BASELINE),
      mAVCEncLevel(AVC_LEVEL2),
      mNumInputFrames(-1),
      mPrevTimestampUs(-1),
      mStarted(false),
      mSawInputEOS(false),
      mSignalledError(false),
      mHandle(new tagAVCHandle),
      mEncParams(new tagAVCEncParam),
      mInputFrameData(NULL),
      mSliceGroup(NULL) {

 const size_t kOutputBufferSize =
 320 * ConversionTable[NELEM(ConversionTable) - 1].maxMacroBlocks;

    initPorts(
            kNumBuffers, kNumBuffers, kOutputBufferSize,
            MEDIA_MIMETYPE_VIDEO_AVC, 2 /* minCompressionRatio */);

    ALOGI("Construct SoftAVCEncoder");
}

void ACodec::initiateShutdown(bool keepComponentAllocated) {
    sp<AMessage> msg = new AMessage(kWhatShutdown, this);
    msg->setInt32("keepComponentAllocated", keepComponentAllocated);
    msg->post();
 if (!keepComponentAllocated) {
 (new AMessage(kWhatReleaseCodecInstance, this))->post(3000000);
 }
}

void ACodec::UninitializedState::onSetup(
 const sp<AMessage> &msg) {
 if (onAllocateComponent(msg)
 && mCodec->mLoadedState->onConfigureComponent(msg)) {
        mCodec->mLoadedState->onStart();
 }
}

OMX_ERRORTYPE SoftGSM::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = 1;
            pcmParams->nSamplingRate = 8000;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

bool ACodec::IdleToExecutingState::onMessageReceived(const sp<AMessage> &msg) {
 switch (msg->what()) {
 case kWhatSetParameters:
 case kWhatShutdown:
 {
            mCodec->deferMessage(msg);
 return true;
 }

 case kWhatResume:
 {
 return true;
 }

 case kWhatFlush:
 {
            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatFlushCompleted);
            notify->post();

 return true;
 }

 case kWhatSignalEndOfInputStream:
 {
            mCodec->onSignalEndOfInputStream();
 return true;
 }

 default:
 return BaseState::onMessageReceived(msg);
 }
}

void ACodec::BufferInfo::checkReadFence(const char *dbg) {
 if (mFenceFd >= 0 && !mIsReadFence) {
        ALOGD("REUSING write fence %d as read fence in %s", mFenceFd, dbg);
 }
}

status_t ACodec::setPriority(int32_t priority) {
 if (priority < 0) {
 return BAD_VALUE;
 }
    OMX_PARAM_U32TYPE config;
 InitOMXParams(&config);
    config.nU32 = (OMX_U32)priority;
 status_t temp = mOMX->setConfig(
            mNode, (OMX_INDEXTYPE)OMX_IndexConfigPriority,
 &config, sizeof(config));
 if (temp != OK) {
        ALOGI("codec does not support config priority (err %d)", temp);
 }
 return OK;
}

bool ACodec::allYourBuffersAreBelongToUs() {
 return allYourBuffersAreBelongToUs(kPortIndexInput)
 && allYourBuffersAreBelongToUs(kPortIndexOutput);
}

status_t ACodec::cancelBufferToNativeWindow(BufferInfo *info) {
    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_US);

    ALOGV("[%s] Calling cancelBuffer on buffer %u",
         mComponentName.c_str(), info->mBufferID);

    info->checkWriteFence("cancelBufferToNativeWindow");
 int err = mNativeWindow->cancelBuffer(
        mNativeWindow.get(), info->mGraphicBuffer.get(), info->mFenceFd);
    info->mFenceFd = -1;

    ALOGW_IF(err != 0, "[%s] can not return buffer %u to native window",
            mComponentName.c_str(), info->mBufferID);
    info->mStatus = BufferInfo::OWNED_BY_NATIVE_WINDOW;

 return err;
}

status_t ACodec::setVideoPortFormatType(
        OMX_U32 portIndex,
        OMX_VIDEO_CODINGTYPE compressionFormat,
        OMX_COLOR_FORMATTYPE colorFormat,
 bool usingNativeBuffers) {
    OMX_VIDEO_PARAM_PORTFORMATTYPE format;
 InitOMXParams(&format);
    format.nPortIndex = portIndex;
    format.nIndex = 0;
 bool found = false;

    OMX_U32 index = 0;
 for (;;) {
        format.nIndex = index;
 status_t err = mOMX->getParameter(
                mNode, OMX_IndexParamVideoPortFormat,
 &format, sizeof(format));

 if (err != OK) {
 return err;
 }

        OMX_U32 flexibleEquivalent;
 if (compressionFormat == OMX_VIDEO_CodingUnused
 && isFlexibleColorFormat(
                        mOMX, mNode, format.eColorFormat, usingNativeBuffers, &flexibleEquivalent)
 && colorFormat == flexibleEquivalent) {
            ALOGI("[%s] using color format %#x in place of %#x",
                    mComponentName.c_str(), format.eColorFormat, colorFormat);
            colorFormat = format.eColorFormat;
 }


 if (!strcmp("OMX.TI.Video.encoder", mComponentName.c_str())) {
 if (portIndex == kPortIndexInput
 && colorFormat == format.eColorFormat) {
                found = true;
 break;
 }
 if (portIndex == kPortIndexOutput
 && compressionFormat == format.eCompressionFormat) {
                found = true;
 break;
 }
 }

 if (format.eCompressionFormat == compressionFormat
 && format.eColorFormat == colorFormat) {
            found = true;
 break;
 }

 ++index;
 }

 if (!found) {
 return UNKNOWN_ERROR;
 }

 status_t err = mOMX->setParameter(
            mNode, OMX_IndexParamVideoPortFormat,
 &format, sizeof(format));

 return err;
}

bool ACodec::BaseState::onOMXFillBufferDone(
        IOMX::buffer_id bufferID,
 size_t rangeOffset, size_t rangeLength,
        OMX_U32 flags,
 int64_t timeUs,
 int fenceFd) {
    ALOGV("[%s] onOMXFillBufferDone %u time %" PRId64 " us, flags = 0x%08x",
         mCodec->mComponentName.c_str(), bufferID, timeUs, flags);

 ssize_t index;
 status_t err= OK;

#if TRACK_BUFFER_TIMING
    index = mCodec->mBufferStats.indexOfKey(timeUs);
 if (index >= 0) {
 ACodec::BufferStats *stats = &mCodec->mBufferStats.editValueAt(index);
        stats->mFillBufferDoneTimeUs = ALooper::GetNowUs();

        ALOGI("frame PTS %lld: %lld",
                timeUs,
                stats->mFillBufferDoneTimeUs - stats->mEmptyBufferTimeUs);

        mCodec->mBufferStats.removeItemsAt(index);
        stats = NULL;
 }
#endif

 BufferInfo *info =
        mCodec->findBufferByID(kPortIndexOutput, bufferID, &index);
 BufferInfo::Status status = BufferInfo::getSafeStatus(info);
 if (status != BufferInfo::OWNED_BY_COMPONENT) {
        ALOGE("Wrong ownership in FBD: %s(%d) buffer #%u", _asString(status), status, bufferID);
        mCodec->dumpBuffers(kPortIndexOutput);
        mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 if (fenceFd >= 0) {
 ::close(fenceFd);
 }
 return true;
 }

    info->mDequeuedAt = ++mCodec->mDequeueCounter;
    info->mStatus = BufferInfo::OWNED_BY_US;

 if (info->mRenderInfo != NULL) {
        mCodec->notifyOfRenderedFrames(true /* dropIncomplete */);
 }

 if (mCodec->mNativeWindow == NULL) {
 (void)mCodec->waitForFence(fenceFd, "onOMXFillBufferDone");
        fenceFd = -1;
 }
    info->setReadFence(fenceFd, "onOMXFillBufferDone");

 PortMode mode = getPortMode(kPortIndexOutput);

 switch (mode) {
 case KEEP_BUFFERS:
 break;

 case RESUBMIT_BUFFERS:
 {
 if (rangeLength == 0 && (!(flags & OMX_BUFFERFLAG_EOS)
 || mCodec->mPortEOS[kPortIndexOutput])) {
                ALOGV("[%s] calling fillBuffer %u",
                     mCodec->mComponentName.c_str(), info->mBufferID);

                err = mCodec->mOMX->fillBuffer(mCodec->mNode, info->mBufferID, info->mFenceFd);
                info->mFenceFd = -1;
 if (err != OK) {
                    mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));
 return true;
 }

                info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
 break;
 }

            sp<AMessage> reply =
 new AMessage(kWhatOutputBufferDrained, mCodec);

 if (!mCodec->mSentFormat && rangeLength > 0) {
                mCodec->sendFormatChange(reply);
 }
 if (mCodec->usingMetadataOnEncoderOutput()) {
 native_handle_t *handle = NULL;
 VideoGrallocMetadata &grallocMeta = *(VideoGrallocMetadata *)info->mData->data();
 VideoNativeMetadata &nativeMeta = *(VideoNativeMetadata *)info->mData->data();
 if (info->mData->size() >= sizeof(grallocMeta)
 && grallocMeta.eType == kMetadataBufferTypeGrallocSource) {
                    handle = (native_handle_t *)(uintptr_t)grallocMeta.pHandle;
 } else if (info->mData->size() >= sizeof(nativeMeta)
 && nativeMeta.eType == kMetadataBufferTypeANWBuffer) {
#ifdef OMX_ANDROID_COMPILE_AS_32BIT_ON_64BIT_PLATFORMS
                    handle = NULL;
#else
                    handle = (native_handle_t *)nativeMeta.pBuffer->handle;
#endif
 }
                info->mData->meta()->setPointer("handle", handle);
                info->mData->meta()->setInt32("rangeOffset", rangeOffset);
                info->mData->meta()->setInt32("rangeLength", rangeLength);
 } else {
                info->mData->setRange(rangeOffset, rangeLength);
 }
#if 0
 if (mCodec->mNativeWindow == NULL) {
 if (IsIDR(info->mData)) {
                    ALOGI("IDR frame");
 }
 }
#endif

 if (mCodec->mSkipCutBuffer != NULL) {
                mCodec->mSkipCutBuffer->submit(info->mData);
 }
            info->mData->meta()->setInt64("timeUs", timeUs);

            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatDrainThisBuffer);
            notify->setInt32("buffer-id", info->mBufferID);
            notify->setBuffer("buffer", info->mData);
            notify->setInt32("flags", flags);

            reply->setInt32("buffer-id", info->mBufferID);

            notify->setMessage("reply", reply);

            notify->post();

            info->mStatus = BufferInfo::OWNED_BY_DOWNSTREAM;

 if (flags & OMX_BUFFERFLAG_EOS) {
                ALOGV("[%s] saw output EOS", mCodec->mComponentName.c_str());

                sp<AMessage> notify = mCodec->mNotify->dup();
                notify->setInt32("what", CodecBase::kWhatEOS);
                notify->setInt32("err", mCodec->mInputEOSResult);
                notify->post();

                mCodec->mPortEOS[kPortIndexOutput] = true;
 }
 break;
 }

 case FREE_BUFFERS:
            err = mCodec->freeBuffer(kPortIndexOutput, index);
 if (err != OK) {
                mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));
 return true;
 }
 break;

 default:
            ALOGE("Invalid port mode: %d", mode);
 return false;
 }

 return true;
}

 BpOMX(const sp<IBinder> &impl)
 : BpInterface<IOMX>(impl) {
 }

OMX_ERRORTYPE SoftVideoDecoderOMXComponent::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamVideoPortFormat:
 {

             OMX_VIDEO_PARAM_PORTFORMATTYPE *formatParams =
                 (OMX_VIDEO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > kMaxPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

 if (formatParams->nIndex != 0) {
 return OMX_ErrorNoMore;
 }

 if (formatParams->nPortIndex == kInputPortIndex) {
                formatParams->eCompressionFormat = mCodingType;
                formatParams->eColorFormat = OMX_COLOR_FormatUnused;
                formatParams->xFramerate = 0;
 } else {
                CHECK_EQ(formatParams->nPortIndex, 1u);

                formatParams->eCompressionFormat = OMX_VIDEO_CodingUnused;
                formatParams->eColorFormat = OMX_COLOR_FormatYUV420Planar;
                formatParams->xFramerate = 0;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoProfileLevelQuerySupported:
 {

             OMX_VIDEO_PARAM_PROFILELEVELTYPE *profileLevel =
                   (OMX_VIDEO_PARAM_PROFILELEVELTYPE *) params;
 
             if (profileLevel->nPortIndex != kInputPortIndex) {
                 ALOGE("Invalid port index: %" PRIu32, profileLevel->nPortIndex);
                 return OMX_ErrorUnsupportedIndex;
 }

 if (profileLevel->nProfileIndex >= mNumProfileLevels) {
 return OMX_ErrorNoMore;
 }

            profileLevel->eProfile = mProfileLevels[profileLevel->nProfileIndex].mProfile;
            profileLevel->eLevel   = mProfileLevels[profileLevel->nProfileIndex].mLevel;
 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

status_t ACodec::setupFlacCodec(
 bool encoder, int32_t numChannels, int32_t sampleRate, int32_t compressionLevel) {

 if (encoder) {
        OMX_AUDIO_PARAM_FLACTYPE def;
 InitOMXParams(&def);
        def.nPortIndex = kPortIndexOutput;

 status_t err = mOMX->getParameter(mNode, OMX_IndexParamAudioFlac, &def, sizeof(def));
 if (err != OK) {
            ALOGE("setupFlacCodec(): Error %d getting OMX_IndexParamAudioFlac parameter", err);
 return err;
 }
        def.nCompressionLevel = compressionLevel;
        err = mOMX->setParameter(mNode, OMX_IndexParamAudioFlac, &def, sizeof(def));
 if (err != OK) {
            ALOGE("setupFlacCodec(): Error %d setting OMX_IndexParamAudioFlac parameter", err);
 return err;
 }
 }

 return setupRawAudioFormat(
            encoder ? kPortIndexInput : kPortIndexOutput,
            sampleRate,
            numChannels);
}

 virtual status_t createPersistentInputSurface(
            sp<IGraphicBufferProducer> *bufferProducer,
            sp<IGraphicBufferConsumer> *bufferConsumer) {
 Parcel data, reply;
 status_t err;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        err = remote()->transact(CREATE_PERSISTENT_INPUT_SURFACE, data, &reply);
 if (err != OK) {
            ALOGW("binder transaction failed: %d", err);
 return err;
 }

        err = reply.readInt32();
 if (err != OK) {
 return err;
 }

 *bufferProducer = IGraphicBufferProducer::asInterface(
                reply.readStrongBinder());
 *bufferConsumer = IGraphicBufferConsumer::asInterface(
                reply.readStrongBinder());

 return err;
 }

SoftAVC::~SoftAVC() {
    releaseEncoder();
 List<BufferInfo *> &outQueue = getPortQueue(1);
 List<BufferInfo *> &inQueue = getPortQueue(0);
    CHECK(outQueue.empty());
    CHECK(inQueue.empty());
}

void ACodec::ExecutingToIdleState::changeStateIfWeOwnAllBuffers() {
 if (mComponentNowIdle && mCodec->allYourBuffersAreBelongToUs()) {
 status_t err = mCodec->mOMX->sendCommand(
                mCodec->mNode, OMX_CommandStateSet, OMX_StateLoaded);
 if (err == OK) {
            err = mCodec->freeBuffersOnPort(kPortIndexInput);
 status_t err2 = mCodec->freeBuffersOnPort(kPortIndexOutput);
 if (err == OK) {
                err = err2;
 }
 }

 if ((mCodec->mFlags & kFlagPushBlankBuffersToNativeWindowOnShutdown)
 && mCodec->mNativeWindow != NULL) {
            pushBlankBuffersToNativeWindow(mCodec->mNativeWindow.get());
 }

 if (err != OK) {
            mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return;
 }

        mCodec->changeState(mCodec->mIdleToLoadedState);
 }
}

bool ACodec::FlushingState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case kWhatShutdown:
 {
            mCodec->deferMessage(msg);
 break;
 }

 case kWhatFlush:
 {
            handled = true;
 break;
 }

 default:
            handled = BaseState::onMessageReceived(msg);
 break;
 }

 return handled;
}

OMX_ERRORTYPE SoftVideoDecoderOMXComponent::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 const int32_t indexFull = index;

 switch (indexFull) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         mComponentRole,
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoPortFormat:
 {

             OMX_VIDEO_PARAM_PORTFORMATTYPE *formatParams =
                 (OMX_VIDEO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > kMaxPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

 if (formatParams->nIndex != 0) {
 return OMX_ErrorNoMore;
 }

 if (formatParams->nPortIndex == kInputPortIndex) {
 if (formatParams->eCompressionFormat != mCodingType
 || formatParams->eColorFormat != OMX_COLOR_FormatUnused) {
 return OMX_ErrorUnsupportedSetting;
 }
 } else {
 if (formatParams->eCompressionFormat != OMX_VIDEO_CodingUnused
 || formatParams->eColorFormat != OMX_COLOR_FormatYUV420Planar) {
 return OMX_ErrorUnsupportedSetting;
 }
 }

 return OMX_ErrorNone;
 }

 case kPrepareForAdaptivePlaybackIndex:

         {
             const PrepareForAdaptivePlaybackParams* adaptivePlaybackParams =
                     (const PrepareForAdaptivePlaybackParams *)params;
             mIsAdaptive = adaptivePlaybackParams->bEnable;
             if (mIsAdaptive) {
                 mAdaptiveMaxWidth = adaptivePlaybackParams->nMaxFrameWidth;
                mAdaptiveMaxHeight = adaptivePlaybackParams->nMaxFrameHeight;
                mWidth = mAdaptiveMaxWidth;
                mHeight = mAdaptiveMaxHeight;
 } else {
                mAdaptiveMaxWidth = 0;
                mAdaptiveMaxHeight = 0;
 }
            updatePortDefinitions(true /* updateCrop */, true /* updateInputSize */);
 return OMX_ErrorNone;
 }

 case OMX_IndexParamPortDefinition:

         {
             OMX_PARAM_PORTDEFINITIONTYPE *newParams =
                 (OMX_PARAM_PORTDEFINITIONTYPE *)params;
             OMX_VIDEO_PORTDEFINITIONTYPE *video_def = &newParams->format.video;
             OMX_PARAM_PORTDEFINITIONTYPE *def = &editPortInfo(newParams->nPortIndex)->mDef;
 
 uint32_t oldWidth = def->format.video.nFrameWidth;
 uint32_t oldHeight = def->format.video.nFrameHeight;
 uint32_t newWidth = video_def->nFrameWidth;
 uint32_t newHeight = video_def->nFrameHeight;
 if (newWidth != oldWidth || newHeight != oldHeight) {
 bool outputPort = (newParams->nPortIndex == kOutputPortIndex);
 if (outputPort) {
                    mWidth = newWidth;
                    mHeight = newHeight;

                    updatePortDefinitions(true /* updateCrop */, true /* updateInputSize */);
                    newParams->nBufferSize = def->nBufferSize;
 } else {
                    def->format.video.nFrameWidth = newWidth;
                    def->format.video.nFrameHeight = newHeight;
 }
 }
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftFlacEncoder::initCheck() const {
 if (mSignalledError) {
 if (mFlacStreamEncoder == NULL) {
            ALOGE("initCheck() failed due to NULL encoder");
 } else if (mInputBufferPcm32 == NULL) {
            ALOGE("initCheck() failed due to error allocating internal input buffer");
 }
 return OMX_ErrorUndefined;
 } else {
 return SimpleSoftOMXComponent::initCheck();
 }
}

status_t ACodec::setSurface(const sp<Surface> &surface) {
    sp<AMessage> msg = new AMessage(kWhatSetSurface, this);
    msg->setObject("surface", surface);

    sp<AMessage> response;
 status_t err = msg->postAndAwaitResponse(&response);

 if (err == OK) {
 (void)response->findInt32("err", &err);
 }
 return err;
}

void ACodec::deferMessage(const sp<AMessage> &msg) {
    mDeferredQueue.push_back(msg);
}

status_t ACodec::LoadedToIdleState::allocateBuffers() {
 status_t err = mCodec->allocateBuffersOnPort(kPortIndexInput);

 if (err != OK) {
 return err;
 }

 return mCodec->allocateBuffersOnPort(kPortIndexOutput);
}

 virtual status_t createInputSurface(
            node_id node, OMX_U32 port_index,
            sp<IGraphicBufferProducer> *bufferProducer, MetadataBufferType *type) {
 Parcel data, reply;
 status_t err;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        err = remote()->transact(CREATE_INPUT_SURFACE, data, &reply);
 if (err != OK) {
            ALOGW("binder transaction failed: %d", err);
 return err;
 }

 int negotiatedType = reply.readInt32();
 if (type != NULL) {
 *type = (MetadataBufferType)negotiatedType;
 }

        err = reply.readInt32();
 if (err != OK) {
 return err;
 }

 *bufferProducer = IGraphicBufferProducer::asInterface(
                reply.readStrongBinder());

 return err;
 }

OMX_ERRORTYPE SoftMP3::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSamplingRate;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioMp3:
 {

             OMX_AUDIO_PARAM_MP3TYPE *mp3Params =
                 (OMX_AUDIO_PARAM_MP3TYPE *)params;
 
             if (mp3Params->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

            mp3Params->nChannels = mNumChannels;
            mp3Params->nBitRate = 0 /* unknown */;
            mp3Params->nSampleRate = mSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

 virtual status_t configureVideoTunnelMode(
            node_id node, OMX_U32 portIndex, OMX_BOOL tunneled,
            OMX_U32 audioHwSync, native_handle_t **sidebandHandle ) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(portIndex);
        data.writeInt32((int32_t)tunneled);
        data.writeInt32(audioHwSync);
        remote()->transact(CONFIGURE_VIDEO_TUNNEL_MODE, data, &reply);

 status_t err = reply.readInt32();
 if (err == OK && sidebandHandle) {
 *sidebandHandle = (native_handle_t *)reply.readNativeHandle();
 }
 return err;
 }

void ACodec::initiateCreateInputSurface() {
 (new AMessage(kWhatCreateInputSurface, this))->post();
}

 virtual status_t prepareForAdaptivePlayback(
            node_id node, OMX_U32 port_index, OMX_BOOL enable,
            OMX_U32 max_width, OMX_U32 max_height) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeInt32((int32_t)enable);
        data.writeInt32(max_width);
        data.writeInt32(max_height);
        remote()->transact(PREPARE_FOR_ADAPTIVE_PLAYBACK, data, &reply);

 status_t err = reply.readInt32();
 return err;
 }

 virtual status_t setConfig(
            node_id node, OMX_INDEXTYPE index,
 const void *params, size_t size) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(index);
        data.writeInt64(size);
        data.write(params, size);
        remote()->transact(SET_CONFIG, data, &reply);

 return reply.readInt32();
 }

void ACodec::signalSetParameters(const sp<AMessage> &params) {
    sp<AMessage> msg = new AMessage(kWhatSetParameters, this);
    msg->setMessage("params", params);
    msg->post();
}

ACodec::~ACodec() {
}

void SoftRaw::initPorts() {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);

    def.nPortIndex = 0;
    def.eDir = OMX_DirInput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 32 * 1024;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 1;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);

    def.nPortIndex = 1;
    def.eDir = OMX_DirOutput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 32 * 1024;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 2;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);
}

OMX_ERRORTYPE SoftAMRNBEncoder::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPortFormat:
 {

             OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

            formatParams->eEncoding =
 (formatParams->nPortIndex == 0)
 ? OMX_AUDIO_CodingPCM : OMX_AUDIO_CodingAMR;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAmr:
 {

             OMX_AUDIO_PARAM_AMRTYPE *amrParams =
                 (OMX_AUDIO_PARAM_AMRTYPE *)params;
 
             if (amrParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            amrParams->nChannels = 1;
            amrParams->nBitRate = mBitRate;
            amrParams->eAMRBandMode = (OMX_AUDIO_AMRBANDMODETYPE)(mMode + 1);
            amrParams->eAMRDTXMode = OMX_AUDIO_AMRDTXModeOff;
            amrParams->eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelCF;

            pcmParams->nChannels = 1;
            pcmParams->nSamplingRate = kSampleRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftAVC::setDeblockParams() {
    IV_STATUS_T status;
 ive_ctl_set_deblock_params_ip_t s_deblock_params_ip;
 ive_ctl_set_deblock_params_op_t s_deblock_params_op;

    s_deblock_params_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_deblock_params_ip.e_sub_cmd = IVE_CMD_CTL_SET_DEBLOCK_PARAMS;

    s_deblock_params_ip.u4_disable_deblock_level = mDisableDeblkLevel;

    s_deblock_params_ip.u4_timestamp_high = -1;
    s_deblock_params_ip.u4_timestamp_low = -1;

    s_deblock_params_ip.u4_size = sizeof(ive_ctl_set_deblock_params_ip_t);
    s_deblock_params_op.u4_size = sizeof(ive_ctl_set_deblock_params_op_t);

    status = ive_api_function(mCodecCtx, &s_deblock_params_ip, &s_deblock_params_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to enable/disable deblock params = 0x%x\n",
                s_deblock_params_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

SoftAMRNBEncoder::~SoftAMRNBEncoder() {
 if (mEncState != NULL) {
 AMREncodeExit(&mEncState, &mSidState);
        mEncState = mSidState = NULL;
 }
}

 virtual void onMessages(const std::list<omx_message> &messages) {
 Parcel data, reply;
        std::list<omx_message>::const_iterator it = messages.cbegin();
 bool first = true;
 while (it != messages.cend()) {
 const omx_message &msg = *it++;
 if (first) {
                data.writeInterfaceToken(IOMXObserver::getInterfaceDescriptor());
                data.writeInt32(msg.node);
                first = false;
 }
            data.writeInt32(msg.fenceFd >= 0);
 if (msg.fenceFd >= 0) {
                data.writeFileDescriptor(msg.fenceFd, true /* takeOwnership */);
 }
            data.writeInt32(msg.type);
            data.write(&msg.u, sizeof(msg.u));
            ALOGV("onMessage writing message %d, size %zu", msg.type, sizeof(msg));
 }
 if (!first) {
            data.writeInt32(-1); // mark end
            remote()->transact(OBSERVER_ON_MSG, data, &reply, IBinder::FLAG_ONEWAY);
 }
 }

void SoftAVC::initEncParams() {
    mCodecCtx = NULL;
    mMemRecords = NULL;
    mNumMemRecords = DEFAULT_MEM_REC_CNT;
    mHeaderGenerated = 0;
    mNumCores = GetCPUCoreCount();
    mArch = DEFAULT_ARCH;
    mSliceMode = DEFAULT_SLICE_MODE;
    mSliceParam = DEFAULT_SLICE_PARAM;
    mHalfPelEnable = DEFAULT_HPEL;
    mIInterval = DEFAULT_I_INTERVAL;
    mIDRInterval = DEFAULT_IDR_INTERVAL;
    mDisableDeblkLevel = DEFAULT_DISABLE_DEBLK_LEVEL;
    mEnableFastSad = DEFAULT_ENABLE_FAST_SAD;
    mEnableAltRef = DEFAULT_ENABLE_ALT_REF;
    mEncSpeed = DEFAULT_ENC_SPEED;
    mIntra4x4 = DEFAULT_INTRA4x4;
    mAIRMode = DEFAULT_AIR;
    mAIRRefreshPeriod = DEFAULT_AIR_REFRESH_PERIOD;
    mPSNREnable = DEFAULT_PSNR_ENABLE;
    mReconEnable = DEFAULT_RECON_ENABLE;
    mEntropyMode = DEFAULT_ENTROPY_MODE;
    mBframes = DEFAULT_B_FRAMES;

    gettimeofday(&mTimeStart, NULL);
    gettimeofday(&mTimeEnd, NULL);

}

void ACodec::setNotificationMessage(const sp<AMessage> &msg) {
    mNotify = msg;
}

ACodec::IdleToExecutingState::IdleToExecutingState(ACodec *codec)
 : BaseState(codec) {
}

OMX_ERRORTYPE SoftGSM::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0 && pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (pcmParams->nChannels != 1) {
 return OMX_ErrorUndefined;
 }

 if (pcmParams->nSamplingRate != 8000) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.gsm",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

void ACodec::BaseState::onInputBufferFilled(const sp<AMessage> &msg) {
    IOMX::buffer_id bufferID;
    CHECK(msg->findInt32("buffer-id", (int32_t*)&bufferID));
    sp<ABuffer> buffer;
 int32_t err = OK;
 bool eos = false;
 PortMode mode = getPortMode(kPortIndexInput);

 if (!msg->findBuffer("buffer", &buffer)) {
 /* these are unfilled buffers returned by client */
        CHECK(msg->findInt32("err", &err));

 if (err == OK) {
 /* buffers with no errors are returned on MediaCodec.flush */
            mode = KEEP_BUFFERS;
 } else {
            ALOGV("[%s] saw error %d instead of an input buffer",
                 mCodec->mComponentName.c_str(), err);
            eos = true;
 }

        buffer.clear();
 }

 int32_t tmp;
 if (buffer != NULL && buffer->meta()->findInt32("eos", &tmp) && tmp) {
        eos = true;
        err = ERROR_END_OF_STREAM;
 }

 BufferInfo *info = mCodec->findBufferByID(kPortIndexInput, bufferID);
 BufferInfo::Status status = BufferInfo::getSafeStatus(info);
 if (status != BufferInfo::OWNED_BY_UPSTREAM) {
        ALOGE("Wrong ownership in IBF: %s(%d) buffer #%u", _asString(status), status, bufferID);
        mCodec->dumpBuffers(kPortIndexInput);
        mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return;
 }

    info->mStatus = BufferInfo::OWNED_BY_US;

 switch (mode) {
 case KEEP_BUFFERS:
 {
 if (eos) {
 if (!mCodec->mPortEOS[kPortIndexInput]) {
                    mCodec->mPortEOS[kPortIndexInput] = true;
                    mCodec->mInputEOSResult = err;
 }
 }
 break;
 }

 case RESUBMIT_BUFFERS:
 {
 if (buffer != NULL && !mCodec->mPortEOS[kPortIndexInput]) {
 if (buffer->size() == 0 && !eos) {
                    postFillThisBuffer(info);
 break;
 }

 int64_t timeUs;
                CHECK(buffer->meta()->findInt64("timeUs", &timeUs));

                OMX_U32 flags = OMX_BUFFERFLAG_ENDOFFRAME;

 int32_t isCSD;
 if (buffer->meta()->findInt32("csd", &isCSD) && isCSD != 0) {
                    flags |= OMX_BUFFERFLAG_CODECCONFIG;
 }

 if (eos) {
                    flags |= OMX_BUFFERFLAG_EOS;
 }

 if (buffer != info->mData) {
                    ALOGV("[%s] Needs to copy input data for buffer %u. (%p != %p)",
                         mCodec->mComponentName.c_str(),
                         bufferID,
                         buffer.get(), info->mData.get());

 if (buffer->size() > info->mData->capacity()) {
                        ALOGE("data size (%zu) is greated than buffer capacity (%zu)",
                                buffer->size(), // this is the data received
                                info->mData->capacity()); // this is out buffer size
                        mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return;
 }
                    memcpy(info->mData->data(), buffer->data(), buffer->size());
 }

 if (flags & OMX_BUFFERFLAG_CODECCONFIG) {
                    ALOGV("[%s] calling emptyBuffer %u w/ codec specific data",
                         mCodec->mComponentName.c_str(), bufferID);
 } else if (flags & OMX_BUFFERFLAG_EOS) {
                    ALOGV("[%s] calling emptyBuffer %u w/ EOS",
                         mCodec->mComponentName.c_str(), bufferID);
 } else {
#if TRACK_BUFFER_TIMING
                    ALOGI("[%s] calling emptyBuffer %u w/ time %lld us",
                         mCodec->mComponentName.c_str(), bufferID, (long long)timeUs);
#else
                    ALOGV("[%s] calling emptyBuffer %u w/ time %lld us",
                         mCodec->mComponentName.c_str(), bufferID, (long long)timeUs);
#endif
 }

#if TRACK_BUFFER_TIMING
 ACodec::BufferStats stats;
                stats.mEmptyBufferTimeUs = ALooper::GetNowUs();
                stats.mFillBufferDoneTimeUs = -1ll;
                mCodec->mBufferStats.add(timeUs, stats);
#endif

 if (mCodec->storingMetadataInDecodedBuffers()) {
 PortMode outputMode = getPortMode(kPortIndexOutput);

                    ALOGV("MetadataBuffersToSubmit=%u portMode=%s",
                            mCodec->mMetadataBuffersToSubmit,
 (outputMode == FREE_BUFFERS ? "FREE" :
                             outputMode == KEEP_BUFFERS ? "KEEP" : "RESUBMIT"));
 if (outputMode == RESUBMIT_BUFFERS) {
                        mCodec->submitOutputMetadataBuffer();
 }
 }
                info->checkReadFence("onInputBufferFilled");
 status_t err2 = mCodec->mOMX->emptyBuffer(
                    mCodec->mNode,
                    bufferID,
 0,
                    buffer->size(),
                    flags,
                    timeUs,
                    info->mFenceFd);
                info->mFenceFd = -1;
 if (err2 != OK) {
                    mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err2));
 return;
 }
                info->mStatus = BufferInfo::OWNED_BY_COMPONENT;

 if (!eos && err == OK) {
                    getMoreInputDataIfPossible();
 } else {
                    ALOGV("[%s] Signalled EOS (%d) on the input port",
                         mCodec->mComponentName.c_str(), err);

                    mCodec->mPortEOS[kPortIndexInput] = true;
                    mCodec->mInputEOSResult = err;
 }
 } else if (!mCodec->mPortEOS[kPortIndexInput]) {
 if (err != OK && err != ERROR_END_OF_STREAM) {
                    ALOGV("[%s] Signalling EOS on the input port due to error %d",
                         mCodec->mComponentName.c_str(), err);
 } else {
                    ALOGV("[%s] Signalling EOS on the input port",
                         mCodec->mComponentName.c_str());
 }

                ALOGV("[%s] calling emptyBuffer %u signalling EOS",
                     mCodec->mComponentName.c_str(), bufferID);

                info->checkReadFence("onInputBufferFilled");
 status_t err2 = mCodec->mOMX->emptyBuffer(
                        mCodec->mNode,
                        bufferID,
 0,
 0,
                        OMX_BUFFERFLAG_EOS,
 0,
                        info->mFenceFd);
                info->mFenceFd = -1;
 if (err2 != OK) {
                    mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err2));
 return;
 }
                info->mStatus = BufferInfo::OWNED_BY_COMPONENT;

                mCodec->mPortEOS[kPortIndexInput] = true;
                mCodec->mInputEOSResult = err;
 }
 break;
 }

 case FREE_BUFFERS:
 break;

 default:
            ALOGE("invalid port mode: %d", mode);
 break;
 }
}

OMX_ERRORTYPE SoftAVCEncoder::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamVideoBitrate:
 {

             OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *) params;
 
             if (bitRate->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            bitRate->eControlRate = OMX_Video_ControlRateVariable;
            bitRate->nTargetBitrate = mBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoAvc:
 {

             OMX_VIDEO_PARAM_AVCTYPE *avcParams =
                 (OMX_VIDEO_PARAM_AVCTYPE *)params;
 
             if (avcParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            avcParams->eProfile = OMX_VIDEO_AVCProfileBaseline;
            OMX_U32 omxLevel = AVC_LEVEL2;
 if (OMX_ErrorNone !=
 ConvertAvcSpecLevelToOmxAvcLevel(mAVCEncLevel, &omxLevel)) {
 return OMX_ErrorUndefined;
 }

            avcParams->eLevel = (OMX_VIDEO_AVCLEVELTYPE) omxLevel;
            avcParams->nRefFrames = 1;
            avcParams->nBFrames = 0;
            avcParams->bUseHadamard = OMX_TRUE;
            avcParams->nAllowedPictureTypes =
 (OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP);
            avcParams->nRefIdx10ActiveMinus1 = 0;
            avcParams->nRefIdx11ActiveMinus1 = 0;
            avcParams->bWeightedPPrediction = OMX_FALSE;
            avcParams->bEntropyCodingCABAC = OMX_FALSE;
            avcParams->bconstIpred = OMX_FALSE;
            avcParams->bDirect8x8Inference = OMX_FALSE;
            avcParams->bDirectSpatialTemporal = OMX_FALSE;
            avcParams->nCabacInitIdc = 0;
 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalGetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftAVCEncoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 int32_t indexFull = index;

 switch (indexFull) {
 case OMX_IndexParamVideoBitrate:
 {

             OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *) params;
 
             if (bitRate->nPortIndex != 1 ||
                 bitRate->eControlRate != OMX_Video_ControlRateVariable) {
                 return OMX_ErrorUndefined;
 }

            mBitrate = bitRate->nTargetBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoAvc:
 {

             OMX_VIDEO_PARAM_AVCTYPE *avcType =
                 (OMX_VIDEO_PARAM_AVCTYPE *)params;
 
             if (avcType->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (avcType->eProfile != OMX_VIDEO_AVCProfileBaseline ||
                avcType->nRefFrames != 1 ||
                avcType->nBFrames != 0 ||
                avcType->bUseHadamard != OMX_TRUE ||
 (avcType->nAllowedPictureTypes & OMX_VIDEO_PictureTypeB) != 0 ||
                avcType->nRefIdx10ActiveMinus1 != 0 ||
                avcType->nRefIdx11ActiveMinus1 != 0 ||
                avcType->bWeightedPPrediction != OMX_FALSE ||
                avcType->bEntropyCodingCABAC != OMX_FALSE ||
                avcType->bconstIpred != OMX_FALSE ||
                avcType->bDirect8x8Inference != OMX_FALSE ||
                avcType->bDirectSpatialTemporal != OMX_FALSE ||
                avcType->nCabacInitIdc != 0) {
 return OMX_ErrorUndefined;
 }

 if (OK != ConvertOmxAvcLevelToAvcSpecLevel(avcType->eLevel, &mAVCEncLevel)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalSetParameter(index, params);
 }
}

 virtual status_t useBuffer(
            node_id node, OMX_U32 port_index, const sp<IMemory> &params,
            buffer_id *buffer, OMX_U32 allottedSize) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeStrongBinder(IInterface::asBinder(params));
        data.writeInt32(allottedSize);
        remote()->transact(USE_BUFFER, data, &reply);

 status_t err = reply.readInt32();
 if (err != OK) {
 *buffer = 0;

 return err;
 }

 *buffer = (buffer_id)reply.readInt32();

 return err;
 }

void ACodec::signalError(OMX_ERRORTYPE error, status_t internalError) {
    sp<AMessage> notify = mNotify->dup();
    notify->setInt32("what", CodecBase::kWhatError);
    ALOGE("signalError(omxError %#x, internalError %d)", error, internalError);

 if (internalError == UNKNOWN_ERROR) { // find better error code
 const status_t omxStatus = statusFromOMXError(error);
 if (omxStatus != 0) {
            internalError = omxStatus;
 } else {
            ALOGW("Invalid OMX error %#x", error);
 }
 }

    mFatalError = true;

    notify->setInt32("err", internalError);
    notify->setInt32("actionCode", ACTION_CODE_FATAL); // could translate from OMX error.
    notify->post();
}

bool ACodec::ExecutingState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
 switch (event) {
 case OMX_EventPortSettingsChanged:
 {
            CHECK_EQ(data1, (OMX_U32)kPortIndexOutput);

 if (data2 == 0 || data2 == OMX_IndexParamPortDefinition) {
                mCodec->mMetadataBuffersToSubmit = 0;
                CHECK_EQ(mCodec->mOMX->sendCommand(
                            mCodec->mNode,
                            OMX_CommandPortDisable, kPortIndexOutput),
 (status_t)OK);

                mCodec->freeOutputBuffersNotOwnedByComponent();

                mCodec->changeState(mCodec->mOutputPortSettingsChangedState);
 } else if (data2 == OMX_IndexConfigCommonOutputCrop) {
                mCodec->mSentFormat = false;

 if (mCodec->mTunneled) {
                    sp<AMessage> dummy = new AMessage(kWhatOutputBufferDrained, mCodec);
                    mCodec->sendFormatChange(dummy);
 }
 } else {
                ALOGV("[%s] OMX_EventPortSettingsChanged 0x%08x",
                     mCodec->mComponentName.c_str(), data2);
 }

 return true;
 }

 case OMX_EventBufferFlag:
 {
 return true;
 }

 default:
 return BaseState::onOMXEvent(event, data1, data2);
 }
}

OMX_ERRORTYPE SoftOpus::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamAudioAndroidOpus:
 {

             OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *opusParams =
                 (OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *)params;
 
             if (opusParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            opusParams->nAudioBandWidth = 0;
            opusParams->nSampleRate = kRate;
            opusParams->nBitRate = 0;

 if (!isConfigured()) {
                opusParams->nChannels = 1;
 } else {
                opusParams->nChannels = mHeader->channels;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;
            pcmParams->nSamplingRate = kRate;

 if (!isConfigured()) {
                pcmParams->nChannels = 1;
 } else {
                pcmParams->nChannels = mHeader->channels;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

void SoftFlacEncoder::onQueueFilled(OMX_U32 portIndex) {
    UNUSED_UNLESS_VERBOSE(portIndex);
    ALOGV("SoftFlacEncoder::onQueueFilled(portIndex=%d)", portIndex);

 if (mSignalledError) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 while (!inQueue.empty() && !outQueue.empty()) {
 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
            inQueue.erase(inQueue.begin());
            inInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inHeader);

            outHeader->nFilledLen = 0;
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;

            outQueue.erase(outQueue.begin());
            outInfo->mOwnedByUs = false;
            notifyFillBufferDone(outHeader);

 return;
 }

 if (inHeader->nFilledLen > kMaxInputBufferSize) {
            ALOGE("input buffer too large (%d).", inHeader->nFilledLen);
            mSignalledError = true;
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }

        assert(mNumChannels != 0);
        mEncoderWriteData = true;
        mEncoderReturnedEncodedData = false;
        mEncoderReturnedNbBytes = 0;
        mCurrentInputTimeStamp = inHeader->nTimeStamp;

 const unsigned nbInputFrames = inHeader->nFilledLen / (2 * mNumChannels);
 const unsigned nbInputSamples = inHeader->nFilledLen / 2;
 const OMX_S16 * const pcm16 = reinterpret_cast<OMX_S16 *>(inHeader->pBuffer);

        CHECK_LE(nbInputSamples, 2 * kMaxNumSamplesPerFrame);
 for (unsigned i=0 ; i < nbInputSamples ; i++) {
            mInputBufferPcm32[i] = (FLAC__int32) pcm16[i];
 }
        ALOGV(" about to encode %u samples per channel", nbInputFrames);
        FLAC__bool ok = FLAC__stream_encoder_process_interleaved(
                        mFlacStreamEncoder,
                        mInputBufferPcm32,
                        nbInputFrames /*samples per channel*/ );

 if (ok) {
 if (mEncoderReturnedEncodedData && (mEncoderReturnedNbBytes != 0)) {
                ALOGV(" dequeueing buffer on output port after writing data");
                outInfo->mOwnedByUs = false;
                outQueue.erase(outQueue.begin());
                outInfo = NULL;
                notifyFillBufferDone(outHeader);
                outHeader = NULL;
                mEncoderReturnedEncodedData = false;
 } else {
                ALOGV(" encoder process_interleaved returned without data to write");
 }
 } else {
            ALOGE(" error encountered during encoding");
            mSignalledError = true;
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }

        inInfo->mOwnedByUs = false;
        inQueue.erase(inQueue.begin());
        inInfo = NULL;
        notifyEmptyBufferDone(inHeader);
        inHeader = NULL;
 }
}

bool ACodec::IdleToLoadedState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case kWhatShutdown:
 {

            handled = true;
 break;
 }

 case kWhatFlush:
 {
            ALOGE("Got flush request in IdleToLoadedState");
 break;
 }

 default:
            handled = BaseState::onMessageReceived(msg);
 break;
 }

 return handled;
}

OMX_ERRORTYPE SoftVorbis::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioVorbis:
 {

             OMX_AUDIO_PARAM_VORBISTYPE *vorbisParams =
                 (OMX_AUDIO_PARAM_VORBISTYPE *)params;
 
             if (vorbisParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            vorbisParams->nBitRate = 0;
            vorbisParams->nMinBitRate = 0;
            vorbisParams->nMaxBitRate = 0;
            vorbisParams->nAudioBandWidth = 0;
            vorbisParams->nQuality = 3;
            vorbisParams->bManaged = OMX_FALSE;
            vorbisParams->bDownmix = OMX_FALSE;

 if (!isConfigured()) {
                vorbisParams->nChannels = 1;
                vorbisParams->nSampleRate = 44100;
 } else {
                vorbisParams->nChannels = mVi->channels;
                vorbisParams->nSampleRate = mVi->rate;
                vorbisParams->nBitRate = mVi->bitrate_nominal;
                vorbisParams->nMinBitRate = mVi->bitrate_lower;
                vorbisParams->nMaxBitRate = mVi->bitrate_upper;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

 if (!isConfigured()) {
                pcmParams->nChannels = 1;
                pcmParams->nSamplingRate = 44100;
 } else {
                pcmParams->nChannels = mVi->channels;
                pcmParams->nSamplingRate = mVi->rate;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

void SoftRaw::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 while (!inQueue.empty() && !outQueue.empty()) {
 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

        CHECK_GE(outHeader->nAllocLen, inHeader->nFilledLen);
        memcpy(outHeader->pBuffer,
               inHeader->pBuffer + inHeader->nOffset,
               inHeader->nFilledLen);

        outHeader->nFlags = inHeader->nFlags;
        outHeader->nOffset = 0;
        outHeader->nFilledLen = inHeader->nFilledLen;
        outHeader->nTimeStamp = inHeader->nTimeStamp;

 bool sawEOS = (inHeader->nFlags & OMX_BUFFERFLAG_EOS) != 0;

        inQueue.erase(inQueue.begin());
        inInfo->mOwnedByUs = false;
        notifyEmptyBufferDone(inHeader);

        outQueue.erase(outQueue.begin());
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

 if (sawEOS) {
 break;
 }
 }
}

void SoftAVCEncoder::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError || mSawInputEOS) {
 return;
 }

 if (!mStarted) {
 if (OMX_ErrorNone != initEncoder()) {
 return;
 }
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 while (!mSawInputEOS && !inQueue.empty() && !outQueue.empty()) {
 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;
 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

        outHeader->nTimeStamp = 0;
        outHeader->nFlags = 0;
        outHeader->nOffset = 0;
        outHeader->nFilledLen = 0;
        outHeader->nOffset = 0;

 uint8_t *outPtr = (uint8_t *) outHeader->pBuffer;
 uint32_t dataLength = outHeader->nAllocLen;

 if (!mSpsPpsHeaderReceived && mNumInputFrames < 0) {
            outPtr += 4;
            dataLength -= 4;
 }

 int32_t type;
 AVCEnc_Status encoderStatus = AVCENC_SUCCESS;

 while (!mSpsPpsHeaderReceived && mNumInputFrames <= 0) {
            encoderStatus = PVAVCEncodeNAL(mHandle, outPtr, &dataLength, &type);
 if (encoderStatus == AVCENC_WRONG_STATE) {
                mSpsPpsHeaderReceived = true;
                CHECK_EQ(0, mNumInputFrames); // 1st video frame is 0
                outHeader->nFlags = OMX_BUFFERFLAG_CODECCONFIG;
                outQueue.erase(outQueue.begin());
                outInfo->mOwnedByUs = false;
                notifyFillBufferDone(outHeader);
 return;
 } else {
 switch (type) {
 case AVC_NALTYPE_SPS:
 ++mNumInputFrames;
                        memcpy((uint8_t *)outHeader->pBuffer, "\x00\x00\x00\x01", 4);
                        outHeader->nFilledLen = 4 + dataLength;
                        outPtr += (dataLength + 4); // 4 bytes for next start code
                        dataLength = outHeader->nAllocLen - outHeader->nFilledLen;
 break;
 default:
                        CHECK_EQ(AVC_NALTYPE_PPS, type);
 ++mNumInputFrames;
                        memcpy((uint8_t *) outHeader->pBuffer + outHeader->nFilledLen,
 "\x00\x00\x00\x01", 4);
                        outHeader->nFilledLen += (dataLength + 4);
                        outPtr += (dataLength + 4);
 break;
 }
 }
 }

 if (mReadyForNextFrame) {
 InputBufferInfo info;
            info.mTimeUs = inHeader->nTimeStamp;
            info.mFlags = inHeader->nFlags;
            mInputBufferInfoVec.push(info);
            mPrevTimestampUs = inHeader->nTimeStamp;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                mSawInputEOS = true;
 }

 if (inHeader->nFilledLen > 0) {
 AVCFrameIO videoInput;
                memset(&videoInput, 0, sizeof(videoInput));
                videoInput.height = align(mHeight, 16);
                videoInput.pitch = align(mWidth, 16);
                videoInput.coding_timestamp = (inHeader->nTimeStamp + 500) / 1000; // in ms
 const uint8_t *inputData = NULL;
 if (mInputDataIsMeta) {
                    inputData =
                        extractGraphicBuffer(
                                mInputFrameData, (mWidth * mHeight * 3) >> 1,
                                inHeader->pBuffer + inHeader->nOffset, inHeader->nFilledLen,
                                mWidth, mHeight);
 if (inputData == NULL) {
                        ALOGE("Unable to extract gralloc buffer in metadata mode");
                        mSignalledError = true;
                        notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return;
 }
 } else {
                    inputData = (const uint8_t *)inHeader->pBuffer + inHeader->nOffset;
 if (mColorFormat != OMX_COLOR_FormatYUV420Planar) {
 ConvertYUV420SemiPlanarToYUV420Planar(
                            inputData, mInputFrameData, mWidth, mHeight);
                        inputData = mInputFrameData;
 }
 }

                CHECK(inputData != NULL);
                videoInput.YCbCr[0] = (uint8_t *)inputData;
                videoInput.YCbCr[1] = videoInput.YCbCr[0] + videoInput.height * videoInput.pitch;
                videoInput.YCbCr[2] = videoInput.YCbCr[1] +
 ((videoInput.height * videoInput.pitch) >> 2);
                videoInput.disp_order = mNumInputFrames;

                encoderStatus = PVAVCEncSetInput(mHandle, &videoInput);
 if (encoderStatus == AVCENC_SUCCESS || encoderStatus == AVCENC_NEW_IDR) {
                    mReadyForNextFrame = false;
 ++mNumInputFrames;
 if (encoderStatus == AVCENC_NEW_IDR) {
                        mIsIDRFrame = 1;
 }
 } else {
 if (encoderStatus < AVCENC_SUCCESS) {
                        ALOGE("encoderStatus = %d at line %d", encoderStatus, __LINE__);
                        mSignalledError = true;
                        notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return;
 } else {
                        ALOGV("encoderStatus = %d at line %d", encoderStatus, __LINE__);
                        inQueue.erase(inQueue.begin());
                        inInfo->mOwnedByUs = false;
                        notifyEmptyBufferDone(inHeader);
 return;
 }
 }
 }
 }

        CHECK(encoderStatus == AVCENC_SUCCESS || encoderStatus == AVCENC_NEW_IDR);
        dataLength = outHeader->nAllocLen; // Reset the output buffer length
 if (inHeader->nFilledLen > 0) {
 if (outHeader->nAllocLen >= 4) {
                memcpy(outPtr, "\x00\x00\x00\x01", 4);
                outPtr += 4;
                dataLength -= 4;
 }
            encoderStatus = PVAVCEncodeNAL(mHandle, outPtr, &dataLength, &type);
            dataLength = outPtr + dataLength - outHeader->pBuffer;
 if (encoderStatus == AVCENC_SUCCESS) {
                CHECK(NULL == PVAVCEncGetOverrunBuffer(mHandle));
 } else if (encoderStatus == AVCENC_PICTURE_READY) {
                CHECK(NULL == PVAVCEncGetOverrunBuffer(mHandle));
 if (mIsIDRFrame) {
                    outHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;
                    mIsIDRFrame = false;
 }
                mReadyForNextFrame = true;
 AVCFrameIO recon;
 if (PVAVCEncGetRecon(mHandle, &recon) == AVCENC_SUCCESS) {
 PVAVCEncReleaseRecon(mHandle, &recon);
 }
 } else {
                dataLength = 0;
                mReadyForNextFrame = true;
 }

 if (encoderStatus < AVCENC_SUCCESS) {
                ALOGE("encoderStatus = %d at line %d", encoderStatus, __LINE__);
                mSignalledError = true;
                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return;
 }
 } else {
            dataLength = 0;
 }

        inQueue.erase(inQueue.begin());
        inInfo->mOwnedByUs = false;
        notifyEmptyBufferDone(inHeader);

        outQueue.erase(outQueue.begin());
        CHECK(!mInputBufferInfoVec.empty());
 InputBufferInfo *inputBufInfo = mInputBufferInfoVec.begin();
        outHeader->nTimeStamp = inputBufInfo->mTimeUs;
        outHeader->nFlags |= (inputBufInfo->mFlags | OMX_BUFFERFLAG_ENDOFFRAME);
 if (mSawInputEOS) {
            outHeader->nFlags |= OMX_BUFFERFLAG_EOS;
 }
        outHeader->nFilledLen = dataLength;
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);
        mInputBufferInfoVec.erase(mInputBufferInfoVec.begin());
 }
}

status_t ACodec::configureBitrate(
 int32_t bitrate, OMX_VIDEO_CONTROLRATETYPE bitrateMode) {
    OMX_VIDEO_PARAM_BITRATETYPE bitrateType;
 InitOMXParams(&bitrateType);
    bitrateType.nPortIndex = kPortIndexOutput;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamVideoBitrate,
 &bitrateType, sizeof(bitrateType));

 if (err != OK) {
 return err;
 }

    bitrateType.eControlRate = bitrateMode;
    bitrateType.nTargetBitrate = bitrate;

 return mOMX->setParameter(
            mNode, OMX_IndexParamVideoBitrate,
 &bitrateType, sizeof(bitrateType));
}

bool ACodec::describeColorFormat(
 const sp<IOMX> &omx, IOMX::node_id node,
 DescribeColorFormatParams &describeParams)
{
    OMX_INDEXTYPE describeColorFormatIndex;
 if (omx->getExtensionIndex(
            node, "OMX.google.android.index.describeColorFormat",
 &describeColorFormatIndex) != OK ||
        omx->getParameter(
            node, describeColorFormatIndex,
 &describeParams, sizeof(describeParams)) != OK) {
 return describeDefaultColorFormat(describeParams);
 }
 return describeParams.sMediaImage.mType !=
 MediaImage::MEDIA_IMAGE_TYPE_UNKNOWN;
}

void ACodec::BufferInfo::setWriteFence(int fenceFd, const char *dbg) {
 if (mFenceFd >= 0) {
        ALOGW("OVERWRITE OF %s fence %d by write fence %d in %s",
                mIsReadFence ? "read" : "write", mFenceFd, fenceFd, dbg);
 }
    mFenceFd = fenceFd;
    mIsReadFence = false;
}

OMX_ERRORTYPE SoftAVC::internalGetParameter(OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamVideoBitrate:
 {

             OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *)params;
 
             if (bitRate->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            bitRate->eControlRate = OMX_Video_ControlRateVariable;
            bitRate->nTargetBitrate = mBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoAvc:

         {
             OMX_VIDEO_PARAM_AVCTYPE *avcParams = (OMX_VIDEO_PARAM_AVCTYPE *)params;
 
             if (avcParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            OMX_VIDEO_AVCLEVELTYPE omxLevel = OMX_VIDEO_AVCLevel41;
 if (OMX_ErrorNone
 != ConvertAvcSpecLevelToOmxAvcLevel(mAVCEncLevel, &omxLevel)) {
 return OMX_ErrorUndefined;
 }

            avcParams->eProfile = OMX_VIDEO_AVCProfileBaseline;
            avcParams->eLevel = omxLevel;
            avcParams->nRefFrames = 1;
            avcParams->bUseHadamard = OMX_TRUE;
            avcParams->nAllowedPictureTypes = (OMX_VIDEO_PictureTypeI
 | OMX_VIDEO_PictureTypeP | OMX_VIDEO_PictureTypeB);
            avcParams->nRefIdx10ActiveMinus1 = 0;
            avcParams->nRefIdx11ActiveMinus1 = 0;
            avcParams->bWeightedPPrediction = OMX_FALSE;
            avcParams->bconstIpred = OMX_FALSE;
            avcParams->bDirect8x8Inference = OMX_FALSE;
            avcParams->bDirectSpatialTemporal = OMX_FALSE;
            avcParams->nCabacInitIdc = 0;
 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalGetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftAVC::setIpeParams() {
 ive_ctl_set_ipe_params_ip_t s_ipe_params_ip;
 ive_ctl_set_ipe_params_op_t s_ipe_params_op;
    IV_STATUS_T status;

    s_ipe_params_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_ipe_params_ip.e_sub_cmd = IVE_CMD_CTL_SET_IPE_PARAMS;

    s_ipe_params_ip.u4_enable_intra_4x4 = mIntra4x4;
    s_ipe_params_ip.u4_enc_speed_preset = mEncSpeed;

    s_ipe_params_ip.u4_timestamp_high = -1;
    s_ipe_params_ip.u4_timestamp_low = -1;

    s_ipe_params_ip.u4_size = sizeof(ive_ctl_set_ipe_params_ip_t);
    s_ipe_params_op.u4_size = sizeof(ive_ctl_set_ipe_params_op_t);

    status = ive_api_function(mCodecCtx, &s_ipe_params_ip, &s_ipe_params_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set ipe params = 0x%x\n",
                s_ipe_params_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

 virtual status_t sendCommand(
            node_id node, OMX_COMMANDTYPE cmd, OMX_S32 param) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(cmd);
        data.writeInt32(param);
        remote()->transact(SEND_COMMAND, data, &reply);

 return reply.readInt32();
 }

status_t ACodec::handleSetSurface(const sp<Surface> &surface) {
 if (surface == NULL) {
 if (mNativeWindow != NULL) {
            ALOGW("cannot unset a surface");
 return INVALID_OPERATION;
 }
 return OK;
 }

 if (mNativeWindow == NULL) {
        ALOGW("component was not configured with a surface");
 return INVALID_OPERATION;
 }

 ANativeWindow *nativeWindow = surface.get();
 if (mBuffers[kPortIndexInput].size() == 0) {
        mNativeWindow = surface;
 return OK;
 }

 if (mTunneled) {
        ALOGW("cannot change tunneled surface");
 return INVALID_OPERATION;
 }

 int usageBits = 0;
 status_t err = setupNativeWindowSizeFormatAndUsage(nativeWindow, &usageBits);
 if (err != OK) {
 return err;
 }

 int ignoredFlags = kVideoGrallocUsage;
 if ((usageBits & ~(mNativeWindowUsageBits | ignoredFlags)) != 0) {
        ALOGW("cannot change usage from %#x to %#x", mNativeWindowUsageBits, usageBits);
 return BAD_VALUE;
 }

 int minUndequeuedBuffers = 0;
    err = nativeWindow->query(
            nativeWindow, NATIVE_WINDOW_MIN_UNDEQUEUED_BUFFERS,
 &minUndequeuedBuffers);
 if (err != 0) {
        ALOGE("NATIVE_WINDOW_MIN_UNDEQUEUED_BUFFERS query failed: %s (%d)",
                strerror(-err), -err);
 return err;
 }
 if (minUndequeuedBuffers > (int)mNumUndequeuedBuffers) {
        ALOGE("new surface holds onto more buffers (%d) than planned for (%zu)",
                minUndequeuedBuffers, mNumUndequeuedBuffers);
 return BAD_VALUE;
 }

 Vector<BufferInfo> &buffers = mBuffers[kPortIndexOutput];
    ALOGV("setting up surface for %zu buffers", buffers.size());

    err = native_window_set_buffer_count(nativeWindow, buffers.size());
 if (err != 0) {
        ALOGE("native_window_set_buffer_count failed: %s (%d)", strerror(-err),
 -err);
 return err;
 }

    surface->getIGraphicBufferProducer()->allowAllocation(true);

 for (size_t i = 0; i < buffers.size(); ++i) {
 const BufferInfo &info = buffers[i];
 if (storingMetadataInDecodedBuffers()
 && !mLegacyAdaptiveExperiment
 && info.mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW) {
            ALOGV("skipping buffer %p", info.mGraphicBuffer->getNativeBuffer());
 continue;
 }
        ALOGV("attaching buffer %p", info.mGraphicBuffer->getNativeBuffer());

        err = surface->attachBuffer(info.mGraphicBuffer->getNativeBuffer());
 if (err != OK) {
            ALOGE("failed to attach buffer %p to the new surface: %s (%d)",
                    info.mGraphicBuffer->getNativeBuffer(),
                    strerror(-err), -err);
 return err;
 }
 }

 if (!storingMetadataInDecodedBuffers() || mLegacyAdaptiveExperiment) {
 for (size_t i = 0; i < buffers.size(); ++i) {
 BufferInfo &info = buffers.editItemAt(i);
 if (info.mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW) {
                ALOGV("canceling buffer %p", info.mGraphicBuffer->getNativeBuffer());
                err = nativeWindow->cancelBuffer(
                        nativeWindow, info.mGraphicBuffer->getNativeBuffer(), info.mFenceFd);
                info.mFenceFd = -1;
 if (err != OK) {
                    ALOGE("failed to cancel buffer %p to the new surface: %s (%d)",
                            info.mGraphicBuffer->getNativeBuffer(),
                            strerror(-err), -err);
 return err;
 }
 }
 }
 (void)surface->getIGraphicBufferProducer()->allowAllocation(false);
 }

 if (mFlags & kFlagPushBlankBuffersToNativeWindowOnShutdown) {
        pushBlankBuffersToNativeWindow(mNativeWindow.get());
 }

    mNativeWindow = nativeWindow;
    mNativeWindowUsageBits = usageBits;
 return OK;
}

OMX_ERRORTYPE SoftAAC2::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioAac:
 {

             OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
                 (OMX_AUDIO_PARAM_AACPROFILETYPE *)params;
 
             if (aacParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            aacParams->nBitRate = 0;
            aacParams->nAudioBandWidth = 0;
            aacParams->nAACtools = 0;
            aacParams->nAACERtools = 0;
            aacParams->eAACProfile = OMX_AUDIO_AACObjectMain;

            aacParams->eAACStreamFormat =
                mIsADTS
 ? OMX_AUDIO_AACStreamFormatMP4ADTS
 : OMX_AUDIO_AACStreamFormatMP4FF;

            aacParams->eChannelMode = OMX_AUDIO_ChannelModeStereo;

 if (!isConfigured()) {
                aacParams->nChannels = 1;
                aacParams->nSampleRate = 44100;
                aacParams->nFrameLength = 0;
 } else {
                aacParams->nChannels = mStreamInfo->numChannels;
                aacParams->nSampleRate = mStreamInfo->sampleRate;
                aacParams->nFrameLength = mStreamInfo->frameSize;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;
            pcmParams->eChannelMapping[2] = OMX_AUDIO_ChannelCF;
            pcmParams->eChannelMapping[3] = OMX_AUDIO_ChannelLFE;
            pcmParams->eChannelMapping[4] = OMX_AUDIO_ChannelLS;
            pcmParams->eChannelMapping[5] = OMX_AUDIO_ChannelRS;

 if (!isConfigured()) {
                pcmParams->nChannels = 1;
                pcmParams->nSamplingRate = 44100;
 } else {
                pcmParams->nChannels = mStreamInfo->numChannels;
                pcmParams->nSamplingRate = mStreamInfo->sampleRate;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

status_t OMXCodec::configureCodec(const sp<MetaData> &meta) {
ALOGV("configureCodec protected=%d",
(mFlags & kEnableGrallocUsageProtected) ? 1 : 0);

if (!(mFlags & kIgnoreCodecSpecificData)) {
uint32_t type;
const void *data;
size_t size;
if (meta->findData(kKeyESDS, &type, &data, &size)) {
ESDS esds((const char *)data, size);
CHECK_EQ(esds.InitCheck(), (status_t)OK);

const void *codec_specific_data;
size_t codec_specific_data_size;
esds.getCodecSpecificInfo(
&codec_specific_data, &codec_specific_data_size);

addCodecSpecificData(
codec_specific_data, codec_specific_data_size);
} else if (meta->findData(kKeyAVCC, &type, &data, &size)) {
// Parse the AVCDecoderConfigurationRecord

unsigned profile, level;
status_t err;
if ((err = parseAVCCodecSpecificData(
data, size, &profile, &level)) != OK) {
ALOGE("Malformed AVC codec specific data.");
return err;
}

CODEC_LOGI(
"AVC profile = %u (%s), level = %u",
profile, AVCProfileToString(profile), level);
} else if (meta->findData(kKeyHVCC, &type, &data, &size)) {
// Parse the HEVCDecoderConfigurationRecord

unsigned profile, level;
status_t err;
if ((err = parseHEVCCodecSpecificData(
data, size, &profile, &level)) != OK) {
ALOGE("Malformed HEVC codec specific data.");
return err;
}

CODEC_LOGI(
"HEVC profile = %u , level = %u",
profile, level);
} else if (meta->findData(kKeyVorbisInfo, &type, &data, &size)) {
addCodecSpecificData(data, size);

CHECK(meta->findData(kKeyVorbisBooks, &type, &data, &size));
addCodecSpecificData(data, size);
} else if (meta->findData(kKeyOpusHeader, &type, &data, &size)) {
addCodecSpecificData(data, size);

CHECK(meta->findData(kKeyOpusCodecDelay, &type, &data, &size));
addCodecSpecificData(data, size);
CHECK(meta->findData(kKeyOpusSeekPreRoll, &type, &data, &size));
addCodecSpecificData(data, size);
}
}

int32_t bitRate = 0;
if (mIsEncoder) {
CHECK(meta->findInt32(kKeyBitRate, &bitRate));
}
if (!strcasecmp(MEDIA_MIMETYPE_AUDIO_AMR_NB, mMIME)) {
setAMRFormat(false /* isWAMR */, bitRate);
} else if (!strcasecmp(MEDIA_MIMETYPE_AUDIO_AMR_WB, mMIME)) {
setAMRFormat(true /* isWAMR */, bitRate);
} else if (!strcasecmp(MEDIA_MIMETYPE_AUDIO_AAC, mMIME)) {
int32_t numChannels, sampleRate, aacProfile;
CHECK(meta->findInt32(kKeyChannelCount, &numChannels));
CHECK(meta->findInt32(kKeySampleRate, &sampleRate));

if (!meta->findInt32(kKeyAACProfile, &aacProfile)) {
aacProfile = OMX_AUDIO_AACObjectNull;
}

int32_t isADTS;
if (!meta->findInt32(kKeyIsADTS, &isADTS)) {
isADTS = false;
}

status_t err = setAACFormat(numChannels, sampleRate, bitRate, aacProfile, isADTS);
if (err != OK) {
CODEC_LOGE("setAACFormat() failed (err = %d)", err);
return err;
}
} else if (!strcasecmp(MEDIA_MIMETYPE_AUDIO_MPEG, mMIME)) {
int32_t numChannels, sampleRate;
if (meta->findInt32(kKeyChannelCount, &numChannels)
&& meta->findInt32(kKeySampleRate, &sampleRate)) {
// Since we did not always check for these, leave them optional
// and have the decoder figure it all out.
setRawAudioFormat(
mIsEncoder ? kPortIndexInput : kPortIndexOutput,
sampleRate,
numChannels);
}
} else if (!strcasecmp(MEDIA_MIMETYPE_AUDIO_AC3, mMIME)) {
int32_t numChannels;
int32_t sampleRate;
CHECK(meta->findInt32(kKeyChannelCount, &numChannels));
CHECK(meta->findInt32(kKeySampleRate, &sampleRate));

status_t err = setAC3Format(numChannels, sampleRate);
if (err != OK) {
CODEC_LOGE("setAC3Format() failed (err = %d)", err);
return err;
}
} else if (!strcasecmp(MEDIA_MIMETYPE_AUDIO_G711_ALAW, mMIME)
|| !strcasecmp(MEDIA_MIMETYPE_AUDIO_G711_MLAW, mMIME)) {
// These are PCM-like formats with a fixed sample rate but
// a variable number of channels.

int32_t sampleRate;
int32_t numChannels;
CHECK(meta->findInt32(kKeyChannelCount, &numChannels));
if (!meta->findInt32(kKeySampleRate, &sampleRate)) {
sampleRate = 8000;
}

setG711Format(sampleRate, numChannels);
} else if (!strcasecmp(MEDIA_MIMETYPE_AUDIO_RAW, mMIME)) {
CHECK(!mIsEncoder);

int32_t numChannels, sampleRate;
CHECK(meta->findInt32(kKeyChannelCount, &numChannels));
CHECK(meta->findInt32(kKeySampleRate, &sampleRate));

setRawAudioFormat(kPortIndexInput, sampleRate, numChannels);
}

if (!strncasecmp(mMIME, "video/", 6)) {

if (mIsEncoder) {
setVideoInputFormat(mMIME, meta);
} else {
status_t err = setVideoOutputFormat(
mMIME, meta);

if (err != OK) {
return err;
}
}
}

int32_t maxInputSize;
if (meta->findInt32(kKeyMaxInputSize, &maxInputSize)) {
setMinBufferSize(kPortIndexInput, (OMX_U32)maxInputSize);
}


initOutputFormat(meta);

    if ((mFlags & kClientNeedsFramebuffer)
            && !strncmp(mComponentName, "OMX.SEC.", 8)) {
        // This appears to no longer be needed???
        OMX_INDEXTYPE index;
        status_t err =
            mOMX->getExtensionIndex(
                    mNode,
                    "OMX.SEC.index.ThumbnailMode",
                    &index);
        if (err != OK) {
            return err;
        }
        OMX_BOOL enable = OMX_TRUE;
        err = mOMX->setConfig(mNode, index, &enable, sizeof(enable));
        if (err != OK) {
            CODEC_LOGE("setConfig('OMX.SEC.index.ThumbnailMode') "
                       "returned error 0x%08x", err);
            return err;
        }
        mQuirks &= ~kOutputBuffersAreUnreadable;
    }
if (mNativeWindow != NULL
&& !mIsEncoder
&& !strncasecmp(mMIME, "video/", 6)
&& !strncmp(mComponentName, "OMX.", 4)) {
status_t err = initNativeWindow();
if (err != OK) {
return err;
}
}

return OK;
}

ACodec::BufferInfo *ACodec::dequeueBufferFromNativeWindow() {
 ANativeWindowBuffer *buf;
    CHECK(mNativeWindow.get() != NULL);

 if (mTunneled) {
        ALOGW("dequeueBufferFromNativeWindow() should not be called in tunnel"
 " video playback mode mode!");
 return NULL;
 }

 if (mFatalError) {
        ALOGW("not dequeuing from native window due to fatal error");
 return NULL;
 }

 int fenceFd = -1;
 do {
 status_t err = mNativeWindow->dequeueBuffer(mNativeWindow.get(), &buf, &fenceFd);
 if (err != 0) {
            ALOGE("dequeueBuffer failed: %s(%d).", asString(err), err);
 return NULL;
 }

 bool stale = false;
 for (size_t i = mBuffers[kPortIndexOutput].size(); i-- > 0;) {
 BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);

 if (info->mGraphicBuffer != NULL &&
                    info->mGraphicBuffer->handle == buf->handle) {
 if (info->mStatus != BufferInfo::OWNED_BY_NATIVE_WINDOW) {
                    ALOGI("dequeued stale buffer %p. discarding", buf);
                    stale = true;
 break;
 }

                ALOGV("dequeued buffer %p", info->mGraphicBuffer->getNativeBuffer());
                info->mStatus = BufferInfo::OWNED_BY_US;
                info->setWriteFence(fenceFd, "dequeueBufferFromNativeWindow");
                updateRenderInfoForDequeuedBuffer(buf, fenceFd, info);
 return info;
 }
 }

 if (!stale && (!storingMetadataInDecodedBuffers() || mLegacyAdaptiveExperiment)) {
            ALOGI("dequeued unrecognized (stale) buffer %p. discarding", buf);
            stale = true;
 }
 if (stale) {
            buf = NULL;
 }
 } while (buf == NULL);

 BufferInfo *oldest = NULL;
 for (size_t i = mBuffers[kPortIndexOutput].size(); i-- > 0;) {
 BufferInfo *info =
 &mBuffers[kPortIndexOutput].editItemAt(i);
 if (info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW &&
 (oldest == NULL ||
             mDequeueCounter - info->mDequeuedAt >
                    mDequeueCounter - oldest->mDequeuedAt)) {
            oldest = info;
 }
 }

    CHECK(oldest != NULL);
    CHECK(storingMetadataInDecodedBuffers());

    oldest->mGraphicBuffer = new GraphicBuffer(buf, false);
    oldest->mStatus = BufferInfo::OWNED_BY_US;
    oldest->setWriteFence(fenceFd, "dequeueBufferFromNativeWindow for oldest");
    mRenderTracker.untrackFrame(oldest->mRenderInfo);
    oldest->mRenderInfo = NULL;

    mOMX->updateGraphicBufferInMeta(
            mNode, kPortIndexOutput, oldest->mGraphicBuffer,
            oldest->mBufferID);

 if (mOutputMetadataType == kMetadataBufferTypeGrallocSource) {
 VideoGrallocMetadata *grallocMeta =
 reinterpret_cast<VideoGrallocMetadata *>(oldest->mData->base());
        ALOGV("replaced oldest buffer #%u with age %u (%p/%p stored in %p)",
 (unsigned)(oldest - &mBuffers[kPortIndexOutput][0]),
                mDequeueCounter - oldest->mDequeuedAt,
 (void *)(uintptr_t)grallocMeta->pHandle,
                oldest->mGraphicBuffer->handle, oldest->mData->base());
 } else if (mOutputMetadataType == kMetadataBufferTypeANWBuffer) {
 VideoNativeMetadata *nativeMeta =
 reinterpret_cast<VideoNativeMetadata *>(oldest->mData->base());
        ALOGV("replaced oldest buffer #%u with age %u (%p/%p stored in %p)",
 (unsigned)(oldest - &mBuffers[kPortIndexOutput][0]),
                mDequeueCounter - oldest->mDequeuedAt,
 (void *)(uintptr_t)nativeMeta->pBuffer,
                oldest->mGraphicBuffer->getNativeBuffer(), oldest->mData->base());
 }

    updateRenderInfoForDequeuedBuffer(buf, fenceFd, oldest);
 return oldest;
}

 virtual status_t getExtensionIndex(
            node_id node,
 const char *parameter_name,
            OMX_INDEXTYPE *index) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeCString(parameter_name);

        remote()->transact(GET_EXTENSION_INDEX, data, &reply);

 status_t err = reply.readInt32();
 if (err == OK) {
 *index = static_cast<OMX_INDEXTYPE>(reply.readInt32());
 } else {
 *index = OMX_IndexComponentStartUnused;
 }

 return err;
 }

 virtual status_t freeNode(node_id node) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        remote()->transact(FREE_NODE, data, &reply);

 return reply.readInt32();
 }

bool ACodec::BaseState::onOMXMessage(const sp<AMessage> &msg) {
 int32_t type;
    CHECK(msg->findInt32("type", &type));

 switch (type) {
 case omx_message::EVENT:
 {
 int32_t event, data1, data2;
            CHECK(msg->findInt32("event", &event));
            CHECK(msg->findInt32("data1", &data1));
            CHECK(msg->findInt32("data2", &data2));

 if (event == OMX_EventCmdComplete
 && data1 == OMX_CommandFlush
 && data2 == (int32_t)OMX_ALL) {

 return true;
 }

 return onOMXEvent(
 static_cast<OMX_EVENTTYPE>(event),
 static_cast<OMX_U32>(data1),
 static_cast<OMX_U32>(data2));
 }

 case omx_message::EMPTY_BUFFER_DONE:
 {
            IOMX::buffer_id bufferID;
 int32_t fenceFd;

            CHECK(msg->findInt32("buffer", (int32_t*)&bufferID));
            CHECK(msg->findInt32("fence_fd", &fenceFd));

 return onOMXEmptyBufferDone(bufferID, fenceFd);
 }

 case omx_message::FILL_BUFFER_DONE:
 {
            IOMX::buffer_id bufferID;
            CHECK(msg->findInt32("buffer", (int32_t*)&bufferID));

 int32_t rangeOffset, rangeLength, flags, fenceFd;
 int64_t timeUs;

            CHECK(msg->findInt32("range_offset", &rangeOffset));
            CHECK(msg->findInt32("range_length", &rangeLength));
            CHECK(msg->findInt32("flags", &flags));
            CHECK(msg->findInt64("timestamp", &timeUs));
            CHECK(msg->findInt32("fence_fd", &fenceFd));

 return onOMXFillBufferDone(
                    bufferID,
 (size_t)rangeOffset, (size_t)rangeLength,
 (OMX_U32)flags,
                    timeUs,
                    fenceFd);
 }

 case omx_message::FRAME_RENDERED:
 {
 int64_t mediaTimeUs, systemNano;

            CHECK(msg->findInt64("media_time_us", &mediaTimeUs));
            CHECK(msg->findInt64("system_nano", &systemNano));

 return onOMXFrameRendered(
                    mediaTimeUs, systemNano);
 }

 default:
            ALOGE("Unexpected message type: %d", type);
 return false;
 }
}

void ACodec::BufferInfo::checkWriteFence(const char *dbg) {
 if (mFenceFd >= 0 && mIsReadFence) {
        ALOGD("REUSING read fence %d as write fence in %s", mFenceFd, dbg);
 }
}

 virtual status_t allocateBuffer(
            node_id node, OMX_U32 port_index, size_t size,
            buffer_id *buffer, void **buffer_data) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeInt64(size);
        remote()->transact(ALLOC_BUFFER, data, &reply);

 status_t err = reply.readInt32();
 if (err != OK) {
 *buffer = 0;

 return err;
 }

 *buffer = (buffer_id)reply.readInt32();
 *buffer_data = (void *)reply.readInt64();

 return err;
 }

static status_t GetMimeTypeForVideoCoding(
        OMX_VIDEO_CODINGTYPE codingType, AString *mime) {
 for (size_t i = 0;
         i < sizeof(kVideoCodingMapEntry) / sizeof(kVideoCodingMapEntry[0]);
 ++i) {
 if (codingType == kVideoCodingMapEntry[i].mVideoCodingType) {
 *mime = kVideoCodingMapEntry[i].mMime;
 return OK;
 }
 }

    mime->clear();

 return ERROR_UNSUPPORTED;
}

void ACodec::initiateSetInputSurface(
 const sp<PersistentSurface> &surface) {
    sp<AMessage> msg = new AMessage(kWhatSetInputSurface, this);
    msg->setObject("input-surface", surface);
    msg->post();
}

 virtual ~CodecObserver() {}

void ACodec::ExecutingToIdleState::onInputBufferFilled(
 const sp<AMessage> &msg) {
 BaseState::onInputBufferFilled(msg);

    changeStateIfWeOwnAllBuffers();
}

bool ACodec::OutputPortSettingsChangedState::onOMXFrameRendered(
 int64_t mediaTimeUs, nsecs_t systemNano) {
    mCodec->onFrameRendered(mediaTimeUs, systemNano);
 return true;
}

 BpOMXObserver(const sp<IBinder> &impl)
 : BpInterface<IOMXObserver>(impl) {
 }

status_t ACodec::getPortFormat(OMX_U32 portIndex, sp<AMessage> &notify) {
 const char *niceIndex = portIndex == kPortIndexInput ? "input" : "output";
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

 status_t err = mOMX->getParameter(mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
 if (err != OK) {
 return err;
 }

 if (def.eDir != (portIndex == kPortIndexOutput ? OMX_DirOutput : OMX_DirInput)) {
        ALOGE("unexpected dir: %s(%d) on %s port", asString(def.eDir), def.eDir, niceIndex);
 return BAD_VALUE;
 }

 switch (def.eDomain) {
 case OMX_PortDomainVideo:
 {
            OMX_VIDEO_PORTDEFINITIONTYPE *videoDef = &def.format.video;
 switch ((int)videoDef->eCompressionFormat) {
 case OMX_VIDEO_CodingUnused:
 {
                    CHECK(mIsEncoder ^ (portIndex == kPortIndexOutput));
                    notify->setString("mime", MEDIA_MIMETYPE_VIDEO_RAW);

                    notify->setInt32("stride", videoDef->nStride);
                    notify->setInt32("slice-height", videoDef->nSliceHeight);
                    notify->setInt32("color-format", videoDef->eColorFormat);

 if (mNativeWindow == NULL) {
 DescribeColorFormatParams describeParams;
 InitOMXParams(&describeParams);
                        describeParams.eColorFormat = videoDef->eColorFormat;
                        describeParams.nFrameWidth = videoDef->nFrameWidth;
                        describeParams.nFrameHeight = videoDef->nFrameHeight;
                        describeParams.nStride = videoDef->nStride;
                        describeParams.nSliceHeight = videoDef->nSliceHeight;
                        describeParams.bUsingNativeBuffers = OMX_FALSE;

 if (describeColorFormat(mOMX, mNode, describeParams)) {
                            notify->setBuffer(
 "image-data",
 ABuffer::CreateAsCopy(
 &describeParams.sMediaImage,
 sizeof(describeParams.sMediaImage)));

 MediaImage *img = &describeParams.sMediaImage;
                            ALOGV("[%s] MediaImage { F(%ux%u) @%u+%u+%u @%u+%u+%u @%u+%u+%u }",
                                    mComponentName.c_str(), img->mWidth, img->mHeight,
                                    img->mPlane[0].mOffset, img->mPlane[0].mColInc, img->mPlane[0].mRowInc,
                                    img->mPlane[1].mOffset, img->mPlane[1].mColInc, img->mPlane[1].mRowInc,
                                    img->mPlane[2].mOffset, img->mPlane[2].mColInc, img->mPlane[2].mRowInc);
 }
 }

 if (portIndex != kPortIndexOutput) {
 break;
 }

                    OMX_CONFIG_RECTTYPE rect;
 InitOMXParams(&rect);
                    rect.nPortIndex = portIndex;

 if (mOMX->getConfig(
                                mNode,
 (portIndex == kPortIndexOutput ?
                                        OMX_IndexConfigCommonOutputCrop :
                                        OMX_IndexConfigCommonInputCrop),
 &rect, sizeof(rect)) != OK) {
                        rect.nLeft = 0;
                        rect.nTop = 0;
                        rect.nWidth = videoDef->nFrameWidth;
                        rect.nHeight = videoDef->nFrameHeight;
 }

 if (rect.nLeft < 0 ||
                        rect.nTop < 0 ||
                        rect.nLeft + rect.nWidth > videoDef->nFrameWidth ||
                        rect.nTop + rect.nHeight > videoDef->nFrameHeight) {
                        ALOGE("Wrong cropped rect (%d, %d) - (%u, %u) vs. frame (%u, %u)",
                                rect.nLeft, rect.nTop,
                                rect.nLeft + rect.nWidth, rect.nTop + rect.nHeight,
                                videoDef->nFrameWidth, videoDef->nFrameHeight);
 return BAD_VALUE;
 }

                    notify->setRect(
 "crop",
                            rect.nLeft,
                            rect.nTop,
                            rect.nLeft + rect.nWidth - 1,
                            rect.nTop + rect.nHeight - 1);

 break;
 }

 case OMX_VIDEO_CodingVP8:
 case OMX_VIDEO_CodingVP9:
 {
                    OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE vp8type;
 InitOMXParams(&vp8type);
                    vp8type.nPortIndex = kPortIndexOutput;
 status_t err = mOMX->getParameter(
                            mNode,
 (OMX_INDEXTYPE)OMX_IndexParamVideoAndroidVp8Encoder,
 &vp8type,
 sizeof(vp8type));

 if (err == OK) {
 AString tsSchema = "none";
 if (vp8type.eTemporalPattern
 == OMX_VIDEO_VPXTemporalLayerPatternWebRTC) {
 switch (vp8type.nTemporalLayerCount) {
 case 1:
 {
                                    tsSchema = "webrtc.vp8.1-layer";
 break;
 }
 case 2:
 {
                                    tsSchema = "webrtc.vp8.2-layer";
 break;
 }
 case 3:
 {
                                    tsSchema = "webrtc.vp8.3-layer";
 break;
 }
 default:
 {
 break;
 }
 }
 }
                        notify->setString("ts-schema", tsSchema);
 }
 }

 default:
 {
 if (mIsEncoder ^ (portIndex == kPortIndexOutput)) {
                        ALOGE("Raw port video compression format is %s(%d)",
                                asString(videoDef->eCompressionFormat),
                                videoDef->eCompressionFormat);
 return BAD_VALUE;
 }
 AString mime;
 if (GetMimeTypeForVideoCoding(
                        videoDef->eCompressionFormat, &mime) != OK) {
                        notify->setString("mime", "application/octet-stream");
 } else {
                        notify->setString("mime", mime.c_str());
 }
 break;
 }
 }
            notify->setInt32("width", videoDef->nFrameWidth);
            notify->setInt32("height", videoDef->nFrameHeight);
            ALOGV("[%s] %s format is %s", mComponentName.c_str(),
                    portIndex == kPortIndexInput ? "input" : "output",
                    notify->debugString().c_str());

 break;
 }

 case OMX_PortDomainAudio:
 {
            OMX_AUDIO_PORTDEFINITIONTYPE *audioDef = &def.format.audio;

 switch ((int)audioDef->eEncoding) {
 case OMX_AUDIO_CodingPCM:
 {
                    OMX_AUDIO_PARAM_PCMMODETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioPcm, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

 if (params.nChannels <= 0
 || (params.nChannels != 1 && !params.bInterleaved)
 || params.nBitPerSample != 16u
 || params.eNumData != OMX_NumericalDataSigned
 || params.ePCMMode != OMX_AUDIO_PCMModeLinear) {
                        ALOGE("unsupported PCM port: %u channels%s, %u-bit, %s(%d), %s(%d) mode ",
                                params.nChannels,
                                params.bInterleaved ? " interleaved" : "",
                                params.nBitPerSample,
                                asString(params.eNumData), params.eNumData,
                                asString(params.ePCMMode), params.ePCMMode);
 return FAILED_TRANSACTION;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_RAW);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSamplingRate);

 if (mChannelMaskPresent) {
                        notify->setInt32("channel-mask", mChannelMask);
 }
 break;
 }

 case OMX_AUDIO_CodingAAC:
 {
                    OMX_AUDIO_PARAM_AACPROFILETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioAac, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AAC);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAMR:
 {
                    OMX_AUDIO_PARAM_AMRTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioAmr, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setInt32("channel-count", 1);
 if (params.eAMRBandMode >= OMX_AUDIO_AMRBandModeWB0) {
                        notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AMR_WB);
                        notify->setInt32("sample-rate", 16000);
 } else {
                        notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AMR_NB);
                        notify->setInt32("sample-rate", 8000);
 }
 break;
 }

 case OMX_AUDIO_CodingFLAC:
 {
                    OMX_AUDIO_PARAM_FLACTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioFlac, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_FLAC);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingMP3:
 {
                    OMX_AUDIO_PARAM_MP3TYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioMp3, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_MPEG);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingVORBIS:
 {
                    OMX_AUDIO_PARAM_VORBISTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioVorbis, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_VORBIS);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAndroidAC3:
 {
                    OMX_AUDIO_PARAM_ANDROID_AC3TYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidAc3,
 &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AC3);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAndroidEAC3:
 {
                    OMX_AUDIO_PARAM_ANDROID_EAC3TYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidEac3,
 &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_EAC3);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAndroidOPUS:
 {
                    OMX_AUDIO_PARAM_ANDROID_OPUSTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidOpus,
 &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_OPUS);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingG711:
 {
                    OMX_AUDIO_PARAM_PCMMODETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioPcm, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

 const char *mime = NULL;
 if (params.ePCMMode == OMX_AUDIO_PCMModeMULaw) {
                        mime = MEDIA_MIMETYPE_AUDIO_G711_MLAW;
 } else if (params.ePCMMode == OMX_AUDIO_PCMModeALaw) {
                        mime = MEDIA_MIMETYPE_AUDIO_G711_ALAW;
 } else { // params.ePCMMode == OMX_AUDIO_PCMModeLinear
                        mime = MEDIA_MIMETYPE_AUDIO_RAW;
 }
                    notify->setString("mime", mime);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSamplingRate);
 break;
 }

 case OMX_AUDIO_CodingGSMFR:
 {
                    OMX_AUDIO_PARAM_PCMMODETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                                mNode, OMX_IndexParamAudioPcm, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_MSGSM);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSamplingRate);
 break;
 }

 default:
                    ALOGE("Unsupported audio coding: %s(%d)\n",
                            asString(audioDef->eEncoding), audioDef->eEncoding);
 return BAD_TYPE;
 }
 break;
 }

 default:
            ALOGE("Unsupported domain: %s(%d)", asString(def.eDomain), def.eDomain);
 return BAD_TYPE;
 }

 return OK;
}

ACodec::ExecutingState::ExecutingState(ACodec *codec)
 : BaseState(codec),
      mActive(false) {
}

void ACodec::sendFormatChange(const sp<AMessage> &reply) {
    sp<AMessage> notify = mBaseOutputFormat->dup();
    notify->setInt32("what", kWhatOutputFormatChanged);

 if (getPortFormat(kPortIndexOutput, notify) != OK) {
        ALOGE("[%s] Failed to get port format to send format change", mComponentName.c_str());
 return;
 }

 AString mime;
    CHECK(notify->findString("mime", &mime));

 int32_t left, top, right, bottom;
 if (mime == MEDIA_MIMETYPE_VIDEO_RAW &&
        mNativeWindow != NULL &&
        notify->findRect("crop", &left, &top, &right, &bottom)) {
        reply->setRect("crop", left, top, right + 1, bottom + 1);
 } else if (mime == MEDIA_MIMETYPE_AUDIO_RAW &&
 (mEncoderDelay || mEncoderPadding)) {
 int32_t channelCount;
        CHECK(notify->findInt32("channel-count", &channelCount));
 size_t frameSize = channelCount * sizeof(int16_t);
 if (mSkipCutBuffer != NULL) {
 size_t prevbufsize = mSkipCutBuffer->size();
 if (prevbufsize != 0) {
                ALOGW("Replacing SkipCutBuffer holding %zu bytes", prevbufsize);
 }
 }
        mSkipCutBuffer = new SkipCutBuffer(
                mEncoderDelay * frameSize,
                mEncoderPadding * frameSize);
 }

    notify->post();

    mSentFormat = true;
}

 virtual status_t listNodes(List<ComponentInfo> *list) {
 list->clear();

 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        remote()->transact(LIST_NODES, data, &reply);

 int32_t n = reply.readInt32();
 for (int32_t i = 0; i < n; ++i) {
 list->push_back(ComponentInfo());
 ComponentInfo &info = *--list->end();

            info.mName = reply.readString8();
 int32_t numRoles = reply.readInt32();
 for (int32_t j = 0; j < numRoles; ++j) {
                info.mRoles.push_back(reply.readString8());
 }
 }

 return OK;
 }

status_t ACodec::initNativeWindow() {
 if (mNativeWindow != NULL) {
 return mOMX->enableGraphicBuffers(mNode, kPortIndexOutput, OMX_TRUE);
 }

    mOMX->enableGraphicBuffers(mNode, kPortIndexOutput, OMX_FALSE);
 return OK;
}

bool ACodec::BaseState::checkOMXMessage(const sp<AMessage> &msg) {
 if (mCodec->mNode == 0) {
        ALOGI("ignoring message as already freed component: %s",
                msg->debugString().c_str());
 return false;
 }

    IOMX::node_id nodeID;
    CHECK(msg->findInt32("node", (int32_t*)&nodeID));
 if (nodeID != mCodec->mNode) {
        ALOGE("Unexpected message for nodeID: %u, should have been %u", nodeID, mCodec->mNode);
 return false;
 }
 return true;
}

status_t ACodec::setupErrorCorrectionParameters() {
    OMX_VIDEO_PARAM_ERRORCORRECTIONTYPE errorCorrectionType;
 InitOMXParams(&errorCorrectionType);
    errorCorrectionType.nPortIndex = kPortIndexOutput;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamVideoErrorCorrection,
 &errorCorrectionType, sizeof(errorCorrectionType));

 if (err != OK) {
 return OK; // Optional feature. Ignore this failure
 }

    errorCorrectionType.bEnableHEC = OMX_FALSE;
    errorCorrectionType.bEnableResync = OMX_TRUE;
    errorCorrectionType.nResynchMarkerSpacing = 256;
    errorCorrectionType.bEnableDataPartitioning = OMX_FALSE;
    errorCorrectionType.bEnableRVLC = OMX_FALSE;

 return mOMX->setParameter(
            mNode, OMX_IndexParamVideoErrorCorrection,
 &errorCorrectionType, sizeof(errorCorrectionType));
}

void ACodec::BaseState::postFillThisBuffer(BufferInfo *info) {
 if (mCodec->mPortEOS[kPortIndexInput]) {
 return;
 }

    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_US);

    sp<AMessage> notify = mCodec->mNotify->dup();
    notify->setInt32("what", CodecBase::kWhatFillThisBuffer);
    notify->setInt32("buffer-id", info->mBufferID);

    info->mData->meta()->clear();
    notify->setBuffer("buffer", info->mData);

    sp<AMessage> reply = new AMessage(kWhatInputBufferFilled, mCodec);
    reply->setInt32("buffer-id", info->mBufferID);

    notify->setMessage("reply", reply);

    notify->post();

    info->mStatus = BufferInfo::OWNED_BY_UPSTREAM;
}

OMX_ERRORTYPE SoftMP3::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.mp3",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (const OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            mNumChannels = pcmParams->nChannels;
            mSamplingRate = pcmParams->nSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

status_t ACodec::freeBuffersOnPort(OMX_U32 portIndex) {
 status_t err = OK;
 for (size_t i = mBuffers[portIndex].size(); i > 0;) {
        i--;
 status_t err2 = freeBuffer(portIndex, i);
 if (err == OK) {
            err = err2;
 }
 }

    mDealer[portIndex].clear();
 return err;
}

OMX_ERRORTYPE SoftAVC::setBitRate() {
 ive_ctl_set_bitrate_ip_t s_bitrate_ip;
 ive_ctl_set_bitrate_op_t s_bitrate_op;
    IV_STATUS_T status;

    s_bitrate_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_bitrate_ip.e_sub_cmd = IVE_CMD_CTL_SET_BITRATE;

    s_bitrate_ip.u4_target_bitrate = mBitrate;

    s_bitrate_ip.u4_timestamp_high = -1;
    s_bitrate_ip.u4_timestamp_low = -1;

    s_bitrate_ip.u4_size = sizeof(ive_ctl_set_bitrate_ip_t);
    s_bitrate_op.u4_size = sizeof(ive_ctl_set_bitrate_op_t);

    status = ive_api_function(mCodecCtx, &s_bitrate_ip, &s_bitrate_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set bit rate = 0x%x\n", s_bitrate_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

void ACodec::FlushingState::onInputBufferFilled(const sp<AMessage> &msg) {
 BaseState::onInputBufferFilled(msg);

    changeStateIfWeOwnAllBuffers();
}

status_t ACodec::LoadedState::setupInputSurface() {
 status_t err = OK;

 if (mCodec->mRepeatFrameDelayUs > 0ll) {
        err = mCodec->mOMX->setInternalOption(
                mCodec->mNode,
                kPortIndexInput,
                IOMX::INTERNAL_OPTION_REPEAT_PREVIOUS_FRAME_DELAY,
 &mCodec->mRepeatFrameDelayUs,
 sizeof(mCodec->mRepeatFrameDelayUs));

 if (err != OK) {
            ALOGE("[%s] Unable to configure option to repeat previous "
 "frames (err %d)",
                  mCodec->mComponentName.c_str(),
                  err);
 return err;
 }
 }

 if (mCodec->mMaxPtsGapUs > 0ll) {
        err = mCodec->mOMX->setInternalOption(
                mCodec->mNode,
                kPortIndexInput,
                IOMX::INTERNAL_OPTION_MAX_TIMESTAMP_GAP,
 &mCodec->mMaxPtsGapUs,
 sizeof(mCodec->mMaxPtsGapUs));

 if (err != OK) {
            ALOGE("[%s] Unable to configure max timestamp gap (err %d)",
                    mCodec->mComponentName.c_str(),
                    err);
 return err;
 }
 }

 if (mCodec->mMaxFps > 0) {
        err = mCodec->mOMX->setInternalOption(
                mCodec->mNode,
                kPortIndexInput,
                IOMX::INTERNAL_OPTION_MAX_FPS,
 &mCodec->mMaxFps,
 sizeof(mCodec->mMaxFps));

 if (err != OK) {
            ALOGE("[%s] Unable to configure max fps (err %d)",
                    mCodec->mComponentName.c_str(),
                    err);
 return err;
 }
 }

 if (mCodec->mTimePerCaptureUs > 0ll
 && mCodec->mTimePerFrameUs > 0ll) {
 int64_t timeLapse[2];
        timeLapse[0] = mCodec->mTimePerFrameUs;
        timeLapse[1] = mCodec->mTimePerCaptureUs;
        err = mCodec->mOMX->setInternalOption(
                mCodec->mNode,
                kPortIndexInput,
                IOMX::INTERNAL_OPTION_TIME_LAPSE,
 &timeLapse[0],
 sizeof(timeLapse));

 if (err != OK) {
            ALOGE("[%s] Unable to configure time lapse (err %d)",
                    mCodec->mComponentName.c_str(),
                    err);
 return err;
 }
 }

 if (mCodec->mCreateInputBuffersSuspended) {
 bool suspend = true;
        err = mCodec->mOMX->setInternalOption(
                mCodec->mNode,
                kPortIndexInput,
                IOMX::INTERNAL_OPTION_SUSPEND,
 &suspend,
 sizeof(suspend));

 if (err != OK) {
            ALOGE("[%s] Unable to configure option to suspend (err %d)",
                  mCodec->mComponentName.c_str(),
                  err);
 return err;
 }
 }

 uint32_t usageBits;
 if (mCodec->mOMX->getParameter(
            mCodec->mNode, (OMX_INDEXTYPE)OMX_IndexParamConsumerUsageBits,
 &usageBits, sizeof(usageBits)) == OK) {
        mCodec->mInputFormat->setInt32(
 "using-sw-read-often", !!(usageBits & GRALLOC_USAGE_SW_READ_OFTEN));
 }

 return OK;
}

void ACodec::UninitializedState::stateEntered() {
    ALOGV("Now uninitialized");

 if (mDeathNotifier != NULL) {
 IInterface::asBinder(mCodec->mOMX)->unlinkToDeath(mDeathNotifier);
        mDeathNotifier.clear();
 }

    mCodec->mNativeWindow.clear();
    mCodec->mNativeWindowUsageBits = 0;
    mCodec->mNode = 0;
    mCodec->mOMX.clear();
    mCodec->mQuirks = 0;
    mCodec->mFlags = 0;
    mCodec->mInputMetadataType = kMetadataBufferTypeInvalid;
    mCodec->mOutputMetadataType = kMetadataBufferTypeInvalid;
    mCodec->mComponentName.clear();
}

bool ACodec::BaseState::onOMXEmptyBufferDone(IOMX::buffer_id bufferID, int fenceFd) {
    ALOGV("[%s] onOMXEmptyBufferDone %u",
         mCodec->mComponentName.c_str(), bufferID);

 BufferInfo *info = mCodec->findBufferByID(kPortIndexInput, bufferID);
 BufferInfo::Status status = BufferInfo::getSafeStatus(info);
 if (status != BufferInfo::OWNED_BY_COMPONENT) {
        ALOGE("Wrong ownership in EBD: %s(%d) buffer #%u", _asString(status), status, bufferID);
        mCodec->dumpBuffers(kPortIndexInput);
 if (fenceFd >= 0) {
 ::close(fenceFd);
 }
 return false;
 }
    info->mStatus = BufferInfo::OWNED_BY_US;

 (void)mCodec->waitForFence(fenceFd, "onOMXEmptyBufferDone");
    fenceFd = -1;

    info->setWriteFence(fenceFd, "onOMXEmptyBufferDone");

    info->mData->setMediaBufferBase(NULL);

 PortMode mode = getPortMode(kPortIndexInput);

 switch (mode) {
 case KEEP_BUFFERS:
 break;

 case RESUBMIT_BUFFERS:
            postFillThisBuffer(info);
 break;

 case FREE_BUFFERS:
 default:
            ALOGE("SHOULD NOT REACH HERE: cannot free empty output buffers");
 return false;
 }

 return true;
}

status_t BnOMX::onTransact(
uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {
switch (code) {
case LIVES_LOCALLY:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);
node_id node = (node_id)data.readInt32();
pid_t pid = (pid_t)data.readInt32();
reply->writeInt32(livesLocally(node, pid));

return OK;
}

case LIST_NODES:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

List<ComponentInfo> list;
listNodes(&list);

reply->writeInt32(list.size());
for (List<ComponentInfo>::iterator it = list.begin();
it != list.end(); ++it) {
ComponentInfo &cur = *it;

reply->writeString8(cur.mName);
reply->writeInt32(cur.mRoles.size());
for (List<String8>::iterator role_it = cur.mRoles.begin();
role_it != cur.mRoles.end(); ++role_it) {
reply->writeString8(*role_it);
}
}

return NO_ERROR;
}

case ALLOCATE_NODE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

const char *name = data.readCString();

sp<IOMXObserver> observer =
interface_cast<IOMXObserver>(data.readStrongBinder());

node_id node;

status_t err = allocateNode(name, observer, &node);
reply->writeInt32(err);
if (err == OK) {
reply->writeInt32((int32_t)node);
}

return NO_ERROR;
}

case FREE_NODE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();

reply->writeInt32(freeNode(node));

return NO_ERROR;
}

case SEND_COMMAND:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();

OMX_COMMANDTYPE cmd =
static_cast<OMX_COMMANDTYPE>(data.readInt32());

OMX_S32 param = data.readInt32();
reply->writeInt32(sendCommand(node, cmd, param));

return NO_ERROR;
}

case GET_PARAMETER:
case SET_PARAMETER:
case GET_CONFIG:
case SET_CONFIG:
case SET_INTERNAL_OPTION:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_INDEXTYPE index = static_cast<OMX_INDEXTYPE>(data.readInt32());

size_t size = data.readInt64();

status_t err = NOT_ENOUGH_DATA;

void *params = NULL;
size_t pageSize = 0;
size_t allocSize = 0;
            if ((index == (OMX_INDEXTYPE) OMX_IndexParamConsumerUsageBits && size < 4) ||
                    (code != SET_INTERNAL_OPTION && size < 8)) {
// we expect the structure to contain at least the size and
// version, 8 bytes total
                ALOGE("b/27207275 (%zu)", size);
android_errorWriteLog(0x534e4554, "27207275");
} else {
err = NO_MEMORY;
pageSize = (size_t) sysconf(_SC_PAGE_SIZE);
if (size > SIZE_MAX - (pageSize * 2)) {
ALOGE("requested param size too big");
} else {
allocSize = (size + pageSize * 2) & ~(pageSize - 1);
params = mmap(NULL, allocSize, PROT_READ | PROT_WRITE,
MAP_PRIVATE | MAP_ANONYMOUS, -1 /* fd */, 0 /* offset */);
}
if (params != MAP_FAILED) {
err = data.read(params, size);
if (err != OK) {
android_errorWriteLog(0x534e4554, "26914474");
} else {
err = NOT_ENOUGH_DATA;
OMX_U32 declaredSize = *(OMX_U32*)params;
if (code != SET_INTERNAL_OPTION &&
index != (OMX_INDEXTYPE) OMX_IndexParamConsumerUsageBits &&
declaredSize > size) {
// the buffer says it's bigger than it actually is
ALOGE("b/27207275 (%u/%zu)", declaredSize, size);
android_errorWriteLog(0x534e4554, "27207275");
} else {
// mark the last page as inaccessible, to avoid exploitation
// of codecs that access past the end of the allocation because
// they didn't check the size
mprotect((char*)params + allocSize - pageSize, pageSize, PROT_NONE);
switch (code) {
case GET_PARAMETER:
err = getParameter(node, index, params, size);
break;
case SET_PARAMETER:
err = setParameter(node, index, params, size);
break;
case GET_CONFIG:
err = getConfig(node, index, params, size);
break;
case SET_CONFIG:
err = setConfig(node, index, params, size);
break;
case SET_INTERNAL_OPTION:
{
InternalOptionType type =
(InternalOptionType)data.readInt32();

err = setInternalOption(node, index, type, params, size);
break;
}

default:
TRESPASS();
}
}
}
} else {
ALOGE("couldn't map: %s", strerror(errno));
}
}

reply->writeInt32(err);

if ((code == GET_PARAMETER || code == GET_CONFIG) && err == OK) {
reply->write(params, size);
}

if (params) {
munmap(params, allocSize);
}
params = NULL;

return NO_ERROR;
}

case GET_STATE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_STATETYPE state = OMX_StateInvalid;

status_t err = getState(node, &state);
reply->writeInt32(state);
reply->writeInt32(err);

return NO_ERROR;
}

case ENABLE_GRAPHIC_BUFFERS:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL enable = (OMX_BOOL)data.readInt32();

status_t err = enableGraphicBuffers(node, port_index, enable);
reply->writeInt32(err);

return NO_ERROR;
}

case GET_GRAPHIC_BUFFER_USAGE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();

OMX_U32 usage = 0;
status_t err = getGraphicBufferUsage(node, port_index, &usage);
reply->writeInt32(err);
reply->writeInt32(usage);

return NO_ERROR;
}

case USE_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<IMemory> params =
interface_cast<IMemory>(data.readStrongBinder());
OMX_U32 allottedSize = data.readInt32();

buffer_id buffer;
status_t err = useBuffer(node, port_index, params, &buffer, allottedSize);
reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
}

return NO_ERROR;
}

case USE_GRAPHIC_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();
data.read(*graphicBuffer);

buffer_id buffer;
status_t err = useGraphicBuffer(
node, port_index, graphicBuffer, &buffer);
reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
}

return NO_ERROR;
}

case UPDATE_GRAPHIC_BUFFER_IN_META:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();
data.read(*graphicBuffer);
buffer_id buffer = (buffer_id)data.readInt32();

status_t err = updateGraphicBufferInMeta(
node, port_index, graphicBuffer, buffer);
reply->writeInt32(err);

return NO_ERROR;
}

case CREATE_INPUT_SURFACE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();

sp<IGraphicBufferProducer> bufferProducer;
MetadataBufferType type = kMetadataBufferTypeInvalid;
status_t err = createInputSurface(node, port_index, &bufferProducer, &type);

if ((err != OK) && (type == kMetadataBufferTypeInvalid)) {
android_errorWriteLog(0x534e4554, "26324358");
}

reply->writeInt32(type);
reply->writeInt32(err);

if (err == OK) {
reply->writeStrongBinder(IInterface::asBinder(bufferProducer));
}

return NO_ERROR;
}

case CREATE_PERSISTENT_INPUT_SURFACE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

sp<IGraphicBufferProducer> bufferProducer;
sp<IGraphicBufferConsumer> bufferConsumer;
status_t err = createPersistentInputSurface(
&bufferProducer, &bufferConsumer);

reply->writeInt32(err);

if (err == OK) {
reply->writeStrongBinder(IInterface::asBinder(bufferProducer));
reply->writeStrongBinder(IInterface::asBinder(bufferConsumer));
}

return NO_ERROR;
}

case SET_INPUT_SURFACE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();

sp<IGraphicBufferConsumer> bufferConsumer =
interface_cast<IGraphicBufferConsumer>(data.readStrongBinder());

MetadataBufferType type = kMetadataBufferTypeInvalid;
status_t err = setInputSurface(node, port_index, bufferConsumer, &type);

if ((err != OK) && (type == kMetadataBufferTypeInvalid)) {
android_errorWriteLog(0x534e4554, "26324358");
}

reply->writeInt32(type);
reply->writeInt32(err);
return NO_ERROR;
}

case SIGNAL_END_OF_INPUT_STREAM:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();

status_t err = signalEndOfInputStream(node);
reply->writeInt32(err);

return NO_ERROR;
}

case STORE_META_DATA_IN_BUFFERS:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL enable = (OMX_BOOL)data.readInt32();

MetadataBufferType type = kMetadataBufferTypeInvalid;
status_t err = storeMetaDataInBuffers(node, port_index, enable, &type);

reply->writeInt32(type);
reply->writeInt32(err);

return NO_ERROR;
}

case PREPARE_FOR_ADAPTIVE_PLAYBACK:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL enable = (OMX_BOOL)data.readInt32();
OMX_U32 max_width = data.readInt32();
OMX_U32 max_height = data.readInt32();

status_t err = prepareForAdaptivePlayback(
node, port_index, enable, max_width, max_height);
reply->writeInt32(err);

return NO_ERROR;
}

case CONFIGURE_VIDEO_TUNNEL_MODE:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();
OMX_U32 audio_hw_sync = data.readInt32();

native_handle_t *sideband_handle = NULL;
status_t err = configureVideoTunnelMode(
node, port_index, tunneled, audio_hw_sync, &sideband_handle);
reply->writeInt32(err);
if(err == OK){
reply->writeNativeHandle(sideband_handle);
}

return NO_ERROR;
}

case ALLOC_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
if (!isSecure(node) || port_index != 0 /* kPortIndexInput */) {
ALOGE("b/24310423");
reply->writeInt32(INVALID_OPERATION);
return NO_ERROR;
}

size_t size = data.readInt64();

buffer_id buffer;
void *buffer_data;
status_t err = allocateBuffer(
node, port_index, size, &buffer, &buffer_data);
reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
reply->writeInt64((uintptr_t)buffer_data);
}

return NO_ERROR;
}

case ALLOC_BUFFER_WITH_BACKUP:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
sp<IMemory> params =
interface_cast<IMemory>(data.readStrongBinder());
OMX_U32 allottedSize = data.readInt32();

buffer_id buffer;
status_t err = allocateBufferWithBackup(
node, port_index, params, &buffer, allottedSize);

reply->writeInt32(err);

if (err == OK) {
reply->writeInt32((int32_t)buffer);
}

return NO_ERROR;
}

case FREE_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
OMX_U32 port_index = data.readInt32();
buffer_id buffer = (buffer_id)data.readInt32();
reply->writeInt32(freeBuffer(node, port_index, buffer));

return NO_ERROR;
}

case FILL_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
buffer_id buffer = (buffer_id)data.readInt32();
bool haveFence = data.readInt32();
int fenceFd = haveFence ? ::dup(data.readFileDescriptor()) : -1;
reply->writeInt32(fillBuffer(node, buffer, fenceFd));

return NO_ERROR;
}

case EMPTY_BUFFER:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
buffer_id buffer = (buffer_id)data.readInt32();
OMX_U32 range_offset = data.readInt32();
OMX_U32 range_length = data.readInt32();
OMX_U32 flags = data.readInt32();
OMX_TICKS timestamp = data.readInt64();
bool haveFence = data.readInt32();
int fenceFd = haveFence ? ::dup(data.readFileDescriptor()) : -1;
reply->writeInt32(emptyBuffer(
node, buffer, range_offset, range_length, flags, timestamp, fenceFd));

return NO_ERROR;
}

case GET_EXTENSION_INDEX:
{
CHECK_OMX_INTERFACE(IOMX, data, reply);

node_id node = (node_id)data.readInt32();
const char *parameter_name = data.readCString();

OMX_INDEXTYPE index;
status_t err = getExtensionIndex(node, parameter_name, &index);

reply->writeInt32(err);

if (err == OK) {
reply->writeInt32(index);
}

return OK;
}

default:
return BBinder::onTransact(code, data, reply, flags);
}
}

void ACodec::signalSubmitOutputMetadataBufferIfEOS_workaround() {
 if (mPortEOS[kPortIndexInput] && !mPortEOS[kPortIndexOutput] &&
            mMetadataBuffersToSubmit > 0) {
 (new AMessage(kWhatSubmitOutputMetadataBufferIfEOS, this))->post();
 }
}

OMX_ERRORTYPE SoftAVC::setVbvParams() {
 ive_ctl_set_vbv_params_ip_t s_vbv_ip;
 ive_ctl_set_vbv_params_op_t s_vbv_op;
    IV_STATUS_T status;

    s_vbv_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_vbv_ip.e_sub_cmd = IVE_CMD_CTL_SET_VBV_PARAMS;

    s_vbv_ip.u4_vbv_buf_size = 0;
    s_vbv_ip.u4_vbv_buffer_delay = 1000;

    s_vbv_ip.u4_timestamp_high = -1;
    s_vbv_ip.u4_timestamp_low = -1;

    s_vbv_ip.u4_size = sizeof(ive_ctl_set_vbv_params_ip_t);
    s_vbv_op.u4_size = sizeof(ive_ctl_set_vbv_params_op_t);

    status = ive_api_function(mCodecCtx, &s_vbv_ip, &s_vbv_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set VBC params = 0x%x\n", s_vbv_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

OMX_ERRORTYPE SoftAMR::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (mMode == MODE_NARROW) {
                 if (strncmp((const char *)roleParams->cRole,
                             "audio_decoder.amrnb",
                            OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }
 } else {
 if (strncmp((const char *)roleParams->cRole,
 "audio_decoder.amrwb",
                            OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAmr:
 {

             const OMX_AUDIO_PARAM_AMRTYPE *aacParams =
                 (const OMX_AUDIO_PARAM_AMRTYPE *)params;
 
             if (aacParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftAACEncoder(name, callbacks, appData, component);
}

static status_t ConvertAvcSpecLevelToOmxAvcLevel(
        WORD32 avcLevel, OMX_VIDEO_AVCLEVELTYPE *omxLevel) {
 for (size_t i = 0; i < NELEM(ConversionTable); ++i) {
 if (avcLevel == ConversionTable[i].avcLevel) {
 *omxLevel = ConversionTable[i].omxLevel;
 return OK;
 }
 }

    ALOGE("ConvertAvcSpecLevelToOmxAvcLevel: %d level not supported",
 (int32_t)avcLevel);

 return BAD_VALUE;
}

OMX_ERRORTYPE SoftVPXEncoder::setConfig(
        OMX_INDEXTYPE index, const OMX_PTR _params) {
 switch (index) {
 case OMX_IndexConfigVideoIntraVOPRefresh:
 {

             OMX_CONFIG_INTRAREFRESHVOPTYPE *params =
                 (OMX_CONFIG_INTRAREFRESHVOPTYPE *)_params;
 
             if (params->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

            mKeyFrameRequested = params->IntraRefreshVOP;
 return OMX_ErrorNone;
 }

 case OMX_IndexConfigVideoBitrate:
 {

             OMX_VIDEO_CONFIG_BITRATETYPE *params =
                 (OMX_VIDEO_CONFIG_BITRATETYPE *)_params;
 
             if (params->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

 if (mBitrate != params->nEncodeBitrate) {
                mBitrate = params->nEncodeBitrate;
                mBitrateUpdated = true;
 }
 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::setConfig(index, _params);
 }
}

bool ACodec::FlushingState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
    ALOGV("[%s] FlushingState onOMXEvent(%u,%d)",
            mCodec->mComponentName.c_str(), event, (OMX_S32)data1);

 switch (event) {
 case OMX_EventCmdComplete:
 {
 if (data1 != (OMX_U32)OMX_CommandFlush) {
                ALOGE("unexpected EventCmdComplete %s(%d) data2:%d in FlushingState",
                        asString((OMX_COMMANDTYPE)data1), data1, data2);
                mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return true;
 }

 if (data2 == kPortIndexInput || data2 == kPortIndexOutput) {
 if (mFlushComplete[data2]) {
                    ALOGW("Flush already completed for %s port",
                            data2 == kPortIndexInput ? "input" : "output");
 return true;
 }
                mFlushComplete[data2] = true;

 if (mFlushComplete[kPortIndexInput] && mFlushComplete[kPortIndexOutput]) {
                    changeStateIfWeOwnAllBuffers();
 }
 } else if (data2 == OMX_ALL) {
 if (!mFlushComplete[kPortIndexInput] || !mFlushComplete[kPortIndexOutput]) {
                    ALOGW("received flush complete event for OMX_ALL before ports have been"
 "flushed (%d/%d)",
                            mFlushComplete[kPortIndexInput], mFlushComplete[kPortIndexOutput]);
 return false;
 }

                changeStateIfWeOwnAllBuffers();
 } else {
                ALOGW("data2 not OMX_ALL but %u in EventCmdComplete CommandFlush", data2);
 }

 return true;
 }

 case OMX_EventPortSettingsChanged:
 {
            sp<AMessage> msg = new AMessage(kWhatOMXMessage, mCodec);
            msg->setInt32("type", omx_message::EVENT);
            msg->setInt32("node", mCodec->mNode);
            msg->setInt32("event", event);
            msg->setInt32("data1", data1);
            msg->setInt32("data2", data2);

            ALOGV("[%s] Deferring OMX_EventPortSettingsChanged",
                 mCodec->mComponentName.c_str());

            mCodec->deferMessage(msg);

 return true;
 }

 default:
 return BaseState::onOMXEvent(event, data1, data2);
 }

 return true;
}

status_t ACodec::setComponentRole(
 bool isEncoder, const char *mime) {
 struct MimeToRole {
 const char *mime;
 const char *decoderRole;
 const char *encoderRole;
 };

 static const MimeToRole kMimeToRole[] = {
 { MEDIA_MIMETYPE_AUDIO_MPEG,
 "audio_decoder.mp3", "audio_encoder.mp3" },
 { MEDIA_MIMETYPE_AUDIO_MPEG_LAYER_I,
 "audio_decoder.mp1", "audio_encoder.mp1" },
 { MEDIA_MIMETYPE_AUDIO_MPEG_LAYER_II,
 "audio_decoder.mp2", "audio_encoder.mp2" },
 { MEDIA_MIMETYPE_AUDIO_AMR_NB,
 "audio_decoder.amrnb", "audio_encoder.amrnb" },
 { MEDIA_MIMETYPE_AUDIO_AMR_WB,
 "audio_decoder.amrwb", "audio_encoder.amrwb" },
 { MEDIA_MIMETYPE_AUDIO_AAC,
 "audio_decoder.aac", "audio_encoder.aac" },
 { MEDIA_MIMETYPE_AUDIO_VORBIS,
 "audio_decoder.vorbis", "audio_encoder.vorbis" },
 { MEDIA_MIMETYPE_AUDIO_OPUS,
 "audio_decoder.opus", "audio_encoder.opus" },
 { MEDIA_MIMETYPE_AUDIO_G711_MLAW,
 "audio_decoder.g711mlaw", "audio_encoder.g711mlaw" },
 { MEDIA_MIMETYPE_AUDIO_G711_ALAW,
 "audio_decoder.g711alaw", "audio_encoder.g711alaw" },
 { MEDIA_MIMETYPE_VIDEO_AVC,
 "video_decoder.avc", "video_encoder.avc" },
 { MEDIA_MIMETYPE_VIDEO_HEVC,
 "video_decoder.hevc", "video_encoder.hevc" },
 { MEDIA_MIMETYPE_VIDEO_MPEG4,
 "video_decoder.mpeg4", "video_encoder.mpeg4" },
 { MEDIA_MIMETYPE_VIDEO_H263,
 "video_decoder.h263", "video_encoder.h263" },
 { MEDIA_MIMETYPE_VIDEO_VP8,
 "video_decoder.vp8", "video_encoder.vp8" },
 { MEDIA_MIMETYPE_VIDEO_VP9,
 "video_decoder.vp9", "video_encoder.vp9" },
 { MEDIA_MIMETYPE_AUDIO_RAW,
 "audio_decoder.raw", "audio_encoder.raw" },
 { MEDIA_MIMETYPE_AUDIO_FLAC,
 "audio_decoder.flac", "audio_encoder.flac" },
 { MEDIA_MIMETYPE_AUDIO_MSGSM,
 "audio_decoder.gsm", "audio_encoder.gsm" },
 { MEDIA_MIMETYPE_VIDEO_MPEG2,
 "video_decoder.mpeg2", "video_encoder.mpeg2" },
 { MEDIA_MIMETYPE_AUDIO_AC3,
 "audio_decoder.ac3", "audio_encoder.ac3" },
 { MEDIA_MIMETYPE_AUDIO_EAC3,
 "audio_decoder.eac3", "audio_encoder.eac3" },
 };

 static const size_t kNumMimeToRole =
 sizeof(kMimeToRole) / sizeof(kMimeToRole[0]);

 size_t i;
 for (i = 0; i < kNumMimeToRole; ++i) {
 if (!strcasecmp(mime, kMimeToRole[i].mime)) {
 break;
 }
 }

 if (i == kNumMimeToRole) {
 return ERROR_UNSUPPORTED;
 }

 const char *role =
        isEncoder ? kMimeToRole[i].encoderRole
 : kMimeToRole[i].decoderRole;

 if (role != NULL) {
        OMX_PARAM_COMPONENTROLETYPE roleParams;
 InitOMXParams(&roleParams);

        strncpy((char *)roleParams.cRole,
                role, OMX_MAX_STRINGNAME_SIZE - 1);

        roleParams.cRole[OMX_MAX_STRINGNAME_SIZE - 1] = '\0';

 status_t err = mOMX->setParameter(
                mNode, OMX_IndexParamStandardComponentRole,
 &roleParams, sizeof(roleParams));

 if (err != OK) {
            ALOGW("[%s] Failed to set standard component role '%s'.",
                 mComponentName.c_str(), role);

 return err;
 }
 }

 return OK;
}

status_t ACodec::setupMPEG4EncoderParameters(const sp<AMessage> &msg) {
 int32_t bitrate, iFrameInterval;
 if (!msg->findInt32("bitrate", &bitrate)
 || !msg->findInt32("i-frame-interval", &iFrameInterval)) {
 return INVALID_OPERATION;
 }

    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);

 float frameRate;
 if (!msg->findFloat("frame-rate", &frameRate)) {
 int32_t tmp;
 if (!msg->findInt32("frame-rate", &tmp)) {
 return INVALID_OPERATION;
 }
        frameRate = (float)tmp;
 }

    OMX_VIDEO_PARAM_MPEG4TYPE mpeg4type;
 InitOMXParams(&mpeg4type);
    mpeg4type.nPortIndex = kPortIndexOutput;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamVideoMpeg4, &mpeg4type, sizeof(mpeg4type));

 if (err != OK) {
 return err;
 }

    mpeg4type.nSliceHeaderSpacing = 0;
    mpeg4type.bSVH = OMX_FALSE;
    mpeg4type.bGov = OMX_FALSE;

    mpeg4type.nAllowedPictureTypes =
        OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP;

    mpeg4type.nPFrames = setPFramesSpacing(iFrameInterval, frameRate);
 if (mpeg4type.nPFrames == 0) {
        mpeg4type.nAllowedPictureTypes = OMX_VIDEO_PictureTypeI;
 }
    mpeg4type.nBFrames = 0;
    mpeg4type.nIDCVLCThreshold = 0;
    mpeg4type.bACPred = OMX_TRUE;
    mpeg4type.nMaxPacketSize = 256;
    mpeg4type.nTimeIncRes = 1000;
    mpeg4type.nHeaderExtension = 0;
    mpeg4type.bReversibleVLC = OMX_FALSE;

 int32_t profile;
 if (msg->findInt32("profile", &profile)) {
 int32_t level;
 if (!msg->findInt32("level", &level)) {
 return INVALID_OPERATION;
 }

        err = verifySupportForProfileAndLevel(profile, level);

 if (err != OK) {
 return err;
 }

        mpeg4type.eProfile = static_cast<OMX_VIDEO_MPEG4PROFILETYPE>(profile);
        mpeg4type.eLevel = static_cast<OMX_VIDEO_MPEG4LEVELTYPE>(level);
 }

    err = mOMX->setParameter(
            mNode, OMX_IndexParamVideoMpeg4, &mpeg4type, sizeof(mpeg4type));

 if (err != OK) {
 return err;
 }

    err = configureBitrate(bitrate, bitrateMode);

 if (err != OK) {
 return err;
 }

 return setupErrorCorrectionParameters();
}

uint32_t SoftVideoDecoderOMXComponent::outputBufferWidth() {
 return mIsAdaptive ? mAdaptiveMaxWidth : mWidth;
}

void SoftAAC2::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError || mOutputPortSettingsChange != NONE) {
 return;
 }

    UCHAR* inBuffer[FILEREAD_MAX_LAYERS];
    UINT inBufferLength[FILEREAD_MAX_LAYERS] = {0};
    UINT bytesValid[FILEREAD_MAX_LAYERS] = {0};

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 while ((!inQueue.empty() || mEndOfInput) && !outQueue.empty()) {
 if (!inQueue.empty()) {
            INT_PCM tmpOutBuffer[2048 * MAX_CHANNEL_COUNT];
 BufferInfo *inInfo = *inQueue.begin();
            OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

            mEndOfInput = (inHeader->nFlags & OMX_BUFFERFLAG_EOS) != 0;

 if (mInputBufferCount == 0 && !(inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG)) {
                ALOGE("first buffer should have OMX_BUFFERFLAG_CODECCONFIG set");
                inHeader->nFlags |= OMX_BUFFERFLAG_CODECCONFIG;
 }
 if ((inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) != 0) {
 BufferInfo *inInfo = *inQueue.begin();
                OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

                inBuffer[0] = inHeader->pBuffer + inHeader->nOffset;
                inBufferLength[0] = inHeader->nFilledLen;

                AAC_DECODER_ERROR decoderErr =
                    aacDecoder_ConfigRaw(mAACDecoder,
                                         inBuffer,
                                         inBufferLength);

 if (decoderErr != AAC_DEC_OK) {
                    ALOGW("aacDecoder_ConfigRaw decoderErr = 0x%4.4x", decoderErr);
                    mSignalledError = true;
                    notify(OMX_EventError, OMX_ErrorUndefined, decoderErr, NULL);
 return;
 }

                mInputBufferCount++;
                mOutputBufferCount++; // fake increase of outputBufferCount to keep the counters aligned

                inInfo->mOwnedByUs = false;
                inQueue.erase(inQueue.begin());
                mLastInHeader = NULL;
                inInfo = NULL;
                notifyEmptyBufferDone(inHeader);
                inHeader = NULL;

                configureDownmix();
 if (mStreamInfo->sampleRate && mStreamInfo->numChannels) {
                    ALOGI("Initially configuring decoder: %d Hz, %d channels",
                        mStreamInfo->sampleRate,
                        mStreamInfo->numChannels);

                    notify(OMX_EventPortSettingsChanged, 1, 0, NULL);
                    mOutputPortSettingsChange = AWAITING_DISABLED;
 }
 return;
 }

 if (inHeader->nFilledLen == 0) {
                inInfo->mOwnedByUs = false;
                inQueue.erase(inQueue.begin());
                mLastInHeader = NULL;
                inInfo = NULL;
                notifyEmptyBufferDone(inHeader);
                inHeader = NULL;
 continue;
 }

 if (mIsADTS) {
 size_t adtsHeaderSize = 0;

 const uint8_t *adtsHeader = inHeader->pBuffer + inHeader->nOffset;

 bool signalError = false;
 if (inHeader->nFilledLen < 7) {
                    ALOGE("Audio data too short to contain even the ADTS header. "
 "Got %d bytes.", inHeader->nFilledLen);
                    hexdump(adtsHeader, inHeader->nFilledLen);
                    signalError = true;
 } else {
 bool protectionAbsent = (adtsHeader[1] & 1);

 unsigned aac_frame_length =
 ((adtsHeader[3] & 3) << 11)
 | (adtsHeader[4] << 3)
 | (adtsHeader[5] >> 5);

 if (inHeader->nFilledLen < aac_frame_length) {
                        ALOGE("Not enough audio data for the complete frame. "
 "Got %d bytes, frame size according to the ADTS "
 "header is %u bytes.",
                                inHeader->nFilledLen, aac_frame_length);
                        hexdump(adtsHeader, inHeader->nFilledLen);
                        signalError = true;
 } else {
                        adtsHeaderSize = (protectionAbsent ? 7 : 9);

                        inBuffer[0] = (UCHAR *)adtsHeader + adtsHeaderSize;
                        inBufferLength[0] = aac_frame_length - adtsHeaderSize;

                        inHeader->nOffset += adtsHeaderSize;
                        inHeader->nFilledLen -= adtsHeaderSize;
 }
 }

 if (signalError) {
                    mSignalledError = true;
                    notify(OMX_EventError, OMX_ErrorStreamCorrupt, ERROR_MALFORMED, NULL);
 return;
 }

                mBufferSizes.add(inBufferLength[0]);
 if (mLastInHeader != inHeader) {
                    mBufferTimestamps.add(inHeader->nTimeStamp);
                    mLastInHeader = inHeader;
 } else {
 int64_t currentTime = mBufferTimestamps.top();
                    currentTime += mStreamInfo->aacSamplesPerFrame *
 1000000ll / mStreamInfo->aacSampleRate;
                    mBufferTimestamps.add(currentTime);
 }
 } else {
                inBuffer[0] = inHeader->pBuffer + inHeader->nOffset;
                inBufferLength[0] = inHeader->nFilledLen;
                mLastInHeader = inHeader;
                mBufferTimestamps.add(inHeader->nTimeStamp);
                mBufferSizes.add(inHeader->nFilledLen);
 }

            bytesValid[0] = inBufferLength[0];

            INT prevSampleRate = mStreamInfo->sampleRate;
            INT prevNumChannels = mStreamInfo->numChannels;

            aacDecoder_Fill(mAACDecoder,
                            inBuffer,
                            inBufferLength,
                            bytesValid);

            mDrcWrap.submitStreamData(mStreamInfo);
            mDrcWrap.update();

            UINT inBufferUsedLength = inBufferLength[0] - bytesValid[0];
            inHeader->nFilledLen -= inBufferUsedLength;
            inHeader->nOffset += inBufferUsedLength;

            AAC_DECODER_ERROR decoderErr;
 int numLoops = 0;
 do {
 if (outputDelayRingBufferSpaceLeft() <
 (mStreamInfo->frameSize * mStreamInfo->numChannels)) {
                    ALOGV("skipping decode: not enough space left in ringbuffer");
 break;
 }

 int numConsumed = mStreamInfo->numTotalBytes;
                decoderErr = aacDecoder_DecodeFrame(mAACDecoder,
                                           tmpOutBuffer,
 2048 * MAX_CHANNEL_COUNT,
 0 /* flags */);

                numConsumed = mStreamInfo->numTotalBytes - numConsumed;
                numLoops++;

 if (decoderErr == AAC_DEC_NOT_ENOUGH_BITS) {
 break;
 }
                mDecodedSizes.add(numConsumed);

 if (decoderErr != AAC_DEC_OK) {
                    ALOGW("aacDecoder_DecodeFrame decoderErr = 0x%4.4x", decoderErr);
 }

 if (bytesValid[0] != 0) {
                    ALOGE("bytesValid[0] != 0 should never happen");
                    mSignalledError = true;
                    notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }

 size_t numOutBytes =
                    mStreamInfo->frameSize * sizeof(int16_t) * mStreamInfo->numChannels;

 if (decoderErr == AAC_DEC_OK) {
 if (!outputDelayRingBufferPutSamples(tmpOutBuffer,
                            mStreamInfo->frameSize * mStreamInfo->numChannels)) {
                        mSignalledError = true;
                        notify(OMX_EventError, OMX_ErrorUndefined, decoderErr, NULL);
 return;
 }
 } else {
                    ALOGW("AAC decoder returned error 0x%4.4x, substituting silence", decoderErr);

                    memset(tmpOutBuffer, 0, numOutBytes); // TODO: check for overflow

 if (!outputDelayRingBufferPutSamples(tmpOutBuffer,
                            mStreamInfo->frameSize * mStreamInfo->numChannels)) {
                        mSignalledError = true;
                        notify(OMX_EventError, OMX_ErrorUndefined, decoderErr, NULL);
 return;
 }

 if (inHeader) {
                        inHeader->nFilledLen = 0;
 }

                    aacDecoder_SetParam(mAACDecoder, AAC_TPDEC_CLEAR_BUFFER, 1);

                    mBufferSizes.pop();
 int n = 0;
 for (int i = 0; i < numLoops; i++) {
                        n += mDecodedSizes.itemAt(mDecodedSizes.size() - numLoops + i);
 }
                    mBufferSizes.add(n);

 }

 /*
                 * AAC+/eAAC+ streams can be signalled in two ways: either explicitly
                 * or implicitly, according to MPEG4 spec. AAC+/eAAC+ is a dual
                 * rate system and the sampling rate in the final output is actually
                 * doubled compared with the core AAC decoder sampling rate.
                 *
                 * Explicit signalling is done by explicitly defining SBR audio object
                 * type in the bitstream. Implicit signalling is done by embedding
                 * SBR content in AAC extension payload specific to SBR, and hence
                 * requires an AAC decoder to perform pre-checks on actual audio frames.
                 *
                 * Thus, we could not say for sure whether a stream is
                 * AAC+/eAAC+ until the first data frame is decoded.
                 */
 if (mInputBufferCount <= 2 || mOutputBufferCount > 1) { // TODO: <= 1
 if (mStreamInfo->sampleRate != prevSampleRate ||
                        mStreamInfo->numChannels != prevNumChannels) {
                        ALOGI("Reconfiguring decoder: %d->%d Hz, %d->%d channels",
                              prevSampleRate, mStreamInfo->sampleRate,
                              prevNumChannels, mStreamInfo->numChannels);

                        notify(OMX_EventPortSettingsChanged, 1, 0, NULL);
                        mOutputPortSettingsChange = AWAITING_DISABLED;

 if (inHeader && inHeader->nFilledLen == 0) {
                            inInfo->mOwnedByUs = false;
                            mInputBufferCount++;
                            inQueue.erase(inQueue.begin());
                            mLastInHeader = NULL;
                            inInfo = NULL;
                            notifyEmptyBufferDone(inHeader);
                            inHeader = NULL;
 }
 return;
 }
 } else if (!mStreamInfo->sampleRate || !mStreamInfo->numChannels) {
                    ALOGW("Invalid AAC stream");
                    mSignalledError = true;
                    notify(OMX_EventError, OMX_ErrorUndefined, decoderErr, NULL);
 return;
 }
 if (inHeader && inHeader->nFilledLen == 0) {
                    inInfo->mOwnedByUs = false;
                    mInputBufferCount++;
                    inQueue.erase(inQueue.begin());
                    mLastInHeader = NULL;
                    inInfo = NULL;
                    notifyEmptyBufferDone(inHeader);
                    inHeader = NULL;
 } else {
                    ALOGV("inHeader->nFilledLen = %d", inHeader ? inHeader->nFilledLen : 0);
 }
 } while (decoderErr == AAC_DEC_OK);
 }

 int32_t outputDelay = mStreamInfo->outputDelay * mStreamInfo->numChannels;

 if (!mEndOfInput && mOutputDelayCompensated < outputDelay) {
 int32_t toCompensate = outputDelay - mOutputDelayCompensated;
 int32_t discard = outputDelayRingBufferSamplesAvailable();
 if (discard > toCompensate) {
                discard = toCompensate;
 }
 int32_t discarded = outputDelayRingBufferGetSamples(0, discard);
            mOutputDelayCompensated += discarded;
 continue;
 }

 if (mEndOfInput) {
 while (mOutputDelayCompensated > 0) {
                INT_PCM tmpOutBuffer[2048 * MAX_CHANNEL_COUNT];
 
                 mDrcWrap.submitStreamData(mStreamInfo);
                 mDrcWrap.update();

                AAC_DECODER_ERROR decoderErr =
                    aacDecoder_DecodeFrame(mAACDecoder,
                                           tmpOutBuffer,
 2048 * MAX_CHANNEL_COUNT,
                                           AACDEC_FLUSH);
 if (decoderErr != AAC_DEC_OK) {
                    ALOGW("aacDecoder_DecodeFrame decoderErr = 0x%4.4x", decoderErr);
 }

 int32_t tmpOutBufferSamples = mStreamInfo->frameSize * mStreamInfo->numChannels;
 if (tmpOutBufferSamples > mOutputDelayCompensated) {
                    tmpOutBufferSamples = mOutputDelayCompensated;
 }
                outputDelayRingBufferPutSamples(tmpOutBuffer, tmpOutBufferSamples);
                mOutputDelayCompensated -= tmpOutBufferSamples;
 }
 }

 while (!outQueue.empty()
 && outputDelayRingBufferSamplesAvailable()
 >= mStreamInfo->frameSize * mStreamInfo->numChannels) {
 BufferInfo *outInfo = *outQueue.begin();
            OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 if (outHeader->nOffset != 0) {
                ALOGE("outHeader->nOffset != 0 is not handled");
                mSignalledError = true;
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }

            INT_PCM *outBuffer =
 reinterpret_cast<INT_PCM *>(outHeader->pBuffer + outHeader->nOffset);
 int samplesize = mStreamInfo->numChannels * sizeof(int16_t);
 if (outHeader->nOffset
 + mStreamInfo->frameSize * samplesize
 > outHeader->nAllocLen) {
                ALOGE("buffer overflow");
                mSignalledError = true;
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;

 }

 int available = outputDelayRingBufferSamplesAvailable();
 int numSamples = outHeader->nAllocLen / sizeof(int16_t);
 if (numSamples > available) {
                numSamples = available;
 }
 int64_t currentTime = 0;
 if (available) {

 int numFrames = numSamples / (mStreamInfo->frameSize * mStreamInfo->numChannels);
                numSamples = numFrames * (mStreamInfo->frameSize * mStreamInfo->numChannels);

                ALOGV("%d samples available (%d), or %d frames",
                        numSamples, available, numFrames);
 int64_t *nextTimeStamp = &mBufferTimestamps.editItemAt(0);
                currentTime = *nextTimeStamp;
 int32_t *currentBufLeft = &mBufferSizes.editItemAt(0);
 for (int i = 0; i < numFrames; i++) {
 int32_t decodedSize = mDecodedSizes.itemAt(0);
                    mDecodedSizes.removeAt(0);
                    ALOGV("decoded %d of %d", decodedSize, *currentBufLeft);
 if (*currentBufLeft > decodedSize) {
 *currentBufLeft -= decodedSize;
 *nextTimeStamp += mStreamInfo->aacSamplesPerFrame *
 1000000ll / mStreamInfo->aacSampleRate;
                        ALOGV("adjusted nextTimeStamp/size to %lld/%d",
 (long long) *nextTimeStamp, *currentBufLeft);
 } else {
 if (mBufferTimestamps.size() > 0) {
                            mBufferTimestamps.removeAt(0);
                            nextTimeStamp = &mBufferTimestamps.editItemAt(0);
                            mBufferSizes.removeAt(0);
                            currentBufLeft = &mBufferSizes.editItemAt(0);
                            ALOGV("moved to next time/size: %lld/%d",
 (long long) *nextTimeStamp, *currentBufLeft);
 }
                        numFrames = i + 1;
                        numSamples = numFrames * mStreamInfo->frameSize * mStreamInfo->numChannels;
 break;
 }
 }

                ALOGV("getting %d from ringbuffer", numSamples);
 int32_t ns = outputDelayRingBufferGetSamples(outBuffer, numSamples);
 if (ns != numSamples) {
                    ALOGE("not a complete frame of samples available");
                    mSignalledError = true;
                    notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 }

            outHeader->nFilledLen = numSamples * sizeof(int16_t);

 if (mEndOfInput && !outQueue.empty() && outputDelayRingBufferSamplesAvailable() == 0) {
                outHeader->nFlags = OMX_BUFFERFLAG_EOS;
                mEndOfOutput = true;
 } else {
                outHeader->nFlags = 0;
 }

            outHeader->nTimeStamp = currentTime;

            mOutputBufferCount++;
            outInfo->mOwnedByUs = false;
            outQueue.erase(outQueue.begin());
            outInfo = NULL;
            ALOGV("out timestamp %lld / %d", outHeader->nTimeStamp, outHeader->nFilledLen);
            notifyFillBufferDone(outHeader);
            outHeader = NULL;
 }

 if (mEndOfInput) {
 int ringBufAvail = outputDelayRingBufferSamplesAvailable();
 if (!outQueue.empty()
 && ringBufAvail < mStreamInfo->frameSize * mStreamInfo->numChannels) {
 if (!mEndOfOutput) {
                    mEndOfOutput = true;
 BufferInfo *outInfo = *outQueue.begin();
                    OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

                    INT_PCM *outBuffer = reinterpret_cast<INT_PCM *>(outHeader->pBuffer
 + outHeader->nOffset);
 int32_t ns = outputDelayRingBufferGetSamples(outBuffer, ringBufAvail);
 if (ns < 0) {
                        ns = 0;
 }
                    outHeader->nFilledLen = ns;
                    outHeader->nFlags = OMX_BUFFERFLAG_EOS;

                    outHeader->nTimeStamp = mBufferTimestamps.itemAt(0);
                    mBufferTimestamps.clear();
                    mBufferSizes.clear();
                    mDecodedSizes.clear();

                    mOutputBufferCount++;
                    outInfo->mOwnedByUs = false;
                    outQueue.erase(outQueue.begin());
                    outInfo = NULL;
                    notifyFillBufferDone(outHeader);
                    outHeader = NULL;
 }
 break; // if outQueue not empty but no more output
 }
 }
 }
}

SoftAVC::SoftAVC(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SoftVideoEncoderOMXComponent(
            name, "video_encoder.avc", OMX_VIDEO_CodingAVC,
            kProfileLevels, NELEM(kProfileLevels),
 176 /* width */, 144 /* height */,
            callbacks, appData, component),
      mBitrateUpdated(false),
      mKeyFrameRequested(false),
      mIvVideoColorFormat(IV_YUV_420P),
      mAVCEncProfile(IV_PROFILE_BASE),
      mAVCEncLevel(41),
      mStarted(false),
      mSawInputEOS(false),
      mSawOutputEOS(false),
      mSignalledError(false),
      mCodecCtx(NULL) {

    initPorts(kNumBuffers, kNumBuffers, ((mWidth * mHeight * 3) >> 1),
            MEDIA_MIMETYPE_VIDEO_AVC, 2);

    GENERATE_FILE_NAMES();
    CREATE_DUMP_FILE(mInFile);
    CREATE_DUMP_FILE(mOutFile);
    memset(mConversionBuffers, 0, sizeof(mConversionBuffers));
    memset(mInputBufferInfo, 0, sizeof(mInputBufferInfo));

    initEncParams();

}

 virtual void binderDied(const wp<IBinder> &) {
        mNotify->post();
 }

OMX_ERRORTYPE SoftVideoDecoderOMXComponent::getConfig(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexConfigCommonOutputCrop:

         {
             OMX_CONFIG_RECTTYPE *rectParams = (OMX_CONFIG_RECTTYPE *)params;
 
             if (rectParams->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorUndefined;
             }

            rectParams->nLeft = mCropLeft;
            rectParams->nTop = mCropTop;
            rectParams->nWidth = mCropWidth;
            rectParams->nHeight = mCropHeight;

 return OMX_ErrorNone;
 }

 default:
 return OMX_ErrorUnsupportedIndex;
 }
}

OMX_ERRORTYPE SoftAACEncoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_encoder.aac",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPortFormat:
 {

             const OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (const OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

 if ((formatParams->nPortIndex == 0
 && formatParams->eEncoding != OMX_AUDIO_CodingPCM)
 || (formatParams->nPortIndex == 1
 && formatParams->eEncoding != OMX_AUDIO_CodingAAC)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {

             OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
                 (OMX_AUDIO_PARAM_AACPROFILETYPE *)params;
 
             if (aacParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            mBitRate = aacParams->nBitRate;
            mNumChannels = aacParams->nChannels;
            mSampleRate = aacParams->nSampleRate;

 if (setAudioParams() != OK) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            mNumChannels = pcmParams->nChannels;
            mSampleRate = pcmParams->nSamplingRate;

 if (setAudioParams() != OK) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }


 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

bool ACodec::ExecutingToIdleState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case kWhatFlush:
 {
            ALOGW("Ignoring flush request in ExecutingToIdleState");
 break;
 }

 case kWhatShutdown:
 {

            handled = true;
 break;
 }

 default:
            handled = BaseState::onMessageReceived(msg);
 break;
 }

 return handled;
}

OMX_ERRORTYPE SoftAVC::setGopParams() {
    IV_STATUS_T status;
 ive_ctl_set_gop_params_ip_t s_gop_params_ip;
 ive_ctl_set_gop_params_op_t s_gop_params_op;

    s_gop_params_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_gop_params_ip.e_sub_cmd = IVE_CMD_CTL_SET_GOP_PARAMS;

    s_gop_params_ip.u4_i_frm_interval = mIInterval;
    s_gop_params_ip.u4_idr_frm_interval = mIDRInterval;

    s_gop_params_ip.u4_timestamp_high = -1;
    s_gop_params_ip.u4_timestamp_low = -1;

    s_gop_params_ip.u4_size = sizeof(ive_ctl_set_gop_params_ip_t);
    s_gop_params_op.u4_size = sizeof(ive_ctl_set_gop_params_op_t);

    status = ive_api_function(mCodecCtx, &s_gop_params_ip, &s_gop_params_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set ME params = 0x%x\n",
                s_gop_params_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

SoftAACEncoder::SoftAACEncoder(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mEncoderHandle(NULL),
      mApiHandle(NULL),
      mMemOperator(NULL),
      mNumChannels(1),
      mSampleRate(44100),
      mBitRate(0),
      mSentCodecSpecificData(false),
      mInputSize(0),
      mInputFrame(NULL),
      mInputTimeUs(-1ll),
      mSawInputEOS(false),
      mSignalledError(false) {
    initPorts();
    CHECK_EQ(initEncoder(), (status_t)OK);

    setAudioParams();
}

status_t ACodec::freeBuffer(OMX_U32 portIndex, size_t i) {
 BufferInfo *info = &mBuffers[portIndex].editItemAt(i);
 status_t err = OK;

 MetadataBufferType type =
        portIndex == kPortIndexOutput ? mOutputMetadataType : mInputMetadataType;
 if (type == kMetadataBufferTypeANWBuffer && info->mData != NULL
 && info->mData->size() >= sizeof(VideoNativeMetadata)) {
 int fenceFd = ((VideoNativeMetadata *)info->mData->data())->nFenceFd;
 if (fenceFd >= 0) {
            ALOGW("unreleased fence (%d) in %s metadata buffer %zu",
                    fenceFd, portIndex == kPortIndexInput ? "input" : "output", i);
 }
 }

 switch (info->mStatus) {
 case BufferInfo::OWNED_BY_US:
 if (portIndex == kPortIndexOutput && mNativeWindow != NULL) {
 (void)cancelBufferToNativeWindow(info);
 }

 case BufferInfo::OWNED_BY_NATIVE_WINDOW:
            err = mOMX->freeBuffer(mNode, portIndex, info->mBufferID);
 break;

 default:
            ALOGE("trying to free buffer not owned by us or ANW (%d)", info->mStatus);
            err = FAILED_TRANSACTION;
 break;
 }

 if (info->mFenceFd >= 0) {
 ::close(info->mFenceFd);
 }

 if (portIndex == kPortIndexOutput) {
        mRenderTracker.untrackFrame(info->mRenderInfo, i);
        info->mRenderInfo = NULL;
 }

    mBuffers[portIndex].removeAt(i);
 return err;
}

void ACodec::IdleToLoadedState::stateEntered() {
    ALOGV("[%s] Now Idle->Loaded", mCodec->mComponentName.c_str());
}

OMX_ERRORTYPE SoftAVC::internalSetParameter(OMX_INDEXTYPE index, const OMX_PTR params) {
int32_t indexFull = index;


switch (indexFull) {
case OMX_IndexParamVideoBitrate:
{
            return internalSetBitrateParams(
                    (const OMX_VIDEO_PARAM_BITRATETYPE *)params);
}

case OMX_IndexParamVideoAvc:
{
OMX_VIDEO_PARAM_AVCTYPE *avcType = (OMX_VIDEO_PARAM_AVCTYPE *)params;

if (avcType->nPortIndex != 1) {
return OMX_ErrorUndefined;
}

mEntropyMode = 0;

if (OMX_TRUE == avcType->bEntropyCodingCABAC)
mEntropyMode = 1;

if ((avcType->nAllowedPictureTypes & OMX_VIDEO_PictureTypeB) &&
avcType->nPFrames) {
mBframes = avcType->nBFrames / avcType->nPFrames;
}

mIInterval = avcType->nPFrames + avcType->nBFrames;

if (OMX_VIDEO_AVCLoopFilterDisable == avcType->eLoopFilterMode)
mDisableDeblkLevel = 4;

if (avcType->nRefFrames != 1
|| avcType->bUseHadamard != OMX_TRUE
|| avcType->nRefIdx10ActiveMinus1 != 0
|| avcType->nRefIdx11ActiveMinus1 != 0
|| avcType->bWeightedPPrediction != OMX_FALSE
|| avcType->bconstIpred != OMX_FALSE
|| avcType->bDirect8x8Inference != OMX_FALSE
|| avcType->bDirectSpatialTemporal != OMX_FALSE
|| avcType->nCabacInitIdc != 0) {
return OMX_ErrorUndefined;
}

if (OK != ConvertOmxAvcLevelToAvcSpecLevel(avcType->eLevel, &mAVCEncLevel)) {
return OMX_ErrorUndefined;
}

return OMX_ErrorNone;
}

default:
return SoftVideoEncoderOMXComponent::internalSetParameter(index, params);
}
}

bool ACodec::LoadedToIdleState::onMessageReceived(const sp<AMessage> &msg) {
 switch (msg->what()) {
 case kWhatSetParameters:
 case kWhatShutdown:
 {
            mCodec->deferMessage(msg);
 return true;
 }

 case kWhatSignalEndOfInputStream:
 {
            mCodec->onSignalEndOfInputStream();
 return true;
 }

 case kWhatResume:
 {
 return true;
 }

 case kWhatFlush:
 {
            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatFlushCompleted);
            notify->post();
 return true;
 }

 default:
 return BaseState::onMessageReceived(msg);
 }
}

OMX_ERRORTYPE SoftAVC::setMeParams() {
    IV_STATUS_T status;
 ive_ctl_set_me_params_ip_t s_me_params_ip;
 ive_ctl_set_me_params_op_t s_me_params_op;

    s_me_params_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_me_params_ip.e_sub_cmd = IVE_CMD_CTL_SET_ME_PARAMS;

    s_me_params_ip.u4_enable_fast_sad = mEnableFastSad;
    s_me_params_ip.u4_enable_alt_ref = mEnableAltRef;

    s_me_params_ip.u4_enable_hpel = mHalfPelEnable;
    s_me_params_ip.u4_enable_qpel = DEFAULT_QPEL;
    s_me_params_ip.u4_me_speed_preset = DEFAULT_ME_SPEED;
    s_me_params_ip.u4_srch_rng_x = DEFAULT_SRCH_RNG_X;
    s_me_params_ip.u4_srch_rng_y = DEFAULT_SRCH_RNG_Y;

    s_me_params_ip.u4_timestamp_high = -1;
    s_me_params_ip.u4_timestamp_low = -1;

    s_me_params_ip.u4_size = sizeof(ive_ctl_set_me_params_ip_t);
    s_me_params_op.u4_size = sizeof(ive_ctl_set_me_params_op_t);

    status = ive_api_function(mCodecCtx, &s_me_params_ip, &s_me_params_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set me params = 0x%x\n", s_me_params_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

static status_t ConvertOmxAvcLevelToAvcSpecLevel(
        OMX_VIDEO_AVCLEVELTYPE omxLevel, WORD32 *avcLevel) {
 for (size_t i = 0; i < NELEM(ConversionTable); ++i) {
 if (omxLevel == ConversionTable[i].omxLevel) {
 *avcLevel = ConversionTable[i].avcLevel;
 return OK;
 }
 }

    ALOGE("ConvertOmxAvcLevelToAvcSpecLevel: %d level not supported",
 (int32_t)omxLevel);

 return BAD_VALUE;
}

OMX_ERRORTYPE SoftAVC::setEncMode(IVE_ENC_MODE_T e_enc_mode) {
    IV_STATUS_T status;
 ive_ctl_set_enc_mode_ip_t s_enc_mode_ip;
 ive_ctl_set_enc_mode_op_t s_enc_mode_op;

    s_enc_mode_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_enc_mode_ip.e_sub_cmd = IVE_CMD_CTL_SET_ENC_MODE;

    s_enc_mode_ip.e_enc_mode = e_enc_mode;

    s_enc_mode_ip.u4_timestamp_high = -1;
    s_enc_mode_ip.u4_timestamp_low = -1;

    s_enc_mode_ip.u4_size = sizeof(ive_ctl_set_enc_mode_ip_t);
    s_enc_mode_op.u4_size = sizeof(ive_ctl_set_enc_mode_op_t);

    status = ive_api_function(mCodecCtx, &s_enc_mode_ip, &s_enc_mode_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set in header encode mode = 0x%x\n",
                s_enc_mode_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

SoftFlacEncoder::~SoftFlacEncoder() {
    ALOGV("SoftFlacEncoder::~SoftFlacEncoder()");
 if (mFlacStreamEncoder != NULL) {
        FLAC__stream_encoder_delete(mFlacStreamEncoder);
        mFlacStreamEncoder = NULL;
 }
    free(mInputBufferPcm32);
    mInputBufferPcm32 = NULL;
}

OMX_ERRORTYPE SoftRaw::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.raw",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            mChannelCount = pcmParams->nChannels;
            mSampleRate = pcmParams->nSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftAVC::setAirParams() {
 ive_ctl_set_air_params_ip_t s_air_ip;
 ive_ctl_set_air_params_op_t s_air_op;
    IV_STATUS_T status;

    s_air_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_air_ip.e_sub_cmd = IVE_CMD_CTL_SET_AIR_PARAMS;

    s_air_ip.e_air_mode = mAIRMode;
    s_air_ip.u4_air_refresh_period = mAIRRefreshPeriod;

    s_air_ip.u4_timestamp_high = -1;
    s_air_ip.u4_timestamp_low = -1;

    s_air_ip.u4_size = sizeof(ive_ctl_set_air_params_ip_t);
    s_air_op.u4_size = sizeof(ive_ctl_set_air_params_op_t);

    status = ive_api_function(mCodecCtx, &s_air_ip, &s_air_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set air params = 0x%x\n", s_air_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

void ACodec::updateRenderInfoForDequeuedBuffer(
 ANativeWindowBuffer *buf, int fenceFd, BufferInfo *info) {

    info->mRenderInfo =
        mRenderTracker.updateInfoForDequeuedBuffer(
                buf, fenceFd, info - &mBuffers[kPortIndexOutput][0]);

    notifyOfRenderedFrames(false /* dropIncomplete */, info->mRenderInfo);
}

 virtual status_t setInputSurface(
            node_id node, OMX_U32 port_index,
 const sp<IGraphicBufferConsumer> &bufferConsumer, MetadataBufferType *type) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
 status_t err;
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeStrongBinder(IInterface::asBinder(bufferConsumer));

        err = remote()->transact(SET_INPUT_SURFACE, data, &reply);

 if (err != OK) {
            ALOGW("binder transaction failed: %d", err);
 return err;
 }

 int negotiatedType = reply.readInt32();
 if (type != NULL) {
 *type = (MetadataBufferType)negotiatedType;
 }

 return reply.readInt32();
 }

void ACodec::FlushingState::onOutputBufferDrained(const sp<AMessage> &msg) {
 BaseState::onOutputBufferDrained(msg);

    changeStateIfWeOwnAllBuffers();
}

static int32_t BindFrameWrapper(
 void *userData, int32_t index, uint8_t **yuv) {
 SoftAVCEncoder *encoder = static_cast<SoftAVCEncoder *>(userData);
    CHECK(encoder != NULL);
 return encoder->bindOutputBuffer(index, yuv);
}

status_t ACodec::submitOutputMetadataBuffer() {
    CHECK(storingMetadataInDecodedBuffers());
 if (mMetadataBuffersToSubmit == 0)
 return OK;

 BufferInfo *info = dequeueBufferFromNativeWindow();
 if (info == NULL) {
 return ERROR_IO;
 }

    ALOGV("[%s] submitting output meta buffer ID %u for graphic buffer %p",
          mComponentName.c_str(), info->mBufferID, info->mGraphicBuffer.get());

 --mMetadataBuffersToSubmit;
    info->checkWriteFence("submitOutputMetadataBuffer");
 status_t err = mOMX->fillBuffer(mNode, info->mBufferID, info->mFenceFd);
    info->mFenceFd = -1;
 if (err == OK) {
        info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
 }

 return err;
}

 virtual ~DeathNotifier() {}

void ACodec::FlushingState::changeStateIfWeOwnAllBuffers() {
 if (mFlushComplete[kPortIndexInput]
 && mFlushComplete[kPortIndexOutput]
 && mCodec->allYourBuffersAreBelongToUs()) {
        mCodec->waitUntilAllPossibleNativeWindowBuffersAreReturnedToUs();

        mCodec->mRenderTracker.clear(systemTime(CLOCK_MONOTONIC));

        sp<AMessage> notify = mCodec->mNotify->dup();
        notify->setInt32("what", CodecBase::kWhatFlushCompleted);
        notify->post();

        mCodec->mPortEOS[kPortIndexInput] =
            mCodec->mPortEOS[kPortIndexOutput] = false;

        mCodec->mInputEOSResult = OK;

 if (mCodec->mSkipCutBuffer != NULL) {
            mCodec->mSkipCutBuffer->clear();
 }

        mCodec->changeState(mCodec->mExecutingState);
 }
}

bool ACodec::ExecutingState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case kWhatShutdown:
 {
 int32_t keepComponentAllocated;
            CHECK(msg->findInt32(
 "keepComponentAllocated", &keepComponentAllocated));

            mCodec->mShutdownInProgress = true;
            mCodec->mExplicitShutdown = true;
            mCodec->mKeepComponentAllocated = keepComponentAllocated;

            mActive = false;

 status_t err = mCodec->mOMX->sendCommand(
                    mCodec->mNode, OMX_CommandStateSet, OMX_StateIdle);
 if (err != OK) {
 if (keepComponentAllocated) {
                    mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 }
 } else {
                mCodec->changeState(mCodec->mExecutingToIdleState);
 }

            handled = true;
 break;
 }

 case kWhatFlush:
 {
            ALOGV("[%s] ExecutingState flushing now "
 "(codec owns %zu/%zu input, %zu/%zu output).",
                    mCodec->mComponentName.c_str(),
                    mCodec->countBuffersOwnedByComponent(kPortIndexInput),
                    mCodec->mBuffers[kPortIndexInput].size(),
                    mCodec->countBuffersOwnedByComponent(kPortIndexOutput),
                    mCodec->mBuffers[kPortIndexOutput].size());

            mActive = false;

 status_t err = mCodec->mOMX->sendCommand(mCodec->mNode, OMX_CommandFlush, OMX_ALL);
 if (err != OK) {
                mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 } else {
                mCodec->changeState(mCodec->mFlushingState);
 }

            handled = true;
 break;
 }

 case kWhatResume:
 {
            resume();

            handled = true;
 break;
 }

 case kWhatRequestIDRFrame:
 {
 status_t err = mCodec->requestIDRFrame();
 if (err != OK) {
                ALOGW("Requesting an IDR frame failed.");
 }

            handled = true;
 break;
 }

 case kWhatSetParameters:
 {
            sp<AMessage> params;
            CHECK(msg->findMessage("params", &params));

 status_t err = mCodec->setParameters(params);

            sp<AMessage> reply;
 if (msg->findMessage("reply", &reply)) {
                reply->setInt32("err", err);
                reply->post();
 }

            handled = true;
 break;
 }

 case ACodec::kWhatSignalEndOfInputStream:
 {
            mCodec->onSignalEndOfInputStream();
            handled = true;
 break;
 }

 case kWhatSubmitOutputMetadataBufferIfEOS:
 {
 if (mCodec->mPortEOS[kPortIndexInput] &&
 !mCodec->mPortEOS[kPortIndexOutput]) {
 status_t err = mCodec->submitOutputMetadataBuffer();
 if (err == OK) {
                    mCodec->signalSubmitOutputMetadataBufferIfEOS_workaround();
 }
 }
 return true;
 }

 default:
            handled = BaseState::onMessageReceived(msg);
 break;
 }

 return handled;
}

void SoftAMRNBEncoder::initPorts() {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);

    def.nPortIndex = 0;
    def.eDir = OMX_DirInput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = kNumSamplesPerFrame * sizeof(int16_t);
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 1;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);

    def.nPortIndex = 1;
    def.eDir = OMX_DirOutput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 8192;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 2;

    def.format.audio.cMIMEType = const_cast<char *>("audio/3gpp");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingAMR;

    addPort(def);
}

SoftRaw::SoftRaw(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mSignalledError(false),
      mChannelCount(2),
      mSampleRate(44100) {
    initPorts();
    CHECK_EQ(initDecoder(), (status_t)OK);
}

void SoftVideoDecoderOMXComponent::handlePortSettingsChange(
 bool *portWillReset, uint32_t width, uint32_t height,
 CropSettingsMode cropSettingsMode, bool fakeStride) {
 *portWillReset = false;
 bool sizeChanged = (width != mWidth || height != mHeight);
 bool updateCrop = (cropSettingsMode == kCropUnSet);
 bool cropChanged = (cropSettingsMode == kCropChanged);
 bool strideChanged = false;
 if (fakeStride) {
        OMX_PARAM_PORTDEFINITIONTYPE *def = &editPortInfo(kOutputPortIndex)->mDef;
 if (def->format.video.nStride != (OMX_S32)width
 || def->format.video.nSliceHeight != (OMX_U32)height) {
            strideChanged = true;
 }
 }

 if (sizeChanged || cropChanged || strideChanged) {
        mWidth = width;
        mHeight = height;

 if ((sizeChanged && !mIsAdaptive)
 || width > mAdaptiveMaxWidth
 || height > mAdaptiveMaxHeight) {
 if (mIsAdaptive) {
 if (width > mAdaptiveMaxWidth) {
                    mAdaptiveMaxWidth = width;
 }
 if (height > mAdaptiveMaxHeight) {
                    mAdaptiveMaxHeight = height;
 }
 }
            updatePortDefinitions(updateCrop);
            notify(OMX_EventPortSettingsChanged, kOutputPortIndex, 0, NULL);
            mOutputPortSettingsChange = AWAITING_DISABLED;
 *portWillReset = true;
 } else {
            updatePortDefinitions(updateCrop);

 if (fakeStride) {
                OMX_PARAM_PORTDEFINITIONTYPE *def = &editPortInfo(kOutputPortIndex)->mDef;
                def->format.video.nStride = mWidth;
                def->format.video.nSliceHeight = mHeight;
 }

            notify(OMX_EventPortSettingsChanged, kOutputPortIndex,
                   OMX_IndexConfigCommonOutputCrop, NULL);
 }
 }
}

void ACodec::processDeferredMessages() {
 List<sp<AMessage> > queue = mDeferredQueue;
    mDeferredQueue.clear();

 List<sp<AMessage> >::iterator it = queue.begin();
 while (it != queue.end()) {
        onMessageReceived(*it++);
 }
}

OMX_ERRORTYPE SoftMPEG4Encoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 int32_t indexFull = index;

 switch (indexFull) {
 case OMX_IndexParamVideoBitrate:
 {

             OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *) params;
 
             if (bitRate->nPortIndex != 1 ||
                 bitRate->eControlRate != OMX_Video_ControlRateVariable) {
                 return OMX_ErrorUndefined;
 }

            mBitrate = bitRate->nTargetBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoH263:
 {

             OMX_VIDEO_PARAM_H263TYPE *h263type =
                 (OMX_VIDEO_PARAM_H263TYPE *)params;
 
             if (h263type->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (h263type->eProfile != OMX_VIDEO_H263ProfileBaseline ||
                h263type->eLevel != OMX_VIDEO_H263Level45 ||
 (h263type->nAllowedPictureTypes & OMX_VIDEO_PictureTypeB) ||
                h263type->bPLUSPTYPEAllowed != OMX_FALSE ||
                h263type->bForceRoundingTypeToZero != OMX_FALSE ||
                h263type->nPictureHeaderRepetition != 0 ||
                h263type->nGOBHeaderInterval != 0) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoMpeg4:
 {

             OMX_VIDEO_PARAM_MPEG4TYPE *mpeg4type =
                 (OMX_VIDEO_PARAM_MPEG4TYPE *)params;
 
             if (mpeg4type->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (mpeg4type->eProfile != OMX_VIDEO_MPEG4ProfileCore ||
                mpeg4type->eLevel != OMX_VIDEO_MPEG4Level2 ||
 (mpeg4type->nAllowedPictureTypes & OMX_VIDEO_PictureTypeB) ||
                mpeg4type->nBFrames != 0 ||
                mpeg4type->nIDCVLCThreshold != 0 ||
                mpeg4type->bACPred != OMX_TRUE ||
                mpeg4type->nMaxPacketSize != 256 ||
                mpeg4type->nTimeIncRes != 1000 ||
                mpeg4type->nHeaderExtension != 0 ||
                mpeg4type->bReversibleVLC != OMX_FALSE) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalSetParameter(index, params);
 }
}

OMX_ERRORTYPE SoftAVC::internalSetBitrateParams(
 const OMX_VIDEO_PARAM_BITRATETYPE *bitrate) {
 if (bitrate->nPortIndex != kOutputPortIndex) {
 return OMX_ErrorUnsupportedIndex;
 }

    mBitrate = bitrate->nTargetBitrate;
    mBitrateUpdated = true;

 return OMX_ErrorNone;
}

bool ACodec::OutputPortSettingsChangedState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
 switch (event) {
 case OMX_EventCmdComplete:
 {
 if (data1 == (OMX_U32)OMX_CommandPortDisable) {
 if (data2 != (OMX_U32)kPortIndexOutput) {
                    ALOGW("ignoring EventCmdComplete CommandPortDisable for port %u", data2);
 return false;
 }

                ALOGV("[%s] Output port now disabled.", mCodec->mComponentName.c_str());

 status_t err = OK;
 if (!mCodec->mBuffers[kPortIndexOutput].isEmpty()) {
                    ALOGE("disabled port should be empty, but has %zu buffers",
                            mCodec->mBuffers[kPortIndexOutput].size());
                    err = FAILED_TRANSACTION;
 } else {
                    mCodec->mDealer[kPortIndexOutput].clear();
 }

 if (err == OK) {
                    err = mCodec->mOMX->sendCommand(
                            mCodec->mNode, OMX_CommandPortEnable, kPortIndexOutput);
 }

 if (err == OK) {
                    err = mCodec->allocateBuffersOnPort(kPortIndexOutput);
                    ALOGE_IF(err != OK, "Failed to allocate output port buffers after port "
 "reconfiguration: (%d)", err);
 }

 if (err != OK) {
                    mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));

                    mCodec->mShutdownInProgress = true;
                    mCodec->mKeepComponentAllocated = false;
                    mCodec->changeState(mCodec->mLoadedState);
 }

 return true;
 } else if (data1 == (OMX_U32)OMX_CommandPortEnable) {
 if (data2 != (OMX_U32)kPortIndexOutput) {
                    ALOGW("ignoring EventCmdComplete OMX_CommandPortEnable for port %u", data2);
 return false;
 }

                mCodec->mSentFormat = false;

 if (mCodec->mTunneled) {
                    sp<AMessage> dummy = new AMessage(kWhatOutputBufferDrained, mCodec);
                    mCodec->sendFormatChange(dummy);
 }

                ALOGV("[%s] Output port now reenabled.", mCodec->mComponentName.c_str());

 if (mCodec->mExecutingState->active()) {
                    mCodec->mExecutingState->submitOutputBuffers();
 }

                mCodec->changeState(mCodec->mExecutingState);

 return true;
 }

 return false;
 }

 default:
 return false;
 }
}

void SoftAMRWBEncoder::initPorts() {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);

    def.nPortIndex = 0;
    def.eDir = OMX_DirInput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = kNumSamplesPerFrame * sizeof(int16_t);
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 1;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);

    def.nPortIndex = 1;
    def.eDir = OMX_DirOutput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 8192;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 2;

    def.format.audio.cMIMEType = const_cast<char *>("audio/amr-wb");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingAMR;

    addPort(def);
}

status_t ACodec::waitForFence(int fd, const char *dbg ) {
 status_t res = OK;
 if (fd >= 0) {
        sp<Fence> fence = new Fence(fd);
        res = fence->wait(IOMX::kFenceTimeoutMs);
        ALOGW_IF(res != OK, "FENCE TIMEOUT for %d in %s", fd, dbg);
 }
 return res;
}

ACodec::FlushingState::FlushingState(ACodec *codec)
 : BaseState(codec) {
}

android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftRaw(name, callbacks, appData, component);
}

 virtual status_t getConfig(
            node_id node, OMX_INDEXTYPE index,
 void *params, size_t size) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(index);
        data.writeInt64(size);
        data.write(params, size);
        remote()->transact(GET_CONFIG, data, &reply);

 status_t err = reply.readInt32();
 if (err != OK) {
 return err;
 }

        reply.read(params, size);

 return OK;
 }

static status_t ConvertAvcSpecLevelToOmxAvcLevel(
 AVCLevel avcLevel, OMX_U32 *omxLevel) {
 for (size_t i = 0, n = sizeof(ConversionTable)/sizeof(ConversionTable[0]);
        i < n; ++i) {
 if (avcLevel == ConversionTable[i].avcLevel) {
 *omxLevel = ConversionTable[i].omxLevel;
 return OK;
 }
 }

    ALOGE("ConvertAvcSpecLevelToOmxAvcLevel: %d level not supported",
 (int32_t) avcLevel);

 return BAD_VALUE;
}

OMX_ERRORTYPE SoftOpus::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.opus",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAndroidOpus:
 {

             const OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *opusParams =
                 (const OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *)params;
 
             if (opusParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

int32_t SoftAVCEncoder::bindOutputBuffer(int32_t index, uint8_t **yuv) {
    CHECK(index >= 0);
    CHECK(index < (int32_t) mOutputBuffers.size());
 *yuv = (uint8_t *) mOutputBuffers[index]->data();

 return 1;
}

status_t ACodec::verifySupportForProfileAndLevel(
 int32_t profile, int32_t level) {
    OMX_VIDEO_PARAM_PROFILELEVELTYPE params;
 InitOMXParams(&params);
    params.nPortIndex = kPortIndexOutput;

 for (params.nProfileIndex = 0;; ++params.nProfileIndex) {
 status_t err = mOMX->getParameter(
                mNode,
                OMX_IndexParamVideoProfileLevelQuerySupported,
 &params,
 sizeof(params));

 if (err != OK) {
 return err;
 }

 int32_t supportedProfile = static_cast<int32_t>(params.eProfile);
 int32_t supportedLevel = static_cast<int32_t>(params.eLevel);

 if (profile == supportedProfile && level <= supportedLevel) {
 return OK;
 }
 }
}

void ACodec::BaseState::onOutputBufferDrained(const sp<AMessage> &msg) {
    IOMX::buffer_id bufferID;
    CHECK(msg->findInt32("buffer-id", (int32_t*)&bufferID));
 ssize_t index;
 BufferInfo *info = mCodec->findBufferByID(kPortIndexOutput, bufferID, &index);
 BufferInfo::Status status = BufferInfo::getSafeStatus(info);
 if (status != BufferInfo::OWNED_BY_DOWNSTREAM) {
        ALOGE("Wrong ownership in OBD: %s(%d) buffer #%u", _asString(status), status, bufferID);
        mCodec->dumpBuffers(kPortIndexOutput);
        mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return;
 }

 android_native_rect_t crop;
 if (msg->findRect("crop", &crop.left, &crop.top, &crop.right, &crop.bottom)) {
 status_t err = native_window_set_crop(mCodec->mNativeWindow.get(), &crop);
        ALOGW_IF(err != NO_ERROR, "failed to set crop: %d", err);
 }

 int32_t render;
 if (mCodec->mNativeWindow != NULL
 && msg->findInt32("render", &render) && render != 0
 && info->mData != NULL && info->mData->size() != 0) {
        ATRACE_NAME("render");

 int64_t mediaTimeUs = -1;
        info->mData->meta()->findInt64("timeUs", &mediaTimeUs);
 if (mediaTimeUs >= 0) {
            mCodec->mRenderTracker.onFrameQueued(
                    mediaTimeUs, info->mGraphicBuffer, new Fence(::dup(info->mFenceFd)));
 }

 int64_t timestampNs = 0;
 if (!msg->findInt64("timestampNs", &timestampNs)) {
 if (info->mData->meta()->findInt64("timeUs", &timestampNs)) {
                ALOGV("using buffer PTS of %lld", (long long)timestampNs);
                timestampNs *= 1000;
 }
 }

 status_t err;
        err = native_window_set_buffers_timestamp(mCodec->mNativeWindow.get(), timestampNs);
        ALOGW_IF(err != NO_ERROR, "failed to set buffer timestamp: %d", err);

        info->checkReadFence("onOutputBufferDrained before queueBuffer");
        err = mCodec->mNativeWindow->queueBuffer(
                    mCodec->mNativeWindow.get(), info->mGraphicBuffer.get(), info->mFenceFd);
        info->mFenceFd = -1;
 if (err == OK) {
            info->mStatus = BufferInfo::OWNED_BY_NATIVE_WINDOW;
 } else {
            ALOGE("queueBuffer failed in onOutputBufferDrained: %d", err);
            mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));
            info->mStatus = BufferInfo::OWNED_BY_US;
            info->mIsReadFence = false;
 }
 } else {
 if (mCodec->mNativeWindow != NULL &&
 (info->mData == NULL || info->mData->size() != 0)) {
            info->mIsReadFence = false;
            ATRACE_NAME("frame-drop");
 }
        info->mStatus = BufferInfo::OWNED_BY_US;
 }

 PortMode mode = getPortMode(kPortIndexOutput);

 switch (mode) {
 case KEEP_BUFFERS:
 {

 if (info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW) {

                info = mCodec->dequeueBufferFromNativeWindow();
 }
 break;
 }

 case RESUBMIT_BUFFERS:
 {
 if (!mCodec->mPortEOS[kPortIndexOutput]) {
 if (info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW) {

                    info = mCodec->dequeueBufferFromNativeWindow();
 }

 if (info != NULL) {
                    ALOGV("[%s] calling fillBuffer %u",
                         mCodec->mComponentName.c_str(), info->mBufferID);
                    info->checkWriteFence("onOutputBufferDrained::RESUBMIT_BUFFERS");
 status_t err = mCodec->mOMX->fillBuffer(
                            mCodec->mNode, info->mBufferID, info->mFenceFd);
                    info->mFenceFd = -1;
 if (err == OK) {
                        info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
 } else {
                        mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));
 }
 }
 }
 break;
 }

 case FREE_BUFFERS:
 {
 status_t err = mCodec->freeBuffer(kPortIndexOutput, index);
 if (err != OK) {
                mCodec->signalError(OMX_ErrorUndefined, makeNoSideEffectStatus(err));
 }
 break;
 }

 default:
            ALOGE("Invalid port mode: %d", mode);
 return;
 }
}

OMX_ERRORTYPE SoftVPXEncoder::internalSetParameter(OMX_INDEXTYPE index,
const OMX_PTR param) {
// can include extension index OMX_INDEXEXTTYPE

const int32_t indexFull = index;

switch (indexFull) {
        case OMX_IndexParamVideoBitrate:
            return internalSetBitrateParams(
                (const OMX_VIDEO_PARAM_BITRATETYPE *)param);

        case OMX_IndexParamVideoVp8:
            return internalSetVp8Params(
                (const OMX_VIDEO_PARAM_VP8TYPE *)param);

        case OMX_IndexParamVideoAndroidVp8Encoder:
            return internalSetAndroidVp8Params(
                (const OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE *)param);

default:
return SoftVideoEncoderOMXComponent::internalSetParameter(index, param);
}
}

status_t ACodec::selectAudioPortFormat(
        OMX_U32 portIndex, OMX_AUDIO_CODINGTYPE desiredFormat) {
    OMX_AUDIO_PARAM_PORTFORMATTYPE format;
 InitOMXParams(&format);

    format.nPortIndex = portIndex;
 for (OMX_U32 index = 0;; ++index) {
        format.nIndex = index;

 status_t err = mOMX->getParameter(
                mNode, OMX_IndexParamAudioPortFormat,
 &format, sizeof(format));

 if (err != OK) {
 return err;
 }

 if (format.eEncoding == desiredFormat) {
 break;
 }
 }

 return mOMX->setParameter(
            mNode, OMX_IndexParamAudioPortFormat, &format, sizeof(format));
}

ACodec::BufferInfo *ACodec::findBufferByID(
 uint32_t portIndex, IOMX::buffer_id bufferID, ssize_t *index) {
 for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
 BufferInfo *info = &mBuffers[portIndex].editItemAt(i);

 if (info->mBufferID == bufferID) {
 if (index != NULL) {
 *index = i;
 }
 return info;
 }
 }

    ALOGE("Could not find buffer with ID %u", bufferID);
 return NULL;
}

void ACodec::ExecutingState::resume() {
 if (mActive) {
        ALOGV("[%s] We're already active, no need to resume.", mCodec->mComponentName.c_str());
 return;
 }

    submitOutputBuffers();

 if (mCodec->mBuffers[kPortIndexInput].size() == 0u) {
        ALOGW("[%s] we don't have any input buffers to resume", mCodec->mComponentName.c_str());
 }

 for (size_t i = 0; i < mCodec->mBuffers[kPortIndexInput].size(); i++) {
 BufferInfo *info = &mCodec->mBuffers[kPortIndexInput].editItemAt(i);
 if (info->mStatus == BufferInfo::OWNED_BY_US) {
            postFillThisBuffer(info);
 }
 }

    mActive = true;
}

void SoftAVC::logVersion() {
 ive_ctl_getversioninfo_ip_t s_ctl_ip;
 ive_ctl_getversioninfo_op_t s_ctl_op;
    UWORD8 au1_buf[512];
    IV_STATUS_T status;

    s_ctl_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVE_CMD_CTL_GETVERSION;
    s_ctl_ip.u4_size = sizeof(ive_ctl_getversioninfo_ip_t);
    s_ctl_op.u4_size = sizeof(ive_ctl_getversioninfo_op_t);
    s_ctl_ip.pu1_version = au1_buf;
    s_ctl_ip.u4_version_bufsize = sizeof(au1_buf);

    status = ive_api_function(mCodecCtx, (void *) &s_ctl_ip, (void *) &s_ctl_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in getting version: 0x%x", s_ctl_op.u4_error_code);
 } else {
        ALOGV("Ittiam encoder version: %s", (char *)s_ctl_ip.pu1_version);
 }
 return;
}

SoftFlacEncoder::SoftFlacEncoder(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mSignalledError(false),
      mNumChannels(1),
      mSampleRate(44100),
      mCompressionLevel(FLAC_COMPRESSION_LEVEL_DEFAULT),
      mEncoderWriteData(false),
      mEncoderReturnedEncodedData(false),
      mEncoderReturnedNbBytes(0),
      mInputBufferPcm32(NULL)
#ifdef WRITE_FLAC_HEADER_IN_FIRST_BUFFER
 , mHeaderOffset(0)
 , mWroteHeader(false)
#endif
{
    ALOGV("SoftFlacEncoder::SoftFlacEncoder(name=%s)", name);
    initPorts();

    mFlacStreamEncoder = FLAC__stream_encoder_new();
 if (mFlacStreamEncoder == NULL) {
        ALOGE("SoftFlacEncoder::SoftFlacEncoder(name=%s) error instantiating FLAC encoder", name);
        mSignalledError = true;
 }

 if (!mSignalledError) { // no use allocating input buffer if we had an error above
        mInputBufferPcm32 = (FLAC__int32*) malloc(sizeof(FLAC__int32) * 2 * kMaxNumSamplesPerFrame);
 if (mInputBufferPcm32 == NULL) {
            ALOGE("SoftFlacEncoder::SoftFlacEncoder(name=%s) error allocating internal input buffer", name);
            mSignalledError = true;
 }
 }
}
