void CheckFakeData(uint8* audio_data, int frames_written,
                     double playback_rate) {
    size_t length =
        (frames_written * algorithm_.bytes_per_frame())
        / algorithm_.bytes_per_channel();
    switch (algorithm_.bytes_per_channel()) {
      case 4:
        DoCheckFakeData<int32>(audio_data, length);
        break;
      case 2:
        DoCheckFakeData<int16>(audio_data, length);
        break;
      case 1:
        DoCheckFakeData<uint8>(audio_data, length);
        break;
      default:
        NOTREACHED() << "Unsupported audio bit depth in crossfade.";
    }
  }

void EnqueueData() {
scoped_array<uint8> audio_data(new uint8[kRawDataSize]);
CHECK_EQ(kRawDataSize % algorithm_.bytes_per_channel(), 0u);
CHECK_EQ(kRawDataSize % algorithm_.bytes_per_frame(), 0u);
    size_t length = kRawDataSize / algorithm_.bytes_per_channel();
    switch (algorithm_.bytes_per_channel()) {
      case 4:
        WriteFakeData<int32>(audio_data.get(), length);
        break;
      case 2:
        WriteFakeData<int16>(audio_data.get(), length);
        break;
      case 1:
        WriteFakeData<uint8>(audio_data.get(), length);
        break;
      default:
        NOTREACHED() << "Unsupported audio bit depth in crossfade.";
    }
algorithm_.EnqueueBuffer(new DataBuffer(audio_data.Pass(), kRawDataSize));
bytes_enqueued_ += kRawDataSize;
}

void TestPlaybackRate(double playback_rate,
int buffer_size_in_frames,
int total_frames_requested) {
int initial_bytes_enqueued = bytes_enqueued_;
int initial_bytes_buffered = algorithm_.bytes_buffered();

algorithm_.SetPlaybackRate(static_cast<float>(playback_rate));

scoped_array<uint8> buffer(
new uint8[buffer_size_in_frames * algorithm_.bytes_per_frame()]);

if (playback_rate == 0.0) {
int frames_written =
algorithm_.FillBuffer(buffer.get(), buffer_size_in_frames);
EXPECT_EQ(0, frames_written);
return;
}

int frames_remaining = total_frames_requested;
while (frames_remaining > 0) {
int frames_requested = std::min(buffer_size_in_frames, frames_remaining);
int frames_written =
algorithm_.FillBuffer(buffer.get(), frames_requested);
      CHECK_GT(frames_written, 0);
      CheckFakeData(buffer.get(), frames_written, playback_rate);
frames_remaining -= frames_written;
}

int bytes_requested = total_frames_requested * algorithm_.bytes_per_frame();
int bytes_consumed = ComputeConsumedBytes(initial_bytes_enqueued,
initial_bytes_buffered);

// If playing back at normal speed, we should always get back the same
// number of bytes requested.
if (playback_rate == 1.0) {
EXPECT_EQ(bytes_requested, bytes_consumed);
return;
}

// Otherwise, allow |kMaxAcceptableDelta| difference between the target and
// actual playback rate.
// When |kSamplesPerSecond| and |total_frames_requested| are reasonably
// large, one can expect less than a 1% difference in most cases. In our
// current implementation, sped up playback is less accurate than slowed
// down playback, and for playback_rate > 1, playback rate generally gets
// less and less accurate the farther it drifts from 1 (though this is
// nonlinear).
static const double kMaxAcceptableDelta = 0.01;
double actual_playback_rate = 1.0 * bytes_consumed / bytes_requested;

// Calculate the percentage difference from the target |playback_rate| as a
// fraction from 0.0 to 1.0.
double delta = std::abs(1.0 - (actual_playback_rate / playback_rate));

EXPECT_LE(delta, kMaxAcceptableDelta);
}

int AudioRendererAlgorithm::FillBuffer(
uint8* dest, int requested_frames) {
DCHECK_NE(bytes_per_frame_, 0);

if (playback_rate_ == 0.0f)
return 0;

int total_frames_rendered = 0;
uint8* output_ptr = dest;
while (total_frames_rendered < requested_frames) {
if (index_into_window_ == window_size_)
ResetWindow();

bool rendered_frame = true;
    if (playback_rate_ > 1.0)
      rendered_frame = OutputFasterPlayback(output_ptr);
    else if (playback_rate_ < 1.0)
      rendered_frame = OutputSlowerPlayback(output_ptr);
    else
rendered_frame = OutputNormalPlayback(output_ptr);

if (!rendered_frame) {
needs_more_data_ = true;
break;
}

output_ptr += bytes_per_frame_;
total_frames_rendered++;
}
return total_frames_rendered;
}

  AudioRendererAlgorithmTest()
      : bytes_enqueued_(0) {
  }

void Initialize() {
    Initialize(kDefaultChannelLayout, kDefaultSampleBits);
}

void AudioRendererAlgorithm::CopyWithoutAdvance(uint8* dest) {
  CopyWithoutAdvance(dest, 0);
}

void AudioRendererAlgorithm::CopyWithoutAdvance(
    uint8* dest, int offset) {
  if (muted_) {
    memset(dest, 0, bytes_per_frame_);
    return;
  }
  int copied = audio_buffer_.Peek(dest, bytes_per_frame_, offset);
  DCHECK_EQ(bytes_per_frame_, copied);
}

bool AudioRendererAlgorithm::OutputSlowerPlayback(uint8* dest) {
DCHECK_LT(index_into_window_, window_size_);
DCHECK_LT(playback_rate_, 1.0);
DCHECK_NE(playback_rate_, 0.0);

if (audio_buffer_.forward_bytes() < bytes_per_frame_)
return false;

// The audio data is output in a series of windows. For slowed down playback,
// the window is comprised of the following phases:
//
//  a) Output raw data.
//  b) Output and save bytes for crossfade in |crossfade_buffer_|.
//  c) Output* raw data.
//  d) Output* crossfaded audio leading up to the next window.
//
// * Phases c) and d) do not progress |audio_buffer_|'s cursor so that the
// |audio_buffer_|'s cursor is in the correct place for the next window.
//
// The duration of each phase is computed below based on the |window_size_|
// and |playback_rate_|.
  int input_step = ceil(window_size_ * playback_rate_);
  AlignToFrameBoundary(&input_step);
  int output_step = window_size_;
  DCHECK_LT(input_step, output_step);
int bytes_to_crossfade = bytes_in_crossfade_;
if (muted_ || bytes_to_crossfade > input_step)
bytes_to_crossfade = 0;

// This is the index of the end of phase a, beginning of phase b.
int intro_crossfade_begin = input_step - bytes_to_crossfade;

// This is the index of the end of phase b, beginning of phase c.
int intro_crossfade_end = input_step;

// This is the index of the end of phase c,  beginning of phase d.
// This phase continues until |index_into_window_| reaches |window_size_|, at
// which point the window restarts.
int outtro_crossfade_begin = output_step - bytes_to_crossfade;

// a) Output a raw frame.
if (index_into_window_ < intro_crossfade_begin) {
CopyWithAdvance(dest);
index_into_window_ += bytes_per_frame_;
return true;
}

// b) Save the raw frame for the intro crossfade section, then output the
//    frame to |dest|.
if (index_into_window_ < intro_crossfade_end) {
int offset = index_into_window_ - intro_crossfade_begin;
uint8* place_to_copy = crossfade_buffer_.get() + offset;
CopyWithoutAdvance(place_to_copy);
CopyWithAdvance(dest);
index_into_window_ += bytes_per_frame_;
return true;
}

int audio_buffer_offset = index_into_window_ - intro_crossfade_end;

if (audio_buffer_.forward_bytes() < audio_buffer_offset + bytes_per_frame_)
return false;

// c) Output a raw frame into |dest| without advancing the |audio_buffer_|
//    cursor. See function-level comment.
DCHECK_GE(index_into_window_, intro_crossfade_end);
CopyWithoutAdvance(dest, audio_buffer_offset);

// d) Crossfade the next frame of |crossfade_buffer_| into |dest| if we've
//    reached the outtro crossfade section of the window.
if (index_into_window_ >= outtro_crossfade_begin) {
int offset_into_crossfade_buffer =
index_into_window_ - outtro_crossfade_begin;
uint8* intro_frame_ptr =
crossfade_buffer_.get() + offset_into_crossfade_buffer;
OutputCrossfadedFrame(dest, intro_frame_ptr);
}

index_into_window_ += bytes_per_frame_;
return true;
}

void DoCheckFakeData(uint8* audio_data, size_t length) {
    Type* output = reinterpret_cast<Type*>(audio_data);
    for (size_t i = 0; i < length; i++) {
      EXPECT_TRUE(algorithm_.is_muted() || output[i] != 0);
    }
}

void AudioRendererAlgorithm::FlushBuffers() {
  ResetWindow();

  audio_buffer_.Clear();
  request_read_cb_.Run();
}

bool AudioRendererAlgorithm::CanFillBuffer() {
  return audio_buffer_.forward_bytes() > 0 && !needs_more_data_;
}

void AudioRendererAlgorithm::SetPlaybackRate(float new_rate) {
  DCHECK_GE(new_rate, 0.0);
  playback_rate_ = new_rate;
  muted_ =
      playback_rate_ < kMinPlaybackRate || playback_rate_ > kMaxPlaybackRate;

  ResetWindow();
}

void AudioRendererAlgorithm::EnqueueBuffer(Buffer* buffer_in) {
  DCHECK(!buffer_in->IsEndOfStream());
  audio_buffer_.Append(buffer_in);
  needs_more_data_ = false;

  if (!IsQueueFull())
    request_read_cb_.Run();
}

void WriteFakeData(uint8* audio_data, size_t length) {
    Type* output = reinterpret_cast<Type*>(audio_data);
    for (size_t i = 0; i < length; i++) {
      // The value of the data is meaningless; we just want non-zero data to
      // differentiate it from muted data.
      output[i] = i % 5 + 10;
    }
  }

int AudioRendererAlgorithm::QueueCapacity() {
  return audio_buffer_.forward_capacity();
}

void AudioRendererAlgorithm::CopyWithAdvance(uint8* dest) {
  CopyWithoutAdvance(dest);
  DropFrame();
}

void AudioRendererAlgorithm::ResetWindow() {
  DCHECK_LE(index_into_window_, window_size_);
  index_into_window_ = 0;
   crossfade_frame_number_ = 0;
 }

base::TimeDelta AudioRendererAlgorithm::GetTime() {
  return audio_buffer_.current_time();
}

bool AudioRendererAlgorithm::OutputFasterPlayback(uint8* dest) {
DCHECK_LT(index_into_window_, window_size_);
DCHECK_GT(playback_rate_, 1.0);

if (audio_buffer_.forward_bytes() < bytes_per_frame_)
return false;

// The audio data is output in a series of windows. For sped-up playback,
// the window is comprised of the following phases:
//
//  a) Output raw data.
//  b) Save bytes for crossfade in |crossfade_buffer_|.
//  c) Drop data.
//  d) Output crossfaded audio leading up to the next window.
//
// The duration of each phase is computed below based on the |window_size_|
// and |playback_rate_|.
  int input_step = window_size_;
  int output_step = ceil(window_size_ / playback_rate_);
  AlignToFrameBoundary(&output_step);
  DCHECK_GT(input_step, output_step);
int bytes_to_crossfade = bytes_in_crossfade_;
if (muted_ || bytes_to_crossfade > output_step)
bytes_to_crossfade = 0;

// This is the index of the end of phase a, beginning of phase b.
int outtro_crossfade_begin = output_step - bytes_to_crossfade;

// This is the index of the end of phase b, beginning of phase c.
int outtro_crossfade_end = output_step;

// This is the index of the end of phase c, beginning of phase d.
// This phase continues until |index_into_window_| reaches |window_size_|, at
// which point the window restarts.
int intro_crossfade_begin = input_step - bytes_to_crossfade;

// a) Output a raw frame if we haven't reached the crossfade section.
if (index_into_window_ < outtro_crossfade_begin) {
CopyWithAdvance(dest);
index_into_window_ += bytes_per_frame_;
return true;
}

// b) Save outtro crossfade frames into intermediate buffer, but do not output
//    anything to |dest|.
while (index_into_window_ < outtro_crossfade_end) {
if (audio_buffer_.forward_bytes() < bytes_per_frame_)
return false;

// This phase only applies if there are bytes to crossfade.
DCHECK_GT(bytes_to_crossfade, 0);
uint8* place_to_copy = crossfade_buffer_.get() +
(index_into_window_ - outtro_crossfade_begin);
CopyWithAdvance(place_to_copy);
index_into_window_ += bytes_per_frame_;
}

// c) Drop frames until we reach the intro crossfade section.
while (index_into_window_ < intro_crossfade_begin) {
if (audio_buffer_.forward_bytes() < bytes_per_frame_)
return false;

DropFrame();
index_into_window_ += bytes_per_frame_;
}

// Return if we have run out of data after Phase c).
if (audio_buffer_.forward_bytes() < bytes_per_frame_)
return false;

// Phase d) doesn't apply if there are no bytes to crossfade.
if (bytes_to_crossfade == 0) {
DCHECK_EQ(index_into_window_, window_size_);
return false;
}

// d) Crossfade and output a frame.
DCHECK_LT(index_into_window_, window_size_);
int offset_into_buffer = index_into_window_ - intro_crossfade_begin;
memcpy(dest, crossfade_buffer_.get() + offset_into_buffer,
bytes_per_frame_);
scoped_array<uint8> intro_frame_ptr(new uint8[bytes_per_frame_]);
audio_buffer_.Read(intro_frame_ptr.get(), bytes_per_frame_);
OutputCrossfadedFrame(dest, intro_frame_ptr.get());
index_into_window_ += bytes_per_frame_;
return true;
}

void AudioRendererAlgorithm::Initialize(float initial_playback_rate,
                                        const AudioParameters& params,
                                        const base::Closure& callback) {
  CHECK(params.IsValid());
  DCHECK(!callback.is_null());

  channels_ = params.channels();
  samples_per_second_ = params.sample_rate();
  bytes_per_channel_ = params.bits_per_sample() / 8;
  bytes_per_frame_ = params.GetBytesPerFrame();
  request_read_cb_ = callback;
  SetPlaybackRate(initial_playback_rate);

  window_size_ =
      samples_per_second_ * bytes_per_channel_ * channels_ * kWindowDuration;
  AlignToFrameBoundary(&window_size_);

  bytes_in_crossfade_ =
      samples_per_second_ * bytes_per_channel_ * channels_ * kCrossfadeDuration;
  AlignToFrameBoundary(&bytes_in_crossfade_);

  crossfade_buffer_.reset(new uint8[bytes_in_crossfade_]);
}
