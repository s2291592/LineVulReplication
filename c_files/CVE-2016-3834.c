void CameraSource::releaseRecordingFrame(const sp<IMemory>& frame) {
    ALOGV("releaseRecordingFrame");
 if (mCameraRecordingProxy != NULL) {
        mCameraRecordingProxy->releaseRecordingFrame(frame);
 } else if (mCamera != NULL) {
 int64_t token = IPCThreadState::self()->clearCallingIdentity();
        mCamera->releaseRecordingFrame(frame);
 IPCThreadState::self()->restoreCallingIdentity(token);
 }
}

status_t StreamingProcessor::setRecordingFormat(int format,
        android_dataspace dataSpace) {
    ATRACE_CALL();

 Mutex::Autolock m(mMutex);

    ALOGV("%s: Camera %d: New recording format/dataspace from encoder: %X, %X",
            __FUNCTION__, mId, format, dataSpace);

    mRecordingFormat = format;
    mRecordingDataSpace = dataSpace;
 int prevGrallocUsage = mRecordingGrallocUsage;
 if (mRecordingFormat == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
        mRecordingGrallocUsage = GRALLOC_USAGE_HW_VIDEO_ENCODER;
 } else {
        mRecordingGrallocUsage = GRALLOC_USAGE_SW_READ_OFTEN;
 }

    ALOGV("%s: Camera %d: New recording gralloc usage: %08X", __FUNCTION__, mId,
            mRecordingGrallocUsage);

 if (prevGrallocUsage != mRecordingGrallocUsage) {
        ALOGV("%s: Camera %d: Resetting recording consumer for new usage",
            __FUNCTION__, mId);

 if (isStreamActive(mActiveStreamIds, mRecordingStreamId)) {
            ALOGE("%s: Camera %d: Changing recording format when "
 "recording stream is already active!", __FUNCTION__,
                    mId);
 return INVALID_OPERATION;
 }

        releaseAllRecordingFramesLocked();

        mRecordingConsumer.clear();
 }

 return OK;
}

bool StreamingProcessor::isStreamActive(const Vector<int32_t> &streams,
 int32_t recordingStreamId) {
 for (size_t i = 0; i < streams.size(); i++) {
 if (streams[i] == recordingStreamId) {
 return true;
 }
 }
 return false;
}

CameraSource *CameraSource::Create(const String16 &clientName) {
 Size size;
    size.width = -1;
    size.height = -1;

    sp<ICamera> camera;
 return new CameraSource(camera, NULL, 0, clientName, -1,
            size, -1, NULL, false);
}

 BpCameraRecordingProxy(const sp<IBinder>& impl)
 : BpInterface<ICameraRecordingProxy>(impl)
 {
 }

status_t CameraSource::reset() {
    ALOGD("reset: E");

 {
 Mutex::Autolock autoLock(mLock);
        mStarted = false;
        mFrameAvailableCondition.signal();

 int64_t token;
 bool isTokenValid = false;
 if (mCamera != 0) {
            token = IPCThreadState::self()->clearCallingIdentity();
            isTokenValid = true;
 }
        releaseQueuedFrames();
 while (!mFramesBeingEncoded.empty()) {
 if (NO_ERROR !=
                mFrameCompleteCondition.waitRelative(mLock,
                        mTimeBetweenFrameCaptureUs * 1000LL + CAMERA_SOURCE_TIMEOUT_NS)) {
                ALOGW("Timed out waiting for outstanding frames being encoded: %zu",
                    mFramesBeingEncoded.size());
 }
 }
        stopCameraRecording();
 if (isTokenValid) {
 IPCThreadState::self()->restoreCallingIdentity(token);
 }

 if (mCollectStats) {
            ALOGI("Frames received/encoded/dropped: %d/%d/%d in %" PRId64 " us",
                    mNumFramesReceived, mNumFramesEncoded, mNumFramesDropped,
                    mLastFrameTimestampUs - mFirstFrameTimeUs);
 }

 if (mNumGlitches > 0) {
            ALOGW("%d long delays between neighboring video frames", mNumGlitches);
 }

        CHECK_EQ(mNumFramesReceived, mNumFramesEncoded + mNumFramesDropped);
 }

    releaseCamera();

    ALOGD("reset: X");
 return OK;
}

void CameraSource::releaseCamera() {
    ALOGV("releaseCamera");
    sp<Camera> camera;
 bool coldCamera = false;
 {
 Mutex::Autolock autoLock(mLock);
        camera = mCamera;
        mCamera.clear();
        coldCamera = (mCameraFlags & FLAGS_HOT_CAMERA) == 0;
 }

 if (camera != 0) {
 int64_t token = IPCThreadState::self()->clearCallingIdentity();
 if (coldCamera) {
            ALOGV("Camera was cold when we started, stopping preview");
            camera->stopPreview();
            camera->disconnect();
 }
        camera->unlock();
 IPCThreadState::self()->restoreCallingIdentity(token);
 }

 {
 Mutex::Autolock autoLock(mLock);
 if (mCameraRecordingProxy != 0) {
 IInterface::asBinder(mCameraRecordingProxy)->unlinkToDeath(mDeathNotifier);
            mCameraRecordingProxy.clear();
 }
        mCameraFlags = 0;
 }
}

status_t BnCameraRecordingProxy::onTransact(
 uint32_t code, const Parcel& data, Parcel* reply, uint32_t flags)
{
 switch(code) {
 case START_RECORDING: {
            ALOGV("START_RECORDING");
            CHECK_INTERFACE(ICameraRecordingProxy, data, reply);
            sp<ICameraRecordingProxyListener> listener =
                interface_cast<ICameraRecordingProxyListener>(data.readStrongBinder());
            reply->writeInt32(startRecording(listener));
 return NO_ERROR;
 } break;
 case STOP_RECORDING: {
            ALOGV("STOP_RECORDING");
            CHECK_INTERFACE(ICameraRecordingProxy, data, reply);
            stopRecording();
 return NO_ERROR;
 } break;
 case RELEASE_RECORDING_FRAME: {
            ALOGV("RELEASE_RECORDING_FRAME");
            CHECK_INTERFACE(ICameraRecordingProxy, data, reply);
            sp<IMemory> mem = interface_cast<IMemory>(data.readStrongBinder());
            releaseRecordingFrame(mem);
 return NO_ERROR;
 } break;

 default:
 return BBinder::onTransact(code, data, reply, flags);
 }
}

int StreamingProcessor::getPreviewStreamId() const {
 Mutex::Autolock m(mMutex);
 return mPreviewStreamId;
}

int32_t StreamingProcessor::getActiveRequestId() const {
 Mutex::Autolock m(mMutex);
 switch (mActiveRequest) {
 case NONE:
 return 0;
 case PREVIEW:
 return mPreviewRequestId;
 case RECORD:
 return mRecordingRequestId;
 default:
            ALOGE("%s: Unexpected mode %d", __FUNCTION__, mActiveRequest);
 return 0;
 }
}

status_t CameraSource::checkFrameRate(
 const CameraParameters& params,
 int32_t frameRate) {

    ALOGV("checkFrameRate");
 int32_t frameRateActual = params.getPreviewFrameRate();
 if (frameRateActual < 0) {
        ALOGE("Failed to retrieve preview frame rate (%d)", frameRateActual);
 return UNKNOWN_ERROR;
 }

 if (frameRate != -1 && (frameRateActual - frameRate) != 0) {
        ALOGE("Failed to set preview frame rate to %d fps. The actual "
 "frame rate is %d", frameRate, frameRateActual);
 return UNKNOWN_ERROR;
 }

    mVideoFrameRate = frameRateActual;
 return OK;
}

status_t CameraSource::read(
 MediaBuffer **buffer, const ReadOptions *options) {
    ALOGV("read");

 *buffer = NULL;

 int64_t seekTimeUs;
 ReadOptions::SeekMode mode;
 if (options && options->getSeekTo(&seekTimeUs, &mode)) {
 return ERROR_UNSUPPORTED;
 }

    sp<IMemory> frame;
 int64_t frameTime;

 {
 Mutex::Autolock autoLock(mLock);
 while (mStarted && mFramesReceived.empty()) {
 if (NO_ERROR !=
                mFrameAvailableCondition.waitRelative(mLock,
                    mTimeBetweenFrameCaptureUs * 1000LL + CAMERA_SOURCE_TIMEOUT_NS)) {
 if (mCameraRecordingProxy != 0 &&
 !IInterface::asBinder(mCameraRecordingProxy)->isBinderAlive()) {
                    ALOGW("camera recording proxy is gone");
 return ERROR_END_OF_STREAM;
 }
                ALOGW("Timed out waiting for incoming camera video frames: %" PRId64 " us",
                    mLastFrameTimestampUs);
 }
 }
 if (!mStarted) {
 return OK;
 }
        frame = *mFramesReceived.begin();
        mFramesReceived.erase(mFramesReceived.begin());

        frameTime = *mFrameTimes.begin();
        mFrameTimes.erase(mFrameTimes.begin());
        mFramesBeingEncoded.push_back(frame);
 *buffer = new MediaBuffer(frame->pointer(), frame->size());
 (*buffer)->setObserver(this);
 (*buffer)->add_ref();
 (*buffer)->meta_data()->setInt64(kKeyTime, frameTime);
 }
 return OK;
}

status_t CameraSource::configureCamera(
 CameraParameters* params,
 int32_t width, int32_t height,
 int32_t frameRate) {
    ALOGV("configureCamera");
 Vector<Size> sizes;
 bool isSetVideoSizeSupportedByCamera = true;
    getSupportedVideoSizes(*params, &isSetVideoSizeSupportedByCamera, sizes);
 bool isCameraParamChanged = false;
 if (width != -1 && height != -1) {
 if (!isVideoSizeSupported(width, height, sizes)) {
            ALOGE("Video dimension (%dx%d) is unsupported", width, height);
 return BAD_VALUE;
 }
 if (isSetVideoSizeSupportedByCamera) {
            params->setVideoSize(width, height);
 } else {
            params->setPreviewSize(width, height);
 }
        isCameraParamChanged = true;
 } else if ((width == -1 && height != -1) ||
 (width != -1 && height == -1)) {
        ALOGE("Requested video size (%dx%d) is not supported", width, height);
 return BAD_VALUE;
 } else { // width == -1 && height == -1
 }

 if (frameRate != -1) {
        CHECK(frameRate > 0 && frameRate <= 120);
 const char* supportedFrameRates =
                params->get(CameraParameters::KEY_SUPPORTED_PREVIEW_FRAME_RATES);
        CHECK(supportedFrameRates != NULL);
        ALOGV("Supported frame rates: %s", supportedFrameRates);
 char buf[4];
        snprintf(buf, 4, "%d", frameRate);
 if (strstr(supportedFrameRates, buf) == NULL) {
            ALOGE("Requested frame rate (%d) is not supported: %s",
                frameRate, supportedFrameRates);
 return BAD_VALUE;
 }

        params->setPreviewFrameRate(frameRate);
        isCameraParamChanged = true;
 } else { // frameRate == -1
 }

 if (isCameraParamChanged) {
 String8 s = params->flatten();
 if (OK != mCamera->setParameters(s)) {
            ALOGE("Could not change settings."
 " Someone else is using camera %p?", mCamera.get());
 return -EBUSY;
 }
 }
 return OK;
}

void StreamingProcessor::releaseRecordingFrame(const sp<IMemory>& mem) {
    ATRACE_CALL();
 status_t res;

 Mutex::Autolock m(mMutex);
 ssize_t offset;
 size_t size;
    sp<IMemoryHeap> heap = mem->getMemory(&offset, &size);
 if (heap->getHeapID() != mRecordingHeap->mHeap->getHeapID()) {
        ALOGW("%s: Camera %d: Mismatched heap ID, ignoring release "
 "(got %x, expected %x)", __FUNCTION__, mId,
                heap->getHeapID(), mRecordingHeap->mHeap->getHeapID());
 return;
 }

 VideoNativeMetadata *payload = reinterpret_cast<VideoNativeMetadata*>(
 (uint8_t*)heap->getBase() + offset);

 if (payload->eType != kMetadataBufferTypeANWBuffer) {
        ALOGE("%s: Camera %d: Recording frame type invalid (got %x, expected %x)",
                __FUNCTION__, mId, payload->eType,
                kMetadataBufferTypeANWBuffer);

         return;
     }
 
     size_t itemIndex;
     for (itemIndex = 0; itemIndex < mRecordingBuffers.size(); itemIndex++) {
 const BufferItem item = mRecordingBuffers[itemIndex];
 if (item.mBuf != BufferItemConsumer::INVALID_BUFFER_SLOT &&
                item.mGraphicBuffer->getNativeBuffer() == payload->pBuffer) {
 break;
 }
 }

 if (itemIndex == mRecordingBuffers.size()) {
        ALOGE("%s: Camera %d: Can't find returned ANW Buffer %p in list of "
 "outstanding buffers", __FUNCTION__, mId,
                payload->pBuffer);
 return;
 }

    ALOGVV("%s: Camera %d: Freeing returned ANW buffer %p index %d", __FUNCTION__,
            mId, payload->pBuffer, itemIndex);

    res = mRecordingConsumer->releaseBuffer(mRecordingBuffers[itemIndex]);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to free recording frame "
 "(Returned ANW buffer: %p): %s (%d)", __FUNCTION__,
                mId, payload->pBuffer, strerror(-res), res);
 return;
 }
    mRecordingBuffers.replaceAt(itemIndex);

    mRecordingHeapFree++;
    ALOGV_IF(mRecordingHeapFree == mRecordingHeapCount,
 "%s: Camera %d: All %d recording buffers returned",
            __FUNCTION__, mId, mRecordingHeapCount);
}

bool StreamingProcessor::haveValidPreviewWindow() const {
 Mutex::Autolock m(mMutex);
 return mPreviewWindow != 0;
}

void CameraSource::stopCameraRecording() {
    ALOGV("stopCameraRecording");
 if (mCameraFlags & FLAGS_HOT_CAMERA) {
        mCameraRecordingProxy->stopRecording();
 } else {
        mCamera->setListener(NULL);
        mCamera->stopRecording();
 }
}

status_t CameraSource::initCheck() const {
 return mInitCheck;
}

CameraSource::CameraSource(
 const sp<ICamera>& camera,
 const sp<ICameraRecordingProxy>& proxy,
 int32_t cameraId,
 const String16& clientName,
 uid_t clientUid,
 Size videoSize,
 int32_t frameRate,
 const sp<IGraphicBufferProducer>& surface,
 bool storeMetaDataInVideoBuffers)
 : mCameraFlags(0),
      mNumInputBuffers(0),
      mVideoFrameRate(-1),
      mCamera(0),
      mSurface(surface),
      mNumFramesReceived(0),
      mLastFrameTimestampUs(0),
      mStarted(false),
      mNumFramesEncoded(0),
      mTimeBetweenFrameCaptureUs(0),
      mFirstFrameTimeUs(0),
      mNumFramesDropped(0),
      mNumGlitches(0),
      mGlitchDurationThresholdUs(200000),
      mCollectStats(false) {
    mVideoSize.width  = -1;
    mVideoSize.height = -1;

    mInitCheck = init(camera, proxy, cameraId,
                    clientName, clientUid,
                    videoSize, frameRate,
                    storeMetaDataInVideoBuffers);
 if (mInitCheck != OK) releaseCamera();
}

CameraSource::~CameraSource() {
 if (mStarted) {
        reset();
 } else if (mInitCheck == OK) {
        releaseCamera();
 }
}

bool CameraSource::isMetaDataStoredInVideoBuffers() const {
    ALOGV("isMetaDataStoredInVideoBuffers");

     return mIsMetaDataStoredInVideoBuffers;
 }

 CameraSource::ProxyListener::ProxyListener(const sp<CameraSource>& source) {
     mSource = source;
 }

status_t CameraSource::init(
 const sp<ICamera>& camera,
 const sp<ICameraRecordingProxy>& proxy,
 int32_t cameraId,
 const String16& clientName,
 uid_t clientUid,
 Size videoSize,
 int32_t frameRate,
 bool storeMetaDataInVideoBuffers) {

    ALOGV("init");
 status_t err = OK;
 int64_t token = IPCThreadState::self()->clearCallingIdentity();
    err = initWithCameraAccess(camera, proxy, cameraId, clientName, clientUid,
                               videoSize, frameRate,
                               storeMetaDataInVideoBuffers);
 IPCThreadState::self()->restoreCallingIdentity(token);
 return err;
}

status_t StreamingProcessor::updateRecordingRequest(const Parameters &params) {
    ATRACE_CALL();
 status_t res;
 Mutex::Autolock m(mMutex);

    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 if (mRecordingRequest.entryCount() == 0) {
        res = device->createDefaultRequest(CAMERA2_TEMPLATE_VIDEO_RECORD,
 &mRecordingRequest);
 if (res != OK) {
            ALOGE("%s: Camera %d: Unable to create default recording request:"
 " %s (%d)", __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 }

    res = params.updateRequest(&mRecordingRequest);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to update common entries of recording "
 "request: %s (%d)", __FUNCTION__, mId,
                strerror(-res), res);
 return res;
 }

    res = mRecordingRequest.update(ANDROID_REQUEST_ID,
 &mRecordingRequestId, 1);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to update request id for request: %s (%d)",
                __FUNCTION__, mId, strerror(-res), res);
 return res;
 }

 return OK;
}

status_t StreamingProcessor::updatePreviewRequest(const Parameters &params) {
    ATRACE_CALL();
 status_t res;
    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 Mutex::Autolock m(mMutex);
 if (mPreviewRequest.entryCount() == 0) {
        sp<Camera2Client> client = mClient.promote();
 if (client == 0) {
            ALOGE("%s: Camera %d: Client does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 if (client->getCameraDeviceVersion() >= CAMERA_DEVICE_API_VERSION_3_0) {
 if (params.zslMode && !params.recordingHint) {
                res = device->createDefaultRequest(CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG,
 &mPreviewRequest);
 } else {
                res = device->createDefaultRequest(CAMERA3_TEMPLATE_PREVIEW,
 &mPreviewRequest);
 }
 } else {
            res = device->createDefaultRequest(CAMERA2_TEMPLATE_PREVIEW,
 &mPreviewRequest);
 }

 if (res != OK) {
            ALOGE("%s: Camera %d: Unable to create default preview request: "
 "%s (%d)", __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 }

    res = params.updateRequest(&mPreviewRequest);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to update common entries of preview "
 "request: %s (%d)", __FUNCTION__, mId,
                strerror(-res), res);
 return res;
 }

    res = mPreviewRequest.update(ANDROID_REQUEST_ID,
 &mPreviewRequestId, 1);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to update request id for preview: %s (%d)",
                __FUNCTION__, mId, strerror(-res), res);
 return res;
 }

 return OK;
}

void CameraSource::releaseQueuedFrames() {

     List<sp<IMemory> >::iterator it;
     while (!mFramesReceived.empty()) {
         it = mFramesReceived.begin();
         releaseRecordingFrame(*it);
         mFramesReceived.erase(it);
         ++mNumFramesDropped;
 }
}

bool StreamingProcessor::threadLoop() {
 status_t res;

 {
 Mutex::Autolock l(mMutex);
 while (!mRecordingFrameAvailable) {
            res = mRecordingFrameAvailableSignal.waitRelative(
                mMutex, kWaitDuration);
 if (res == TIMED_OUT) return true;
 }
        mRecordingFrameAvailable = false;
 }

 do {
        res = processRecordingFrame();
 } while (res == OK);

 return true;
}

status_t StreamingProcessor::updateRecordingStream(const Parameters &params) {
    ATRACE_CALL();
 status_t res;
 Mutex::Autolock m(mMutex);

    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 bool newConsumer = false;
 if (mRecordingConsumer == 0) {
        ALOGV("%s: Camera %d: Creating recording consumer with %zu + 1 "
 "consumer-side buffers", __FUNCTION__, mId, mRecordingHeapCount);
        sp<IGraphicBufferProducer> producer;
        sp<IGraphicBufferConsumer> consumer;
 BufferQueue::createBufferQueue(&producer, &consumer);
        mRecordingConsumer = new BufferItemConsumer(consumer,
                mRecordingGrallocUsage,
                mRecordingHeapCount + 1);
        mRecordingConsumer->setFrameAvailableListener(this);
        mRecordingConsumer->setName(String8("Camera2-RecordingConsumer"));
        mRecordingWindow = new Surface(producer);
        newConsumer = true;
 }

 if (mRecordingStreamId != NO_STREAM) {
 uint32_t currentWidth, currentHeight;
 uint32_t currentFormat;
        android_dataspace currentDataSpace;
        res = device->getStreamInfo(mRecordingStreamId,
 &currentWidth, &currentHeight,
 &currentFormat, &currentDataSpace);
 if (res != OK) {
            ALOGE("%s: Camera %d: Error querying recording output stream info: "
 "%s (%d)", __FUNCTION__, mId,
                    strerror(-res), res);
 return res;
 }
 if (currentWidth != (uint32_t)params.videoWidth ||
                currentHeight != (uint32_t)params.videoHeight ||
                currentFormat != (uint32_t)mRecordingFormat ||
                currentDataSpace != mRecordingDataSpace ||
                newConsumer) {
            res = device->deleteStream(mRecordingStreamId);

 if (res == -EBUSY) {
                ALOGV("%s: Camera %d: Device is busy, call "
 "updateRecordingStream after it becomes idle",
                      __FUNCTION__, mId);
 return res;
 } else if (res != OK) {
                ALOGE("%s: Camera %d: Unable to delete old output stream "
 "for recording: %s (%d)", __FUNCTION__,
                        mId, strerror(-res), res);
 return res;
 }
            mRecordingStreamId = NO_STREAM;
 }
 }

 if (mRecordingStreamId == NO_STREAM) {
        mRecordingFrameCount = 0;
        res = device->createStream(mRecordingWindow,
                params.videoWidth, params.videoHeight,
                mRecordingFormat, mRecordingDataSpace,
                CAMERA3_STREAM_ROTATION_0, &mRecordingStreamId);
 if (res != OK) {
            ALOGE("%s: Camera %d: Can't create output stream for recording: "
 "%s (%d)", __FUNCTION__, mId,
                    strerror(-res), res);
 return res;
 }
 }

 return OK;
}

sp<MetaData> CameraSource::getFormat() {
 return mMeta;
}

int StreamingProcessor::getRecordingStreamId() const {
 return mRecordingStreamId;
}

static int32_t getColorFormat(const char* colorFormat) {
 if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_YUV420P)) {
 return OMX_COLOR_FormatYUV420Planar;
 }

 if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_YUV422SP)) {
 return OMX_COLOR_FormatYUV422SemiPlanar;
 }

 if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_YUV420SP)) {
 return OMX_COLOR_FormatYUV420SemiPlanar;
 }

 if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_YUV422I)) {
 return OMX_COLOR_FormatYCbYCr;
 }

 if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_RGB565)) {
 return OMX_COLOR_Format16bitRGB565;
 }

 if (!strcmp(colorFormat, "OMX_TI_COLOR_FormatYUV420PackedSemiPlanar")) {
 return OMX_TI_COLOR_FormatYUV420PackedSemiPlanar;
 }

 if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_ANDROID_OPAQUE)) {
 return OMX_COLOR_FormatAndroidOpaque;
 }

    ALOGE("Uknown color format (%s), please add it to "
 "CameraSource::getColorFormat", colorFormat);

    CHECK(!"Unknown color format");
 return -1;
}

status_t CameraSource::startCameraRecording() {
    ALOGV("startCameraRecording");
 int64_t token = IPCThreadState::self()->clearCallingIdentity();
 status_t err;
 if (mNumInputBuffers > 0) {
        err = mCamera->sendCommand(
            CAMERA_CMD_SET_VIDEO_BUFFER_COUNT, mNumInputBuffers, 0);

 if (err != OK) {
            ALOGW("Failed to set video buffer count to %d due to %d",
                mNumInputBuffers, err);
 }
 }

    err = mCamera->sendCommand(
        CAMERA_CMD_SET_VIDEO_FORMAT, mEncoderFormat, mEncoderDataSpace);

 if (err != OK) {
        ALOGW("Failed to set video encoder format/dataspace to %d, %d due to %d",
                mEncoderFormat, mEncoderDataSpace, err);
 }

    err = OK;
 if (mCameraFlags & FLAGS_HOT_CAMERA) {
        mCamera->unlock();
        mCamera.clear();
 if ((err = mCameraRecordingProxy->startRecording(
 new ProxyListener(this))) != OK) {
            ALOGE("Failed to start recording, received error: %s (%d)",
                    strerror(-err), err);
 }
 } else {
        mCamera->setListener(new CameraSourceListener(this));
        mCamera->startRecording();
 if (!mCamera->recordingEnabled()) {
            err = -EINVAL;
            ALOGE("Failed to start recording");
 }
 }
 IPCThreadState::self()->restoreCallingIdentity(token);
 return err;
}

CameraSourceListener::CameraSourceListener(const sp<CameraSource> &source)
 : mSource(source) {
}

 void stopRecording()
 {
        ALOGV("stopRecording");
 Parcel data, reply;
        data.writeInterfaceToken(ICameraRecordingProxy::getInterfaceDescriptor());
        remote()->transact(STOP_RECORDING, data, &reply);
 }

CameraSourceListener::~CameraSourceListener() {
}

status_t StreamingProcessor::togglePauseStream(bool pause) {
    ATRACE_CALL();
 status_t res;

    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

    ALOGV("%s: Camera %d: toggling pause to %d", __FUNCTION__, mId, pause);

 Mutex::Autolock m(mMutex);

 if (mActiveRequest == NONE) {
        ALOGE("%s: Camera %d: Can't toggle pause, streaming was not started",
              __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 if (mPaused == pause) {
 return OK;
 }

 if (pause) {
        res = device->clearStreamingRequest();
 if (res != OK) {
            ALOGE("%s: Camera %d: Can't clear stream request: %s (%d)",
                    __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 } else {
 CameraMetadata &request =
 (mActiveRequest == PREVIEW) ? mPreviewRequest
 : mRecordingRequest;
        res = device->setStreamingRequest(request);
 if (res != OK) {
            ALOGE("%s: Camera %d: Unable to set preview request to resume: "
 "%s (%d)",
                    __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 }

    mPaused = pause;
 return OK;
}

void CameraSource::dataCallbackTimestamp(int64_t timestampUs,
 int32_t msgType __unused, const sp<IMemory> &data) {
    ALOGV("dataCallbackTimestamp: timestamp %lld us", (long long)timestampUs);
 Mutex::Autolock autoLock(mLock);
 if (!mStarted || (mNumFramesReceived == 0 && timestampUs < mStartTimeUs)) {
        ALOGV("Drop frame at %lld/%lld us", (long long)timestampUs, (long long)mStartTimeUs);
        releaseOneRecordingFrame(data);
 return;
 }

 if (skipCurrentFrame(timestampUs)) {
        releaseOneRecordingFrame(data);
 return;
 }

 if (mNumFramesReceived > 0) {
 if (timestampUs <= mLastFrameTimestampUs) {
            ALOGW("Dropping frame with backward timestamp %lld (last %lld)",
 (long long)timestampUs, (long long)mLastFrameTimestampUs);
            releaseOneRecordingFrame(data);
 return;
 }
 if (timestampUs - mLastFrameTimestampUs > mGlitchDurationThresholdUs) {
 ++mNumGlitches;
 }
 }

    mLastFrameTimestampUs = timestampUs;
 if (mNumFramesReceived == 0) {
        mFirstFrameTimeUs = timestampUs;
 if (mStartTimeUs > 0) {
 if (timestampUs < mStartTimeUs) {
                releaseOneRecordingFrame(data);
 return;
 }
            mStartTimeUs = timestampUs - mStartTimeUs;
 }
 }

     ++mNumFramesReceived;
 
     CHECK(data != NULL && data->size() > 0);
     mFramesReceived.push_back(data);
     int64_t timeUs = mStartTimeUs + (timestampUs - mFirstFrameTimeUs);
     mFrameTimes.push_back(timeUs);
    ALOGV("initial delay: %" PRId64 ", current time stamp: %" PRId64,
        mStartTimeUs, timeUs);
    mFrameAvailableCondition.signal();
}

status_t CameraSource::initWithCameraAccess(
 const sp<ICamera>& camera,
 const sp<ICameraRecordingProxy>& proxy,
 int32_t cameraId,
 const String16& clientName,
 uid_t clientUid,
 Size videoSize,
 int32_t frameRate,
 bool storeMetaDataInVideoBuffers) {
    ALOGV("initWithCameraAccess");
 status_t err = OK;

 if ((err = isCameraAvailable(camera, proxy, cameraId,
            clientName, clientUid)) != OK) {
        ALOGE("Camera connection could not be established.");
 return err;
 }
 CameraParameters params(mCamera->getParameters());
 if ((err = isCameraColorFormatSupported(params)) != OK) {
 return err;
 }

 if ((err = configureCamera(&params,
                    videoSize.width, videoSize.height,
                    frameRate))) {
 return err;
 }

 CameraParameters newCameraParams(mCamera->getParameters());
 if ((err = checkVideoSize(newCameraParams,
                videoSize.width, videoSize.height)) != OK) {
 return err;
 }
 if ((err = checkFrameRate(newCameraParams, frameRate)) != OK) {
 return err;
 }

 if (mSurface != NULL) {
        CHECK_EQ((status_t)OK, mCamera->setPreviewTarget(mSurface));
 }

    mIsMetaDataStoredInVideoBuffers = false;
    mCamera->storeMetaDataInBuffers(false);
 if (storeMetaDataInVideoBuffers) {
 if (OK == mCamera->storeMetaDataInBuffers(true)) {
            mIsMetaDataStoredInVideoBuffers = true;
 }
 }

 int64_t glitchDurationUs = (1000000LL / mVideoFrameRate);
 if (glitchDurationUs > mGlitchDurationThresholdUs) {
        mGlitchDurationThresholdUs = glitchDurationUs;
 }

    mMeta = new MetaData;
    mMeta->setCString(kKeyMIMEType,  MEDIA_MIMETYPE_VIDEO_RAW);
    mMeta->setInt32(kKeyColorFormat, mColorFormat);
    mMeta->setInt32(kKeyWidth,       mVideoSize.width);
    mMeta->setInt32(kKeyHeight,      mVideoSize.height);
    mMeta->setInt32(kKeyStride,      mVideoSize.width);
    mMeta->setInt32(kKeySliceHeight, mVideoSize.height);
    mMeta->setInt32(kKeyFrameRate,   mVideoFrameRate);
 return OK;
}

static void getSupportedVideoSizes(
 const CameraParameters& params,
 bool *isSetVideoSizeSupported,
 Vector<Size>& sizes) {

 *isSetVideoSizeSupported = true;
    params.getSupportedVideoSizes(sizes);
 if (sizes.size() == 0) {
        ALOGD("Camera does not support setVideoSize()");
        params.getSupportedPreviewSizes(sizes);
 *isSetVideoSizeSupported = false;
 }
}

CameraSource *CameraSource::CreateFromCamera(
 const sp<ICamera>& camera,
 const sp<ICameraRecordingProxy>& proxy,
 int32_t cameraId,
 const String16& clientName,
 uid_t clientUid,
 Size videoSize,
 int32_t frameRate,
 const sp<IGraphicBufferProducer>& surface,
 bool storeMetaDataInVideoBuffers) {

 CameraSource *source = new CameraSource(camera, proxy, cameraId,
            clientName, clientUid, videoSize, frameRate, surface,
            storeMetaDataInVideoBuffers);
 return source;
}

 void releaseRecordingFrame(const sp<IMemory>& mem)
 {
        ALOGV("releaseRecordingFrame");
 Parcel data, reply;
        data.writeInterfaceToken(ICameraRecordingProxy::getInterfaceDescriptor());
        data.writeStrongBinder(IInterface::asBinder(mem));
        remote()->transact(RELEASE_RECORDING_FRAME, data, &reply);
 }

StreamingProcessor::~StreamingProcessor() {
    deletePreviewStream();
    deleteRecordingStream();
}

void StreamingProcessor::onFrameAvailable(const BufferItem& /*item*/) {
    ATRACE_CALL();
 Mutex::Autolock l(mMutex);
 if (!mRecordingFrameAvailable) {
        mRecordingFrameAvailable = true;
        mRecordingFrameAvailableSignal.signal();
 }

}

status_t CameraSource::isCameraColorFormatSupported(
 const CameraParameters& params) {
    mColorFormat = getColorFormat(params.get(
 CameraParameters::KEY_VIDEO_FRAME_FORMAT));
 if (mColorFormat == -1) {
 return BAD_VALUE;
 }
 return OK;
}

status_t StreamingProcessor::setPreviewWindow(sp<Surface> window) {
    ATRACE_CALL();
 status_t res;

    res = deletePreviewStream();
 if (res != OK) return res;

 Mutex::Autolock m(mMutex);

    mPreviewWindow = window;

 return OK;
}

status_t StreamingProcessor::stopStream() {
    ATRACE_CALL();
 status_t res;

 Mutex::Autolock m(mMutex);

    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

    res = device->clearStreamingRequest();
 if (res != OK) {
        ALOGE("%s: Camera %d: Can't clear stream request: %s (%d)",
                __FUNCTION__, mId, strerror(-res), res);
 return res;
 }

    mActiveRequest = NONE;
    mActiveStreamIds.clear();
    mPaused = false;

 return OK;
}

status_t StreamingProcessor::updatePreviewStream(const Parameters &params) {
    ATRACE_CALL();
 Mutex::Autolock m(mMutex);

 status_t res;
    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 if (mPreviewStreamId != NO_STREAM) {
 uint32_t currentWidth, currentHeight;
        res = device->getStreamInfo(mPreviewStreamId,
 &currentWidth, &currentHeight, 0, 0);
 if (res != OK) {
            ALOGE("%s: Camera %d: Error querying preview stream info: "
 "%s (%d)", __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 if (currentWidth != (uint32_t)params.previewWidth ||
                currentHeight != (uint32_t)params.previewHeight) {
            ALOGV("%s: Camera %d: Preview size switch: %d x %d -> %d x %d",
                    __FUNCTION__, mId, currentWidth, currentHeight,
                    params.previewWidth, params.previewHeight);
            res = device->waitUntilDrained();
 if (res != OK) {
                ALOGE("%s: Camera %d: Error waiting for preview to drain: "
 "%s (%d)", __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
            res = device->deleteStream(mPreviewStreamId);
 if (res != OK) {
                ALOGE("%s: Camera %d: Unable to delete old output stream "
 "for preview: %s (%d)", __FUNCTION__, mId,
                        strerror(-res), res);
 return res;
 }
            mPreviewStreamId = NO_STREAM;
 }
 }

 if (mPreviewStreamId == NO_STREAM) {
        res = device->createStream(mPreviewWindow,
                params.previewWidth, params.previewHeight,
                CAMERA2_HAL_PIXEL_FORMAT_OPAQUE, HAL_DATASPACE_UNKNOWN,
                CAMERA3_STREAM_ROTATION_0, &mPreviewStreamId);
 if (res != OK) {
            ALOGE("%s: Camera %d: Unable to create preview stream: %s (%d)",
                    __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 }

    res = device->setStreamTransform(mPreviewStreamId,
            params.previewTransform);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to set preview stream transform: "
 "%s (%d)", __FUNCTION__, mId, strerror(-res), res);
 return res;
 }

 return OK;
}

void CameraSource::ProxyListener::dataCallbackTimestamp(
 nsecs_t timestamp, int32_t msgType, const sp<IMemory>& dataPtr) {
    mSource->dataCallbackTimestamp(timestamp / 1000, msgType, dataPtr);
}

void StreamingProcessor::releaseAllRecordingFramesLocked() {
    ATRACE_CALL();
 status_t res;

 if (mRecordingConsumer == 0) {
 return;
 }

    ALOGV("%s: Camera %d: Releasing all recording buffers", __FUNCTION__,
            mId);

 size_t releasedCount = 0;
 for (size_t itemIndex = 0; itemIndex < mRecordingBuffers.size(); itemIndex++) {
 const BufferItem item = mRecordingBuffers[itemIndex];
 if (item.mBuf != BufferItemConsumer::INVALID_BUFFER_SLOT) {
            res = mRecordingConsumer->releaseBuffer(mRecordingBuffers[itemIndex]);
 if (res != OK) {
                ALOGE("%s: Camera %d: Unable to free recording frame "
 "(buffer_handle_t: %p): %s (%d)", __FUNCTION__,
                        mId, item.mGraphicBuffer->handle, strerror(-res), res);
 }
            mRecordingBuffers.replaceAt(itemIndex);
            releasedCount++;
 }
 }

 if (releasedCount > 0) {
        ALOGW("%s: Camera %d: Force-freed %zu outstanding buffers "
 "from previous recording session", __FUNCTION__, mId, releasedCount);
        ALOGE_IF(releasedCount != mRecordingHeapCount - mRecordingHeapFree,
 "%s: Camera %d: Force-freed %zu buffers, but expected %zu",
            __FUNCTION__, mId, releasedCount, mRecordingHeapCount - mRecordingHeapFree);
 }

    mRecordingHeapHead = 0;
    mRecordingHeapFree = mRecordingHeapCount;
}

StreamingProcessor::StreamingProcessor(sp<Camera2Client> client):
        mClient(client),
        mDevice(client->getCameraDevice()),
        mId(client->getCameraId()),
        mActiveRequest(NONE),
        mPaused(false),
        mPreviewRequestId(Camera2Client::kPreviewRequestIdStart),
        mPreviewStreamId(NO_STREAM),
        mRecordingRequestId(Camera2Client::kRecordingRequestIdStart),
        mRecordingStreamId(NO_STREAM),
        mRecordingFrameAvailable(false),
        mRecordingHeapCount(kDefaultRecordingHeapCount),
        mRecordingHeapFree(kDefaultRecordingHeapCount),
        mRecordingFormat(kDefaultRecordingFormat),
        mRecordingDataSpace(kDefaultRecordingDataSpace),
        mRecordingGrallocUsage(kDefaultRecordingGrallocUsage)
{
}

status_t StreamingProcessor::incrementStreamingIds() {
    ATRACE_CALL();
 Mutex::Autolock m(mMutex);

    mPreviewRequestId++;
 if (mPreviewRequestId >= Camera2Client::kPreviewRequestIdEnd) {
        mPreviewRequestId = Camera2Client::kPreviewRequestIdStart;
 }
    mRecordingRequestId++;
 if (mRecordingRequestId >= Camera2Client::kRecordingRequestIdEnd) {
        mRecordingRequestId = Camera2Client::kRecordingRequestIdStart;
 }
 return OK;
}
