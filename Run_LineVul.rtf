{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 $ssh eddie.ecdf.ed.ac.uk\
$qlogin\
$cd /exports/eddie/scratch/username\
\
\
\
1. Anaconda: \
Download anaconda in scratch not in home( the quota of disk is not enough)\
$module load anaconda, and create a env with python3.9 in Eddie( other envs have already set if I choose python3.9)\
$conda activate mypython\
\
\
\
2.Git clone: the URL in README file is wrong\
\
git clone https://github.com/awsm-research/LineVul.git\
cd LineVul\
\
\
\
3.requirements:\
Some of them will not in the PATH if just pip install it.\
\
\
\
4.Experiment Replication Preparation:\
After download model, I use code to test whether it works:\
\
from transformers import RobertaForSequenceClassification\
def load_model():\
model = RobertaForSequenceClassification.from_pretrained('distilroberta-base')\
return model\
\
if __name__ == "__main__":\
load_model()\
\
Note:\
cd data\
cd big-vul_dataset\
gdown https://drive.google.com/uc?id=1ldXyFvHG41VMrm260cK_JEPYqeb6e6Yw\
gdown https://drive.google.com/uc?id=1yggncqivMcP0tzbh8-8Eu02Edwcs44WZ\
cd ../..\
In upper code, the first down is not available, I download it on my pc and create a new URL for gdown:\
\
FILE_ID=1ldXyFvHG41VMrm260cK_JEPYqeb6e6Yw\
FILE_NAME=train.csv\
\
wget --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILE_ID -O $FILE_NAME\
\
5.Replication:\
First we need to use cuda(GPU), use the code below:\
qlogin -q gpu -pe gpu-a100 1 -l h_rt=12:00:00 -l h_vmem=16G\
or qrsh -l h_rt=12:00:00 -l h_vmem=32G -q gpu -pe gpu-a100 2\
or create a run_gpu.sh file and then qsub:\
nano run_gpu.sh\
chmod +x run_gpu.sh\
qsub run_gpu.sh   \
\
If choose first two, and it works, then \
$module load cuda\
$source /exports/applications/support/set_qlogin_environment.sh\
Note: 8 hours is not enough for rq1\
\
run_gpu.sh:\
\
#!/bin/bash\
\
# Grid Engine options (lines prefixed with #$)\
# Runtime limit of 12 hour:\
#$ -l h_rt=12:00:00\
#\
# Set working directory to the directory where the job is submitted from:\
#$ -cwd\
#\
# Request one GPU in the gpu queue:\
#$ -q gpu\
#$ -pe gpu-a100 2\
#\
# Request 16 GB system RAM\
# the total system RAM available to the job is the value specified here multipl$\
# the number of requested GPUs (above)\
#$ -l h_vmem=16G\
\
# Initialise the environment modules and load CUDA version 11.0.2\
. /etc/profile.d/modules.sh\
module load cuda\
source /exports/applications/support/set_qlogin_environment.sh\
# Navigate to the desired directory\
cd /exports/eddie/scratch/username/LineVul\
\
module load anaconda\
conda activate mypython\
\
\
cd linevul\
python linevul_main.py \\\
  --output_dir=./saved_models \\\
  --model_type=roberta \\\
  --tokenizer_name=microsoft/codebert-base \\\
  --model_name_or_path=microsoft/codebert-base \\\
  --do_train \\\
  --do_test \\\
  --train_data_file=../data/big-vul_dataset/train.csv \\\
  --eval_data_file=../data/big-vul_dataset/val.csv \\\
  --test_data_file=../data/big-vul_dataset/test.csv \\\
  --epochs 10 \\\
  --block_size 512 \\\
  --train_batch_size 16 \\\
  --eval_batch_size 16 \\\
  --learning_rate 2e-5 \\\
  --max_grad_norm 1.0 \\\
  --evaluate_during_training \\\
  --seed 123456  2>&1 | tee train.log\
\
}